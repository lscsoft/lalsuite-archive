#!/usr/bin/python
#
# $Id$
#
# Copyright (C) 2006  Kipp C. Cannon
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.


#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#


"""
Translate thinca-style sngl_inspiral coincs to coinc-tables-style coincs.
"""


import itertools
import math
from optparse import OptionParser
import re
import sys


from glue import iterutils
from glue import lal
from glue import segments
from glue.ligolw import ligolw
from glue.ligolw import table
from glue.ligolw import lsctables
from glue.ligolw import utils
from glue.ligolw.utils import ligolw_add
from glue.ligolw.utils import segments as ligolw_segments
from glue.ligolw.utils import process as ligolw_process
from pylal import llwapp
from pylal import ligolw_thinca
from pylal import ligolw_tisi
from pylal import SnglInspiralUtils


__author__ = "Kipp Cannon <kipp@gravity.phys.uwm.edu>"
__version__ = "$Revision$"[11:-2]
__date__ = "$Date$"[7:-2]


#
# =============================================================================
#
#                              Behavioural Tweaks
#
# =============================================================================
#


#
# Make sngl_inspiral table rows hashable so they can be used as dictionary
# keys and uniquified with set()
#


def __sngl_inspiral_hash__(self):
	# The things in this tuple must be the same things used in the
	# __cmp__() method for comparison (if two objects have different
	# hashes they must compare as not equal or stuff breaks), so make
	# sure to keep this updated if the choice of how to compare to
	# triggers changes.
	return hash((self.ifo, self.end_time, self.end_time_ns, self.mass1, self.mass2, self.search))


lsctables.SnglInspiral.__hash__ = __sngl_inspiral_hash__


#
# =============================================================================
#
#                                 Command Line
#
# =============================================================================
#


def parse_command_line():
	parser = OptionParser(
		version = "%prog CVS $Id$",
		usage = "%prog [options] --output-prefix filename",
		description = "Converts thinca output files to coinc tables format.  Files whose names end in \".gz\" are assumed to be gzip-compressed.  If an ihope cache is provided then all second-stage thinca files found in the cache will be processed, grouped by run tag.  Otherwise, one or both of a zero-lag or time-slide thinca output file must be provided."
	)
	parser.add_option("--zero-lag-file", metavar = "filename", help = "Thinca output file containing zero lag triggers.")
	parser.add_option("--time-slide-file", metavar = "filename", help = "Thinca output file containing time slide triggers.")
	parser.add_option("--ihope-cache", metavar = "filename", help = "Get thinca files from this ihope cache.")
	parser.add_option("--instruments", metavar = "name[,name,...]", help = "Set the list of instruments.  Example H1,H2,L1.  If not provided, attempts will be made to deduce the instrument list either from --??-slide command line options in the process_params table or from the contents of the ifos column in the search_summary table.")
	parser.add_option("--output-prefix", metavar = "string", help = "Set the prefix string for output filenames (required).  Output filenames are constructed automatically, and are of the form \"PREFIX_blah_blah_blah.xml.gz\".  Hint:  can include a path.")
	parser.add_option("--veto-segments", metavar = "filename", help = "Load veto segments from this XML document.  See ligolw_segments for information on constructing such a document.")
	parser.add_option("--veto-segments-name", metavar = "string", help = "Set the name of the veto segments to use from the XML document.")
	parser.add_option("--effective-snr-factor", metavar = "float", type = "float", default = 250.0, help = "Set the effective SNR factor (default = 250.0).")
	parser.add_option("--experiment-start-time", type="int", help = "Start time, in gps seconds, of the experiment being performed. This is NOT the start time of the thinca-files	being used. Required.")
	parser.add_option("--experiment-end-time", type="int", help = "End time, in gps seconds, of the experiment being performed. This is NOT the end time of the thinca-files	being used. Required.")
	parser.add_option("-v", "--verbose", action = "store_true", help = "Be verbose.")
	options, args = parser.parse_args()

	if options.ihope_cache:
		if options.zero_lag_file or options.time_slide_file:
			raise ValueError, "cannot specify --zero-lag-file or --time-slide-file with --ihope-cache"
		if options.verbose:
			print >>sys.stderr, "reading %s ..." % options.ihope_cache
		# find second thinca cache entries
		pattern = re.compile("THINCA(_SLIDE)?_SECOND_[^_]+_(?P<tag>.+)_CAT_(?P<cat>[\d]+)_VETO")
		zero_lag_urls = {}
		slide_urls = {}
		for c in map(lal.CacheEntry, file(options.ihope_cache)):
			category = pattern.match(c.description)
			if category is None:
				continue
			category = category.groups()
			if category[0] is None:
				# zero-lag URL
				try:
					zero_lag_urls[category[1:]].append(c)
				except KeyError:
					zero_lag_urls[category[1:]] = [c]
			else:
				# slide URL
				try:
					slide_urls[category[1:]].append(c)
				except KeyError:
					slide_urls[category[1:]] = [c]
		# extract URLs.  sorting cache entries puts them in time
		# order
		zero_lag_urls = dict((key, [c.url for c in sorted(cache)]) for key, cache in zero_lag_urls.items())
		slide_urls = dict((key, [c.url for c in sorted(cache)]) for key, cache in slide_urls.items())
		# pad lists with None's so zero-lag and slide lists exist
		# for all the same categories and have the same number of
		# entries
		for key in set(zero_lag_urls.keys()) | set(slide_urls.keys()):
			if key not in slide_urls:
				# must be in zero-lag
				slide_urls[key] = [None,] * len(zero_lag_urls[key])
			elif key not in zero_lag_urls:
				# must be in slides
				zero_lag_urls[key] = [None,] * len(slide_urls[key])
			# must be in both, make sure lengths are the same
			elif len(zero_lag_urls[key]) > len(slide_urls[key]):
				slide_urls[key] += [None,] * (len(zero_lag_urls[key]) - len(slide_urls[key]))
			elif len(zero_lag_urls[key]) < len(slide_urls[key]):
				zero_lag_urls[key] += [None,] * (len(slide_urls[key]) - len(zero_lag_urls[key]))
		# match up each zero-lag url with corresponding slides urls
		# in each category
		categories = dict((key, zip(zero_lag_urls[key], slide_urls[key])) for key in zero_lag_urls.keys())
	elif options.zero_lag_file or options.time_slide_file:
		categories = {(None, None): [(options.zero_lag_file, options.time_slide_file)]}
	else:
		raise ValueError, "must specify --ihope-cache or at least one of --zero-lag-file and --time-slide-file"
	if not options.output_prefix:
		raise ValueError, "must specify --output-prefix"
	if options.veto_segments and not options.veto_segments_name:
		raise ValueError, "must specify --veto-segments-name if --veto-sements is specified"
	if options.instruments:
		options.instruments = set(options.instruments.split(","))
	if not options.experiment_start_time or not options.experiment_end_time:
		raise ValueError, "must specify --experiment-start-time and --experiment-end-time"

	if args:
		raise ValueError, "extraneous command line arguments specified"

	return options, categories


#
# =============================================================================
#
#                             Process Information
#
# =============================================================================
#


#
# create and initialize this job's row in the process table
#


def initialize_process(xmldoc, comment = u""):
	return llwapp.append_process(xmldoc, program = u"ligolw_thinca_to_coinc", version = __version__, cvs_repository = u"lscsoft", cvs_entry_time = __date__, comment = comment)


#
# record command line arguments
#


def set_process_params(xmldoc, process, options):
	params = []
	if options.zero_lag_file:
		params.append((u"--zero-lag-file", u"lstring", options.zero_lag_file))
	if options.time_slide_file:
		params.append((u"--time-slide-file", u"lstring", options.time_slide_file))
	if options.ihope_cache:
		params.append((u"--ihope-cache", u"lstring", options.ihope_cache))
	if options.instruments:
		params.append((u"--instruments", u"lstring", ",".join(options.instruments)))
	if options.veto_segments:
		params.append((u"--veto-segments", u"lstring", options.veto_segments))
	if options.veto_segments_name:
		params.append((u"--veto-segments-name", u"lstring", options.veto_segments_name))
	if options.effective_snr_factor:
		params.append((u"--effective-snr-factor", u"lstring", options.effective_snr_factor))
	params.append((u"--output-prefix", u"lstring", options.output_prefix))

	ligolw_process.append_process_params(xmldoc, process, params)

	return xmldoc


#
# =============================================================================
#
#                               Document Fix-Up
#
# =============================================================================
#


#
# add missing ID columns.  this is needed because the cbc 2yr tags are on
# versions of LAL that don't have these columns in the tables.  current
# versions of LAL do.
#


def add_missing_id_columns(xmldoc, verbose = False):
	if verbose:
		print >>sys.stderr, "adding any missing ID columns ...",

	#
	# fix summ_value and search_summ_vars tables
	#

	for name in (lsctables.SummValueTable.tableName, lsctables.SearchSummVarsTable.tableName):
		try:
			tbl = table.get_table(xmldoc, name)
			tbl.appendColumn(tbl.next_id.column_name)
		except ValueError:
			# document doesn't have this table or already has
			# ID column
			continue
		if verbose:
			print >>sys.stderr, name,
		for row in tbl:
			setattr(row, tbl.next_id.column_name, tbl.get_next_id())

	#
	# done
	#

	if verbose:
		print >>sys.stderr


#
# Fix ifos columns by turning strings like "H1H2L1" into strings like
# "H1,H2,L1".
#


def fix_ifos_columns(xmldoc, verbose = False):
	if verbose:
		print >>sys.stderr, "fixing ifos columns ...",

	#
	# fix process and search_summary tables
	#

	for table_name in (lsctables.ProcessTable.tableName, lsctables.SearchSummaryTable.tableName):
		try:
			tbl = table.get_table(xmldoc, table_name)
		except ValueError:
			# document doesn't have this table
			continue
		if options.verbose:
			print >>sys.stderr, table_name,
		for row in tbl:
			row.set_ifos(row.get_ifos())

	#
	# done
	#

	if verbose:
		print >>sys.stderr


#
# =============================================================================
#
#                          Populate time_slide Table
#
# =============================================================================
#


def get_thinca_process_ids(xmldoc):
	return table.get_table(xmldoc, lsctables.ProcessTable.tableName).get_ids_by_program("thinca")


def get_search_summary_instruments(xmldoc, thinca_process_ids):
	"""
	Extract the list of analyzed instruments from the thinca entries in
	the search summary table.
	"""
	search_summary_instruments = set(frozenset(row.get_ifos()) for row in table.get_table(xmldoc, lsctables.SearchSummaryTable.tableName) if row.process_id in thinca_process_ids)
	if len(search_summary_instruments) < 1:
		raise ValueError, "cannot find entries for thinca jobs in search_summary table"
	if len(search_summary_instruments) > 1:
		raise ValueError, "search_summary table contains entries for thinca jobs from more than 1 unique set of instruments:  found %s" % ", ".join(search_summary_instruments)
	return search_summary_instruments.pop()


def populate_thinca_time_slide_table(xmldoc, process, instruments = None, verbose = False):
	"""
	Reconstruct the list of time slides from lalapps_thinca's command
	line arguments.
	"""
	if verbose:
		print >>sys.stderr, "populating thinca time_slide table ...",

	#
	# find the time_slide table or add one if needed
	#

	try:
		time_slide_table = table.get_table(xmldoc, lsctables.TimeSlideTable.tableName)
	except ValueError:
		time_slide_table = lsctables.New(lsctables.TimeSlideTable)
		xmldoc.childNodes[0].appendChild(time_slide_table)

	#
	# move existing time_slide IDs out of the way
	#

	# find the lowest unused ID not less than 10000 and set next_id to
	# that value
	time_slide_table.sync_next_id()
	if time_slide_table.next_id < type(time_slide_table.next_id)(10000):
		time_slide_table.set_next_id(type(time_slide_table.next_id)(10000))
	# use the updateKeyMapping method to re-label all existing
	# time_slide IDs and record the old-->new mapping
	mapping = {}
	time_slide_table.updateKeyMapping(mapping)
	# apply the mapping to all other tables in the document to update
	# any references to existing time_slide IDs
	for tbl in xmldoc.getElementsByTagName(time_slide_table.tagName):
		tbl.applyKeyMapping(mapping)

	#
	# get process_ids for all thinca jobs, and for thinca jobs that
	# were run with a --num-slides command line option
	#

	thinca_process_ids = get_thinca_process_ids(xmldoc)
	slides_process_ids = thinca_process_ids & set(row.process_id for row in table.get_table(xmldoc, lsctables.ProcessParamsTable.tableName) if row.param == u"--num-slides")

	if len(thinca_process_ids - slides_process_ids) > 1:
		raise ValueError, "document contains more than 1 zero-lag thinca job"
	if len(slides_process_ids) > 1:
		raise ValueError, "document contains more than 1 non-zero-lag thinca job"

	#
	# get the list of analyzed instruments from the search_summary
	# table
	#

	search_summary_instruments = get_search_summary_instruments(xmldoc, thinca_process_ids)

	#
	# if a set of instruments has been provided by the user require it
	# to be a superset of the instruments named in the search_summary
	# table, either way the union of the two is the required instrument
	# list
	#

	if instruments is None:
		required_instruments = search_summary_instruments
	elif search_summary_instruments.issubset(instruments):
		required_instruments = instruments
	else:
		raise ValueError, "search_summary table named instrument(s) %s that were not named on the command line" % ", ".join(search_summary_instruments - instruments)

	#
	# identify lalapps_thinca's time slides
	#

	if not slides_process_ids:
		#
		# just zero-lag jobs.  synthesize an all-zero vector from
		# the instruments we've retrieved from the search_summary
		# table, and set num_slides to 0
		#

		offset_vector = dict((instrument, 0.0) for instrument in required_instruments)
		num_slides = 0

	else:
		#
		# construct the offset vector from the --??-slide command
		# line options, and extact num_slides from the --num-slides
		# command line option
		#

		num_slides = None
		offset_vector = {}
		slide_option_pattern = re.compile("--(?P<ifo>[a-zA-Z][0-9])-slide")

		for row in table.get_table(xmldoc, lsctables.ProcessParamsTable.tableName):
			if row.process_id in slides_process_ids:
				if row.param == u"--num-slides":
					num_slides = row.get_pyvalue()
					if num_slides < 0:
						raise ValueError, "invalid --num-slides '%s' for process '%s'" % (row.value, row.process_id)
				else:
					match = re.search(slide_option_pattern, row.param)
					if match is not None:
						offset_vector[match.groupdict()["ifo"].upper()] = row.get_pyvalue()

		#
		# confirm that the offset vector contains offsets for all
		# required instruments
		#

		if not required_instruments.issubset(set(offset_vector.keys())):
			missing_instruments = set(offset_vector.keys()) - required_instruments
			raise ValueError, "no option(s) %s in process_params table for instrument(s) %s in search_summary table" % (", ".join(["--%s-slide" % instrument.lower() for instrument in missing_instruments]), ", ".join(missing_instruments))

		#
		# if the user has provided an explicit list of instruments,
		# remove instruments from the offset vector that were not
		# named by the user
		#

		if instruments is not None:
			for instrument in set(offset_vector.keys()) - instruments:
				del offset_vector[instrument]

	#
	# build the time slide vectors for the cases when all instruments
	# are on.  these must be given time_slide IDs that match the slide
	# number component of the old-style event_id
	#

	def ids(id_class, num_slides):
		for n in range(-num_slides, +num_slides + 1):
			if n < 0:
				yield id_class(5000 - n)
			else:
				yield id_class(n)

	n = 0
	for id, offset_vector in zip(ids(type(time_slide_table.next_id), num_slides), ligolw_tisi.Inspiral_Num_Slides_Iter(num_slides, offset_vector)):
		n += 1
		for row in ligolw_tisi.RowsFromOffsetDict(offset_vector, id, process):
			time_slide_table.append(row)

	#
	# done
	#

	if verbose:
		print >>sys.stderr, "added %d time slide vectors" % n


def depopulate_time_slide_table(xmldoc, verbose = False):
	"""
	Search for and remove duplicate time slide definitions from the
	time_slide table.
	"""
	if verbose:
		print >>sys.stderr, "depopulating time_slides ...",

	#
	# find the time_slide table
	#

	time_slide_table = table.get_table(xmldoc, lsctables.TimeSlideTable.tableName)

	length_before = len(set(time_slide_table.getColumnByName("time_slide_id")))

	#
	# translate time_slide table into a dictionary, and identify
	# redundant IDs
	#
	# NOTE:  the time slide vector comparison code treats {"H1": 0,
	# "L1": 5} and {"H1": 10, "L1": 15} as identical vectors because
	# the relative offsets are identical.  in the inspiral pipeline,
	# these are potentially different time slides because one of the
	# two can result in the pair of triggers straddling a ring boundary
	# while the other does not, so a trigger pair can be coincident for
	# one of these vectors but not the other.  this should never be an
	# issue because the pipeline also has the limitation of only being
	# able to apply vectors that are all multiples of a fixed basis
	# vector --- if two instruments have the same relative offsets in
	# two vectors then they must also have the same absolute offsets in
	# those vectors, so comparing by relative offsets yields the same
	# set of redundant vectors that a comparison by absolute offsets
	# would yield.  the use of the time_slides_vacuum() function here
	# is correct, but one should keep the reason why in mind if one is
	# tempted to copy-and-paste this code elsewhere.
	#

	mapping = ligolw_tisi.time_slides_vacuum(time_slide_table.as_dict())

	#
	# remove rows corresponding to redundant IDs
	#

	for i in xrange(len(time_slide_table) - 1, -1, -1):
		if time_slide_table[i].time_slide_id in mapping:
			del time_slide_table[i]

	#
	# reassign time_slide IDs in the rest of the document
	#

	for tbl in xmldoc.getElementsByTagName(time_slide_table.tagName):
		tbl.applyKeyMapping(mapping)

	#
	# done
	#

	if verbose:
		length_after = len(set(time_slide_table.getColumnByName("time_slide_id")))
		print >>sys.stderr, "removed %d redundant time slide vectors, %d remaining" % (length_before - length_after, length_after)



#
# =============================================================================
#
#          Initialize experiment and experiment_summ tables 
#
# =============================================================================
#
		
def populate_experiment_table(xmldoc, search_group, search, lars_id, instruments, expr_start_time, expr_end_time, comments = None, verbose = False):
	"""
	Populate the experiment table using the given entries.

	@xmldoc: xmldoc to get/write table to
	@lars_id: lars_id of the experiment
	@search_group: lsc group that performed the experiment (e.g., cbc)
	@search: type of search performed (e.g., inspiral, grb, etc.)
	@expr_start_time: start time of the experiment (not of the file)
	@expr_end_time: end time of the experiment (not of the file)
	@comments: any desired comments
	@verbose: be verbose
	"""

	if verbose:
		print >> sys.stderr, "populating the Experiment Definer table..."

	# find the experiment table or create one if needed
	try:
		expr_table = table.get_table(xmldoc, lsctables.ExperimentTable.tableName)
	except ValueError:
		expr_table = xmldoc.childNodes[0].appendChild(lsctables.New(lsctables.ExperimentTable))
	
	# write entry to experiment table if it doesn't already exist
	return expr_table.write_new_expr_id( search_group, search, lars_id, instruments, expr_start_time, expr_end_time, comments = comments )


def populate_experiment_summ_table( xmldoc, experiment_id, time_slide_dict, veto_def_id, return_dict = False, verbose = False ):
	#FIXME: Add ability to write simulation entries to be able to handle injection files
	"""
	Populate the experiment_summ_table using an experiment_id, a
	veto_def_id, and a list of time_slide ids. Returns a dictionary
	representation of the updated table.

	@xmldoc: xmldoc to get/write table to
	@experiment_id: experiment_id to be added to the table.
	@veto_def_id: veto_def_id to be added to the table.
	@time_slide_dict: time_slide table as dictionary; used to set time_slide_id
	column and figure out whether or not is zero-lag. Can either be the result
	of lsctables.time_slide_table.as_dict or any dictionary having same format. 
	"""

	if verbose:
		print >> sys.stderr, "populating the Experiment Summary table..."

  # find the experiment_summary table or create one if needed
	try:
		expr_summ_table = table.get_table(xmldoc, lsctables.ExperimentSummaryTable.tableName)
	except ValueError:
		expr_summ_table = xmldoc.childNodes[0].appendChild(lsctables.New(lsctables.ExperimentSummaryTable))
	
	# populate experiment_summ table

	return expr_summ_table.write_experiment_summ_set( experiment_id, veto_def_id, time_slide_dict, return_dict = return_dict )


def generate_expr_tables_from_time_slide(xmldoc, search_group, search, lars_id, veto_def_id, expr_start_time, expr_end_time, comments = None, verbose = False):
	"""
	Creates or adds entries to the experiment table and experiment_summ
	table using the time_slide table.
	"""

	if verbose:
		print >> sys.stderr, "Populating the experiment and experiment_summary tables using the time_slide table..."

	# Get the time_slide_table as dict
	time_slide_dict = table.get_table(xmldoc, lsctables.TimeSlideTable.tableName).as_dict()
	
	# Cycle through the time_slide_ids in the time_slide table and populate the
	# expr table
	experiment_ids = {}
	for slide_id in time_slide_dict:
		# get instrument set
		instruments = set(time_slide_dict[ slide_id ].keys())

		# Add entry to expr_table if instrument set is new
		if frozenset(instruments) not in experiment_ids:
			experiment_ids[frozenset(instruments)] = populate_experiment_table(xmldoc, search_group, search, lars_id, instruments, expr_start_time, expr_end_time, comments = comments, verbose = verbose)

	# Populate experiment_summ_table
	for instruments in experiment_ids:
		populate_experiment_summ_table( xmldoc, experiment_ids[instruments], time_slide_dict, veto_def_id, return_dict = False, verbose = verbose )

		
	
#
# =============================================================================
#
#       Populate coinc_event, coinc_event_map, and coinc_inspiral Tables
#
# =============================================================================
#


#
# retrieve the ring boundaries
#


def retrieve_ring_boundaries(xmldoc):
	#
	# grab the segment list for any instrument selected at random (they
	# are all the same)
	#

	rings = llwapp.segmentlistdict_fromsearchsummary(xmldoc, program = "thinca").popitem()[1]

	#
	# because the input often contains two thinca jobs the rings might
	# be duplicated;  use set() to uniqueify them then sort them.
	#

	rings = segments.segmentlist(set(rings))
	rings.sort()

	#
	# check that the (sorted) rings are non-intersecting
	#

	for i in range(len(rings) - 1):
		if rings[i].interesects(rings[i + 1]):
			raise ValueError, "non-disjoint thinca rings detected in search_summary table"

	#
	# done
	#

	return rings


#
# For sngl_inspiral <--> sngl_inspiral coincidences
#


def populate_coinc_event_sngls(xmldoc, process, effective_snr_factor = 250.0, verbose = False):
	if verbose:
		print >>sys.stderr, "constructing coincs ...",

	#
	# retrieve the ring boundaries
	#

	rings = retrieve_ring_boundaries(xmldoc)

	#
	# get the list of analyzed instruments from the search_summary
	# table
	#

	on_instruments = get_search_summary_instruments(xmldoc, get_thinca_process_ids(xmldoc))

	#
	# find the coinc_definer_id for sngl_inspiral <--> sngl_inspiral
	# coincidences, or create it if needed
	#

	coinc_def_id = llwapp.get_coinc_def_id(xmldoc, ligolw_thinca.InspiralCoincDef.search, ligolw_thinca.InspiralCoincDef.search_coinc_type, create_new = True, description = ligolw_thinca.InspiralCoincDef.description)

	#
	# find the coinc_event table or create one if needed
	#

	try:
		coinc_event_table = table.get_table(xmldoc, lsctables.CoincTable.tableName)
	except ValueError:
		coinc_event_table = xmldoc.childNodes[0].appendChild(lsctables.New(lsctables.CoincTable))

	#
	# synchronize the coinc_event table's ID generator with any
	# pre-existing rows
	#

	coinc_event_table.sync_next_id()

	#
	# find the coinc_event_map table or create one if needed
	#

	try:
		coinc_event_map_table = table.get_table(xmldoc, lsctables.CoincMapTable.tableName)
	except ValueError:
		coinc_event_map_table = xmldoc.childNodes[0].appendChild(lsctables.New(lsctables.CoincMapTable))

	#
	# find the coinc_inspiral table or create one if needed
	#

	try:
		coinc_inspiral_table = table.get_table(xmldoc, lsctables.CoincInspiralTable.tableName)
	except ValueError:
		coinc_inspiral_table = xmldoc.childNodes[0].appendChild(lsctables.New(lsctables.CoincInspiralTable))

	#
	# find the sngl_inspiral table
	#

	try:
		sngl_inspiral_table = table.get_table(xmldoc, lsctables.SnglInspiralTable.tableName)
	except ValueError:
		# no sngl_inspiral table --> no-op
		if verbose:
			print >>sys.stderr, "cannot find sngl_inspiral table"
		return

	#
	# find the time_slide table, and convert it to a dictionary of
	# offset vectors
	#

	time_slide_table = table.get_table(xmldoc, lsctables.TimeSlideTable.tableName)
	time_slides = time_slide_table.as_dict()

	#
	# iterate over reconstructed coincs
	#

	sngl_inspiral_table.sort(lambda a, b: cmp(a.event_id, b.event_id))
	for event_id, events in itertools.groupby(sngl_inspiral_table, lambda row: row.event_id):
		#
		# alphabetize events by instrument
		#

		events = tuple(sorted(events, lambda a, b: cmp(a.ifo, b.ifo)))
		if len(events) < 2:
			# not a coincidence, just a single.  assign a new,
			# unique, event_id and continue.
			for event in events:
				event.event_id = sngl_inspiral_table.get_next_id()
			continue

		#
		# build a coinc_event
		#

		coinc = coinc_event_table.RowType()
		coinc.process_id = process.process_id
		coinc.coinc_event_id = coinc_event_table.get_next_id()
		coinc.coinc_def_id = coinc_def_id
		coinc.nevents = len(events)
		coinc.set_instruments(on_instruments)
		coinc.likelihood = None
		coinc_event_table.append(coinc)

		#
		# construct the time_slide_id from the "slide number" at
		# index 1 in the tuple returned by get_id_parts().  all
		# events in the coinc have the same ID at this stage so it
		# doesn't matter which event's ID we use.
		#

		coinc.time_slide_id = type(time_slide_table.next_id)(events[0].get_id_parts()[1])

		#
		# link events to coinc with coinc_event_map rows.  the
		# inspiral triggers are assigned new, unique, event IDs
		# here.
		#

		for event in events:
			coincmap = coinc_event_map_table.RowType()
			coincmap.coinc_event_id = coinc.coinc_event_id
			coincmap.event_id = event.event_id = sngl_inspiral_table.get_next_id()
			coincmap.table_name = coincmap.event_id.table_name
			coinc_event_map_table.append(coincmap)

		#
		# populate coinc_inspiral table with coinc summary:
		#
		# - end_time is the end time of the first trigger in
		#   alphabetical order by instrument (!?) time-shifted
		#   according to the coinc's offset vector
		# - mass is average of mtotals
		# - mchirp is average of mchirps
		# - snr is root-sum-square of SNRs
		# - false-alarm rate is blank
		#

		coinc_inspiral = lsctables.CoincInspiral()
		coinc_inspiral.coinc_event_id = coinc.coinc_event_id
		coinc_inspiral.set_ifos(str(event.ifo) for event in events)
		#coinc_inspiral.mass = sum(event.mchirp for event in events) / len(events)
		coinc_inspiral.mass = sum(event.mass1 + event.mass2 for event in events) / len(events)
		coinc_inspiral.snr = math.sqrt(sum(event.get_effective_snr(fac = effective_snr_factor)**2 for event in events))
		coinc_inspiral.false_alarm_rate = None

		#
		# the time of the coinc = the end time of the first trigger
		# in the coinc in alphabetical order by instrument
		#

		coinc_time = events[0].get_end()

		#
		# which ring is it in?
		#

		ring = rings[rings.find(coinc_time)]

		#
		# the amount by which to slide it = the offset recorded in
		# the time_slide table for the instrument from which the
		# coinc's time has been taken
		#

		offset = time_slides[coinc.time_slide_id][events[0].ifo]

		#
		# slide the coinc's time on the ring.
		#

		coinc_inspiral.set_end(SnglInspiralUtils.slideTimeOnRing(coinc_time, offset, ring))

		coinc_inspiral_table.append(coinc_inspiral)

	#
	# done
	#

	if verbose:
		print >>sys.stderr, "constructed %d coincs" % len(coinc_event_table)


#
# =============================================================================
#
#                        Depopulate sngl_inspiral Table
#
# =============================================================================
#


def depopulate_sngl_inspiral(xmldoc, verbose = False):
	if verbose:
		print >>sys.stderr, "depopulating sngl_inspirals ...",

	#
	# find the sngl_inspiral table
	#

	try:
		sngl_inspiral_table = table.get_table(xmldoc, lsctables.SnglInspiralTable.tableName)
	except ValueError:
		# no sngl_inspiral table --> no-op
		if verbose:
			print >>sys.stderr, "cannot find sngl_inspiral table"
		return

	length_before = len(sngl_inspiral_table)

	#
	# delete duplicates, recording replacement event_ids.  this relies
	# on the SnglInspiral class' __eq__() and __hash__() methods to
	# define when two triggers are the same
	#

	trigger_to_id_index = {}
	mapping = {}
	for i in xrange(len(sngl_inspiral_table) - 1, -1, -1):
		trigger = sngl_inspiral_table[i]
		if trigger in trigger_to_id_index:
			mapping[trigger.event_id] = trigger_to_id_index[trigger]
			del sngl_inspiral_table[i]
		else:
			trigger_to_id_index[trigger] = trigger.event_id

	#
	# update IDs in other tables
	#

	for tbl in xmldoc.getElementsByTagName(sngl_inspiral_table.tagName):
		tbl.applyKeyMapping(mapping)

	#
	# done
	#

	if verbose:
		print >>sys.stderr, "removed %d redundant sngl_inspiral events, %d remaining" % (length_before - len(sngl_inspiral_table), len(sngl_inspiral_table))


#
# =============================================================================
#
#                          Populate experiment_map_table
#
# =============================================================================
#

def populate_experiment_map(search_group, search, lars_id, veto_def_id, expr_start_time, expr_end_time, verbose = False):

	#
	# find the experiment_map table or create one if needed
	#
	if verbose:
		"Mapping coinc events to experiment_summary table..."

	try:
		expr_map_table = table.get_table(xmldoc, lsctables.ExperimentMapTable.tableName)
	except ValueError:
		expr_map_table = xmldoc.childNodes[0].appendChild(lsctables.New(lsctables.ExperimentMapTable))

	#
	# find the coinc_event table
	#

	coinc_event_table = table.get_table(xmldoc, lsctables.CoincTable.tableName)

	#
	# Get the time_slide_table as dict
	#

	time_slide_dict = table.get_table(xmldoc, lsctables.TimeSlideTable.tableName).as_dict()

	#
	# find the experiment table; for now, assign all coincs to the same
	# experiment ifo time (this may change later when vetoes are applied)
	#

	expr_table = table.get_table(xmldoc, lsctables.ExperimentTable.tableName)

	#
	# find the experiment_summary table
	#

	expr_summ_table = table.get_table(xmldoc, lsctables.ExperimentSummaryTable.tableName)

	#
	# cycle through the coincs in the coinc_inspiral table
	# assigning initial experiment_summ_ids
	#
	for coinc in coinc_event_table:

		#
		#  map the coinc to an experiment
		#

		expr_map = lsctables.ExperimentMap()

		expr_map.coinc_event_id = coinc.coinc_event_id

		# get the (temporary) experiment and summ id for this coinc using the
		# instruments from the time_slide_id
		instruments = set(time_slide_dict[coinc.time_slide_id].keys())
		expr_id = expr_table.get_expr_id( search_group, search, lars_id, instruments, expr_start_time, expr_end_time )
		expr_map.experiment_summ_id = expr_summ_table.get_expr_summ_id( expr_id,
			veto_def_id, coinc.time_slide_id, simulation = False )
		if expr_map.experiment_summ_id is None:
			raise ValueError, "experiment_summ_id could not be found with ids %s" \
			%(','.join([ `expr_id`, `coinc.time_slide_id`, `veto_def_id` ]))

		expr_map_table.append(expr_map)

		# Increment number of events in nevents column by 1
		expr_summ_table.add_nevents( expr_map.experiment_summ_id, 1 )



#
# =============================================================================
#
#                                 Apply Vetoes
#
# =============================================================================
#


def apply_vetoes(xmldoc, veto_segments, process, verbose = False):
	if verbose:
		print >>sys.stderr, "applying vetoes ..."

	#
	# find the tables we'll need
	#
	
	try:
		sngl_inspiral_table = table.get_table(xmldoc, lsctables.SnglInspiralTable.tableName)
	except ValueError:
		# no sngl_inspiral table --> no-op
		if verbose:
			print >>sys.stderr, "\tcannot find sngl_inspiral table"
		return
	coinc_table = table.get_table(xmldoc, lsctables.CoincTable.tableName)
	coinc_map_table = table.get_table(xmldoc, lsctables.CoincMapTable.tableName)
	coinc_inspiral_table = table.get_table(xmldoc, lsctables.CoincInspiralTable.tableName)
	time_slide_table = table.get_table(xmldoc, lsctables.TimeSlideTable.tableName)
	expr_table = table.get_table(xmldoc, lsctables.ExperimentTable.tableName)
	expr_summ_table = table.get_table(xmldoc, lsctables.ExperimentSummaryTable.tableName)
	expr_map_table = table.get_table(xmldoc, lsctables.ExperimentMapTable.tableName)

	#
	# turn the time slide table into a dictionary
	#

	if verbose:
		print >>sys.stderr, "\tindexing time_slide table and computing segment lists ..."
	time_slides = time_slide_table.as_dict()

	#
	# retrieve the ring boundaries
	#

	rings = retrieve_ring_boundaries(xmldoc)

	#
	# performance assist:  remove veto segments that don't fall in any
	# of the rings, then remove veto segment lists that are empty
	#

	coalesced_rings = segments.segmentlist(rings).coalesce()
	veto_segments = segments.segmentlistdict((instrument, seglist & coalesced_rings) for (instrument, seglist) in veto_segments.items() if seglist.intersects(coalesced_rings))
	if not veto_segments:
		if verbose:
			print >>sys.stderr, "\tno vetos were on during the times spanned by this document"
		return

	#
	# create the coinc_event_id --> sngl_inspiral index, and
	# coinc_event_id --> coinc_inspiral index
	#

	if verbose:
		print >>sys.stderr, "\tindexing coinc tables ..."
	index = dict((row.event_id, row) for row in sngl_inspiral_table)

	coinc_map_table.sort(lambda a, b: cmp(a.coinc_event_id, b.coinc_event_id))
	index = dict(
		(coinc_event_id, tuple(index[row.event_id] for row in rows))
		for coinc_event_id, rows in itertools.groupby(
			(row for row in coinc_map_table if row.table_name == "sngl_inspiral"),
			lambda row: row.coinc_event_id
		)
	)

	coinc_inspirals = dict((row.coinc_event_id, row) for row in coinc_inspiral_table)

	#
	# create an experiment_id --> experiment index, 
	# an experiment_summ_id --> experiment_summ index,
	# and a coinc_event_id --> experiment_map index
	#
	if verbose:
		print >> sys.stderr, "\tindexing experiment tables..."
		# set-up a dictionary to keep track of number of coincs moved to different times
		moved_coincs = {}
	experiment_index = dict((row.experiment_id, row) for row in expr_table)
	experiment_summ_index = dict((row.experiment_summ_id, row) for row in expr_summ_table)
	experiment_map_index = dict((row.coinc_event_id, row) for row in expr_map_table)

	#
	# iterate over coincs
	#

	if verbose:
		print >>sys.stderr, "\tchecking for coincs during vetoed times ..."

	cached_vetoes = {}
	N = len(coinc_table) / 1000 or 1

	for n, coinc_event in enumerate(coinc_table):
		if verbose and not (n % N):
			print >>sys.stderr, "\t\t%.1f%%\r" % (100.0 * n / len(coinc_table)),

		if coinc_event.coinc_event_id not in index:
			#
			# not a coinc we care about
			#

			continue

		#
		# retrieve the time slide vector
		#

		offset_vector = time_slides[coinc_event.time_slide_id]

		#
		# compare the instruments participating in the coinc to the
		# instruments named in the time slide vector
		#

		expected_instruments = set(offset_vector.keys())
		found_instruments = set(event.ifo for event in index[coinc_event.coinc_event_id])

		if found_instruments == expected_instruments:
			#
			# all instruments contributed to this coinc:
			# nothing more to check
			#

			continue

		if not found_instruments.issubset(expected_instruments):
			raise ValueError, "coinc '%s' has instrument(s) %s that are not in time slide vector '%s' (%s)" % (coinc_event.coinc_event_id, ", ".join(found_instruments - expected_instruments), coinc_event.time_slide_id, ", ".join(["%s=%g" % item for item in offset_vector.items()]))

		#
		# if we get here, the time shift vector names instruments
		# that did not particicpate in the coinc.  check to see
		# which instruments were on at the time
		#

		#
		# the slid time of the coinc
		#

		coinc_time = coinc_inspirals[coinc_event.coinc_event_id].get_end()

		#
		# which ring is it in?  note:  although the time recorded
		# for the coinc is its time after offsets are applied to
		# triggers, that time is always in the same ring as the
		# original time of the trigger from which the coinc's time
		# has been taken
		#

		ring = rings[rings.find(coinc_time)]

		#
		# slide the veto segments on that ring, cache the results
		# to avoid recalculation
		#

		try:
			vetoes = cached_vetoes[(ring, coinc_event.time_slide_id)]
		except KeyError:
			vetoes = cached_vetoes[(ring, coinc_event.time_slide_id)] = SnglInspiralUtils.slideSegListDictOnRing(ring, veto_segments, offset_vector)

		#
		# set the coinc's instruments to just those that were on at
		# the time of the coinc.  note that because the assignment
		# of a single time to a coinc is a poorly-defined
		# procedure, it can come to pass that a coinc is said to
		# have occured at a time when the instruments that
		# participate in it are vetoed.  we sweep this under the
		# rug by adding to the list of instruments that are on at
		# least those that participated in the coinc.
		# the time of the coinc
		#

		on_instruments = set(instrument for instrument in offset_vector.keys() if instrument not in vetoes or coinc_time not in vetoes[instrument])
		coinc_event.set_instruments(on_instruments | found_instruments)

		# the following re-sets the detectors column in the experiment summary table,
		# if needed

		if not found_instruments.issubset(on_instruments):
			raise ValueError, "coinc '%s' has instrument(s) %s that were off or vetoed at the slid coinc time %s" % (coinc_event.coinc_event_id, ", ".join(found_instruments - on_instruments), str(coinc_time))
		
		# check if on_instruments matches instruments listed in experiment table
		# for this coinc
		current_esid = experiment_map_index[coinc_event.coinc_event_id].experiment_summ_id
		current_eid = experiment_summ_index[current_esid].experiment_id
		current_inst = lsctables.instrument_set_from_ifos(experiment_index[current_eid].instruments)
		if current_inst != on_instruments:
			# create new entry in experiment table
			use_current = experiment_index[current_eid]
			new_eid = expr_table.write_new_expr_id(use_current.search_group, use_current.search, use_current.lars_id, on_instruments, use_current.gps_start_time, use_current.gps_end_time, comments = use_current.comments)
			# update experiment index
			experiment_index.update((row.experiment_id, row) for row in expr_table)
			# check if the new_eid is in the experiment_summ table; if so
			# use the associated esid as the coinc's new esid
			use_current = experiment_summ_index[current_esid]
			new_esid = expr_summ_table.get_expr_summ_id( new_eid, use_current.veto_def_id, use_current.time_slide_id, simulation = False ) 
			if not new_esid: # experiment_summary set doesn't exist; create new
				expr_summ_table.write_experiment_summ_set( new_eid, use_current.veto_def_id, time_slides )
				new_esid = expr_summ_table.get_expr_summ_id( new_eid, use_current.veto_def_id, use_current.time_slide_id, simulation = False)
			# update experiment_map table
			for row in expr_map_table:
				if row.coinc_event_id == coinc_event.coinc_event_id:
					row.experiment_summ_id = new_esid
					break
			# update number of events in experiment_summary table
			expr_summ_table.add_nevents( current_esid, -1 )
			expr_summ_table.add_nevents( new_esid, 1 )
			# update experiment_summ index
			experiment_summ_index.update((row.experiment_summ_id, row) for row in expr_summ_table)
			# if verbose update moved_coincs
			if verbose:
				on_instr = lsctables.ifos_from_instrument_set(on_instruments)
			if verbose and experiment_index[current_eid].instruments not in moved_coincs:
				moved_coincs[experiment_index[current_eid].instruments] = {}
			if verbose and on_instr not in moved_coincs[experiment_index[current_eid].instruments]:
				moved_coincs[experiment_index[current_eid].instruments][on_instr] = 0
			if verbose:
				moved_coincs[experiment_index[current_eid].instruments][on_instr] += 1 


	if verbose:
		print >>sys.stderr, "\t\t100.0%"
		for old_instruments in moved_coincs:
			for new_instruments in moved_coincs[old_instruments]:
				print >> sys.stderr, "\tMoved %i coinc(s) from %s time to %s time." %(moved_coincs[old_instruments][new_instruments], old_instruments, new_instruments)

#
# =============================================================================
#
#                                 Compute Durations
#
# =============================================================================
#


def compute_durations( xmldoc, veto_segments, process, verbose = False):
	"""
	Computes livetime for each element in the experiment_summary table 
	using SngInspiralUtils.compute_thinca_livetime and writes the result
	to the duration column.
	"""

	if options.verbose:
		print >> sys.stderr, "Computing durations for each experiment in the experiment_summary table..."

	#
	# find the tables we'll need
	#

	time_slide_table = table.get_table(xmldoc, lsctables.TimeSlideTable.tableName)
	expr_table = table.get_table(xmldoc, lsctables.ExperimentTable.tableName)
	expr_summ_table = table.get_table(xmldoc, lsctables.ExperimentSummaryTable.tableName)

	#
	# turn the time slide table into a dictionary
	#

	time_slide_dict = time_slide_table.as_dict()


	#
	# retrieve the ring boundaries
	#

	rings = retrieve_ring_boundaries(xmldoc)

	#
	# performance assist:  remove veto segments that don't fall in any
	# of the rings, then remove veto segment lists that are empty
	#

	coalesced_rings = segments.segmentlist(rings).coalesce()
	veto_segments = segments.segmentlistdict((instrument, seglist & coalesced_rings) for (instrument, seglist) in veto_segments.items() if seglist.intersects(coalesced_rings))

	#
	# cycle through experiments in the experiment_summ table 
	# calculating the duration for each
	#

	for row in expr_summ_table:
		on_instruments = lsctables.instrument_set_from_ifos(expr_table.get_row_from_id(row.experiment_id).instruments)
		off_instruments = set(ifo for ifo in time_slide_dict[ row.time_slide_id ]) - on_instruments
		row.duration = SnglInspiralUtils.compute_thinca_livetime( on_instruments, off_instruments, rings, veto_segments, [time_slide_dict[row.time_slide_id]] )
		


#
# =============================================================================
#
#                                     Main
#
# =============================================================================
#


options, url_categories = parse_command_line()

if options.veto_segments:
	veto_segments = ligolw_segments.segmenttable_get_by_name(utils.load_filename(options.veto_segments, gz = (options.veto_segments or "stdin").endswith(".gz"), verbose = options.verbose), options.veto_segments_name).coalesce()


for (tag, veto_category), url_pairs in url_categories.items():
	output_template = "%s%s%s_%%0%dd.xml.gz" % (options.output_prefix, tag and ("_%s" % tag) or "", veto_category and ("_CAT_%s" % veto_category) or "", int(math.floor(math.log10(len(url_pairs) or 1) + 1)))
	for n, url_pair in enumerate(url_pairs):
		lsctables.SnglInspiralTable.next_id = None
		xmldoc = ligolw_add.ligolw_add(ligolw.Document(), [url for url in url_pair if url], verbose = options.verbose)
		lsctables.SnglInspiralTable.next_id = lsctables.SnglInspiralID(0)

		process = initialize_process(xmldoc)
		set_process_params(xmldoc, process, options)

		add_missing_id_columns(xmldoc, verbose = options.verbose)
		# FIXME:  uncomment this after Kipp talks people into it.
		#fix_ifos_columns(xmldoc, verbose = options.verbose)

		populate_thinca_time_slide_table(xmldoc, process, instruments = options.instruments, verbose = options.verbose)

		# set variables for experiment tables
		#FIXME: should search_group and search be command line set? comments?
		search_group = "cbc"
		search = "inspiral"

		#FIXME: Need to come up with a method to get the appropiate lars_id and veto_def_id when
		# they become available
		lars_id = None
		veto_def_id = None

		# write non-injection entries to experiment tables
		#FIXME: how to handle injection files?
		generate_expr_tables_from_time_slide(xmldoc, search_group, search, lars_id, veto_def_id, options.experiment_start_time, options.experiment_end_time, comments = None, verbose = options.verbose)

		populate_coinc_event_sngls(xmldoc, process, effective_snr_factor = options.effective_snr_factor, verbose = options.verbose)

		depopulate_sngl_inspiral(xmldoc, verbose = options.verbose)

		populate_experiment_map(search_group, search, lars_id, veto_def_id, options.experiment_start_time, options.experiment_end_time, verbose = options.verbose)

		if options.veto_segments:
			apply_vetoes(xmldoc, veto_segments, process, verbose = options.verbose)
		elif options.verbose:
			print >>sys.stderr, "no vetoes applied"

		compute_durations( xmldoc, veto_segments, process, verbose = options.verbose)

		depopulate_time_slide_table(xmldoc, verbose = options.verbose)

		llwapp.set_process_end_time(process)

		output = output_template % n
		utils.write_filename(xmldoc, output, verbose = options.verbose, gz = (output or "stdout").endswith(".gz"))
