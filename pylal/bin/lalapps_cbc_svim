#!/usr/bin/python

import scipy
from scipy import interpolate
import numpy
from math import *

try:
  import sqlite3
except ImportError:
  # pre 2.5.x
  from pysqlite2 import dbapi2 as sqlite3

import os
import sys
import copy
from optparse import OptionParser

from glue import segments
from glue.ligolw import ligolw
from glue.ligolw import lsctables
from glue.ligolw import dbtables
from glue.ligolw import utils
from glue.ligolw import table
from glue.ligolw import array
from glue import segmentsUtils
from glue import lal
from glue import iterutils

from pylal import db_thinca_rings
from pylal import llwapp
from pylal import rate
from pylal import SimInspiralUtils
from pylal.xlal.datatypes.ligotimegps import LIGOTimeGPS

from pylal import git_version
__author__ = "Stephen Privitera <sprivite@caltech.edu>"
__version__ = "git id %s" % git_version.id
__date__ = git_version.date

lsctables.LIGOTimeGPS = LIGOTimeGPS


# FIXME this should come from a constants package
# Astronomers use Julian year
secs_in_year = 31557600.0


def edges(bins):
  """Get the boundary points of a rate.NDBins object."""
  return tuple( numpy.concatenate((l,u[-1:])) for l,u in zip(bins.lower(),bins.upper()) )

def total_mass(m1,m2):
  return numpy.array(m1)+numpy.array(m2)

def chirp_mass(m1,m2):
  m1 = numpy.array(m1)
  m2 = numpy.array(m2)
  mu = (m1*m2)/(m1+m2)
  mtotal = m1+m2
  return mu**(3./5) *mtotal**(2./5)

class upper_limit(object):
  """
  The upper_limit class organizes the calculation of the sensitive search volume
  for a search described by the input database.
  """
  def __init__(self, database, opts):
    ## Instance variables ######################################
    self.fname = database
    self.opts = opts
    self.gw = None
    self.wnfunc = None
    ############################################################

    if opts.verbose: print >> sys.stdout, "Gathering stats from: %s...." % (self.fname,)

    # seed the RNG to make output predictably random
    if opts.bootstrap_seed is not None:
      scipy.random.seed(seed=opts.bootstrap_seed)

    # open a connection to the input database
    working_filename = dbtables.get_connection_filename(self.fname, tmp_path=opts.tmp_space, verbose = opts.verbose)
    connection = sqlite3.connect(working_filename)
    dbtables.DBTable_set_connection(connection)
    xmldoc = dbtables.get_xml(connection)

    # figure out which instrument sets to use
    self.get_instruments(connection)      #find out which instruments were on at all during search
    self.set_instruments_to_calculate()   #figure out which instrument sets the user wants us to use

    # take care of binning
    self.get_total_mass_bins(connection)  #determine the total mass ranges and binning for this calculation
    self.get_m1m2_mass_bins(connection)   #determine the component mass ranges and binning for this calculation
    self.get_chirp_mass_bins()            #determine the chirp mass ranges and binning for this calculation
    self.get_bns_bbh_bins()               #set up BNS,BBH, and BHNS bins
    self.set_bins_to_calculate()          #figure out which mass bins the user wants us to use

    # get the rest of the goodies
    self.get_livetime(connection)         #get the livetime for each set of instruments
    self.get_segments(connection)         #get single ifo segments with vetoes applied
    self.get_zero_lag_segments()          #make coincident ifo segments from single ifo segments
    self.get_far_thresholds(connection)   #determine FAR to use for computing search volume
    self.get_gps_times_duration(connection)
    self.get_distance_bins()    #determine the distance bins to use for integration

    # close db connection
    connection.commit()
    dbtables.discard_connection_filename(self.fname, working_filename, verbose = opts.verbose)
    dbtables.DBTable_set_connection(None)


  def get_instruments(self, connection):
    '''Retrieve the sets of instruments which were on during this search.'''
    # FIXME bad to hardcode search_coinc_type
    self.sngl_sngl_coinc_def_id, = connection.cursor().execute("SELECT coinc_def_id FROM coinc_definer WHERE search == 'inspiral' AND search_coinc_type == 0;").fetchone()
    instruments_query = """
    SELECT DISTINCT(instruments) FROM coinc_event WHERE coinc_def_id == ?;
    """

    if self.opts.verbose:
      print >>sys.stdout,"\nQuerying database for on instruments..."
      print >>sys.stdout,"\t" + instruments_query.replace('?',self.sngl_sngl_coinc_def_id)

    self.instruments = []
    for instruments in connection.cursor().execute(instruments_query, (self.sngl_sngl_coinc_def_id,) ):
      inst =  frozenset(lsctables.instrument_set_from_ifos(instruments[0]))
      self.instruments.append(inst)
      if self.opts.verbose: print >>sys.stdout,"\t%s" % instruments[0]

    return self.instruments


  def get_livetime(self,connection):
    livetime_query = """
    SELECT instruments,duration
    FROM experiment_summary
    JOIN experiment ON experiment_summary.experiment_id == experiment.experiment_id
    WHERE experiment_summary.datatype == "exclude_play";
    """
    if self.opts.verbose:
      print >>sys.stdout,"\nQuerying database for livetimes..."
      print >>sys.stdout,"\t" + livetime_query

    self.livetime = dict( (inst,0) for inst in self.instruments )
    for instruments,livetime in connection.cursor().execute(livetime_query):
      inst =  frozenset(lsctables.instrument_set_from_ifos(instruments))
      self.livetime[inst] = livetime
      if self.opts.verbose:
        print >>sys.stdout,"\t%s were on for %g seconds (excludes playground)" % (instruments,livetime)

    return self.livetime


  def get_segments(self, connection):
    '''Retrieve raw single IFO segments from the database and apply vetoes.'''
    if self.opts.verbose: print >>sys.stdout,"\nQuerying database for single IFO zero lag segments..."
    self.segments = db_thinca_rings.get_thinca_zero_lag_segments(connection, program_name = self.opts.live_time_program)  #Get raw zero lag segments

    if self.opts.verbose:
      for ifo in self.segments:
        print "\t%s was on for %g seconds" % (ifo,abs(self.segments[ifo]))

    if self.opts.verbose: print >>sys.stdout,"\nApplying vetoes to single IFO zero lag segments..."

    if self.opts.veto_segments_name is None:
      veto_segments = segments.segmentlistdict()
    else:
      #FIXME super hack to work around missing NS column in veto definer
      try:
        veto_segments = db_thinca_rings.get_veto_segments(connection, self.opts.veto_segments_name)
      except AttributeError:
        # will get an AttributeError if using newer format veto segment file because
        # the new format does not include _ns; if so, remove the _ns columns from the
        # segment table and reset the definitions of lsctables.Segment.get and lsctables.Segment.set
        from glue.lal import LIGOTimeGPS
        del lsctables.SegmentTable.validcolumns['start_time_ns']
        del lsctables.SegmentTable.validcolumns['end_time_ns']
        def get_segment(self):
          return segments.segment(LIGOTimeGPS(self.start_time, 0), LIGOTimeGPS(self.end_time, 0))
        def set_segment(self, segment):
          self.start_time = segment[0].seconds
          self.end_time = segment[1].seconds
        lsctables.Segment.get = get_segment
        lsctables.Segment.set = set_segment
        veto_segments = db_thinca_rings.get_veto_segments(connection, self.opts.veto_segments_name)

    self.segments -= veto_segments

    if self.opts.verbose:
      for ifo in self.segments:
        print "\t%s was on for %g seconds (after vetoes)" % (ifo,abs(self.segments[ifo]))

    return self.segments


  def get_zero_lag_segments(self):
    '''Compute multi-ifo (coincident) segment list from single ifo segments.'''
    if self.opts.verbose: print >>sys.stdout,"\nForming coincident segments from single IFO segments..."

    self.zero_lag_segments = dict( (inst,0) for inst in self.instruments )
    for inst in self.instruments:
      self.zero_lag_segments[inst] = self.segments.intersection(inst) - self.segments.union(set(self.segments.keys()) - inst)
      if self.opts.verbose:
        print >>sys.stdout,"\t%s were on for %g seconds (includes playground)" % (','.join(sorted(list(inst))),abs(self.zero_lag_segments[inst]))

      # FIXME need to reomove playground from segments!!!
      self.zero_lag_segments[inst] -= segmentsUtils.S2playground(self.zero_lag_segments[inst].extent())
      # FIXME need to reomove playground from segments!!!

    return self.zero_lag_segments


  def get_distance_bins(self):
    '''Determine distance bins to use for the calculation.'''
    self.dmin = float('inf')
    self.dmax = 0
    for instr in self.instruments:
      f,m = self.get_injections(instr,0)
      self.dmin = numpy.min([ self.dmin, numpy.min([j.distance for j in m]) ])
      self.dmax = numpy.max([ self.dmax, numpy.max([j.distance for j in m]) ])

    self.dbins = rate.LogarithmicBins(0.99*self.dmin,1.01*self.dmax, int(self.opts.dist_bins))
    return self.dbins


  def get_total_mass_bins(self, connection):
    '''Find the total mass range for the search and generate one dimensional mass bins for this range.'''
    if self.opts.verbose: print >>sys.stdout,"\nFinding the range of injected total masses..."

    #FIXME assumes certain inspinj command lines were run.  probably a good idea but I don't know
    self.mintotal = float(connection.cursor().execute('SELECT MIN(CAST(value as REAL)) FROM process_params JOIN process on process_params.process_id = process.process_id WHERE process.program = "inspinj" AND param == "--min-mtotal"').fetchone()[0])
    if self.opts.max_mtotal:
      self.maxtotal = self.opts.max_mtotal
    else:
      self.maxtotal = float(connection.cursor().execute('SELECT MAX(CAST(value as REAL)) FROM process_params JOIN process on process_params.process_id = process.process_id WHERE process.program = "inspinj" AND param == "--max-mtotal"').fetchone()[0])

    if self.opts.verbose:
       print >>sys.stdout,"\tminimum total: %g solar masses" % self.mintotal
       print >>sys.stdout,"\tmaximum total: %g solar masses" % self.maxtotal

    self.total_mass_bins = rate.NDBins((rate.LinearBins(self.mintotal,self.maxtotal,self.opts.mass_bins),))

    return self.total_mass_bins


  def get_m1m2_mass_bins(self, connection):
    '''Find the component mass range for the search and generate two dimensional mass bins for this range.'''
    if self.opts.verbose: print >>sys.stdout,"\nFinding the range of injected component masses..."

    minmass1 = float(connection.cursor().execute('SELECT MIN(CAST(value as REAL)) FROM process_params JOIN process on process_params.process_id = process.process_id WHERE process.program = "inspinj" AND param == "--min-mass1"').fetchone()[0])
    minmass2 = float(connection.cursor().execute('SELECT MIN(CAST(value as REAL)) FROM process_params JOIN process on process_params.process_id = process.process_id WHERE process.program = "inspinj" AND param == "--min-mass2"').fetchone()[0])
    maxmass1 = float(connection.cursor().execute('SELECT MAX(CAST(value as REAL)) FROM process_params JOIN process on process_params.process_id = process.process_id WHERE process.program = "inspinj" AND param == "--max-mass1"').fetchone()[0])
    maxmass2 = float(connection.cursor().execute('SELECT MAX(CAST(value as REAL)) FROM process_params JOIN process on process_params.process_id = process.process_id WHERE process.program = "inspinj" AND param == "--max-mass2"').fetchone()[0])

    self.minmass = min(minmass1,minmass2)
    self.maxmass = max(maxmass1,maxmass2)

    if self.opts.verbose:
       print >>sys.stdout,"\tminimum component: %g solar masses" % self.minmass
       print >>sys.stdout,"\tmaximum component: %g solar masses" % self.maxmass

    mass1Bin = rate.LinearBins(self.minmass,self.maxmass,self.opts.mass_bins)
    maxm2 = numpy.min(mass1Bin.upper()[mass1Bin.upper() > self.maxtotal/2]) # just to make plots prettier
    m2bins = int(self.opts.mass_bins/2) + numpy.mod(self.opts.mass_bins,2) # ensures equal bin width in m2 as in m1
    mass2Bin = rate.LinearBins(self.minmass,maxm2,m2bins)

    self.m1m2_mass_bins = rate.NDBins( (mass1Bin,mass2Bin) )

    return self.m1m2_mass_bins


  def get_chirp_mass_bins(self):
    min_mchirp = numpy.min(chirp_mass(self.minmass,self.mintotal-self.minmass))
    max_mchirp = numpy.max(chirp_mass(self.maxtotal/2,self.maxtotal/2))

    if self.opts.verbose:
       print >>sys.stdout,"\tminimum chirp mass: %g solar masses" % min_mchirp
       print >>sys.stdout,"\tmaximum chirp mass: %g solar masses" % max_mchirp

    self.chirp_mass_bins = rate.NDBins((rate.LinearBins(min_mchirp,max_mchirp,self.opts.mass_bins),))

    return self.chirp_mass_bins


  def get_bns_bbh_bins(self):
    """Set up bins for BNS/BBH/NSBH systems:
     BNS 1.35 pm 0.04 msun
     BBH 5.0 pm 1.0 msun
     NSBH 1.35 pm 0.04 - 5.0 pm 1.0 msun
    """
    binEdges = [self.minmass,1.31,1.39,4.00,6.00,self.maxmass]
    self.bns_bbh_bins = rate.NDBins((rate.IrregularBins(binEdges),rate.IrregularBins(binEdges)))
    return self.bns_bbh_bins

  def set_bins_to_calculate(self):
    self.mass_bins = {}
    if opts.bin_by_total_mass: self.mass_bins["Total_Mass"] = self.total_mass_bins
    if opts.bin_by_chirp_mass: self.mass_bins["Chirp_Mass"] = self.chirp_mass_bins
    if opts.bin_by_m1m2: self.mass_bins["Mass1_Mass2"] = self.m1m2_mass_bins
    if opts.bin_by_bns_bbh: self.mass_bins["BNS_BBH"] = self.bns_bbh_bins
    return self.mass_bins

  def get_far_thresholds(self, connection):
    """Returns the false alarm rate to use for computing the search volume (in the typical case, this will
    be the FAR of the most rare zero-lag coinc)."""
    if self.opts.verbose: print >>sys.stdout, "\nGetting FAR thresholds for the loudest event..."

    self.far = dict( (inst,-1) for inst in self.instruments )

    if self.opts.use_expected_loudest_event:
      for inst in self.instruments:
        self.far[inst] = 1./self.livetime[inst]
    elif self.opts.far:
      for inst in self.instruments:
        self.far[inst] = self.opts.far
    else:
      far_threshold_query = """
      SELECT coinc_event.instruments,MIN(combined_far)
      FROM coinc_inspiral
      JOIN coinc_event ON (coinc_inspiral.coinc_event_id == coinc_event.coinc_event_id)
      JOIN experiment_map ON (coinc_event.coinc_event_id == experiment_map.coinc_event_id)
      JOIN experiment_summary ON ( experiment_summary.experiment_summ_id == experiment_map.experiment_summ_id)
      WHERE experiment_summary.datatype == "exclude_play"
      GROUP BY coinc_event.instruments;
      """
      if self.opts.verbose: print >>sys.stdout,"\t"+far_threshold_query

      for inst, far in connection.cursor().execute(far_threshold_query):
        inst = frozenset(lsctables.instrument_set_from_ifos(inst))
        self.far[inst] = far # handle FAR = 0 case specially downstream

    if self.opts.verbose:
      for inst in self.instruments:
        print >>sys.stdout,"\tloudest event in %s time has FAR = %g" % (','.join(sorted(list(inst))),self.far[inst])

    return self.far


  def get_gps_times_duration(self, connection):
    self.start_time = int( connection.cursor().execute('SELECT MIN(gps_start_time) FROM experiment').fetchone()[0] )
    self.end_time = int( connection.cursor().execute('SELECT MAX(gps_end_time) FROM experiment').fetchone()[0] )
    return True


  def set_instruments_to_calculate(self):
    if not opts.instruments: return self.instruments
    if opts.instruments in self.instruments:
      self.instruments = [opts.instruments]
    else:
      print >> sys.stderr, "Instruments %s do not exist in DB, nothing will be calculated" % (str(opts.instruments))
      self.instruments = []

    return self.instruments

  def get_volume_derivative(self,instruments,bin_type):
    """
    Compute the derivative of the search volume at the FAR of the loudest event
    """
    if self.opts.verbose:
      print >>sys.stdout, "\nCalculating volume derivative at FAR %g for %s, binning by %s" % (UL.far[instruments],",".join(sorted(list(instruments))),bin_type)

    mass_bins = self.mass_bins[bin_type]

    FAR = self.far[instruments]
    gw = self.gw

    # If the loudest event has 0-FAR, then there is no volume above that event.
    # We return zeros for the volume arrays.
    if FAR == 0:
      return rate.BinnedArray(mass_bins)

    #determine binning up front for infinite FAR
    found, missed = self.get_injections(instruments, FAR=float("inf"))
    dbin = rate.LogarithmicBins(min([l.distance for l in found]),max([l.distance for l in found]), int(self.opts.dist_bins))

    livetime = float(abs(self.zero_lag_segments[instruments]))/secs_in_year

    FARh = FAR*100000
    FARl = FAR*0.001
    nbins = 5
    FARS = rate.LogarithmicBins(FARl, FARh, nbins)
    vA = []

    for far in FARS.centres():
      vAt, vA2t, fm = self.twoD_SearchVolume(instruments,bin_type,dbin_in=dbin,FAR=far,bootnum=1)
      # we need to compute derivitive of log according to ul paper
      vAt.array = scipy.log10(vAt.array + 0.001)
      vA.append(vAt)

    # the derivitive is calcuated with respect to FAR * t
    FARTS = rate.LogarithmicBins(FARl * livetime, FARh * livetime, nbins)
    volDeriv = self._derivitave_fit(FARTS, FAR * livetime, vA, mass_bins)

    if self.opts.verbose:
      dim = len(mass_bins)
      if dim == 1:
        print >>sys.stdout,"\t\t%s (Msun)\tLambda" % bin_type
        for m_low,m_high in zip(mass_bins.lower()[0],mass_bins.upper()[0]):
          print >>sys.stdout,"\t\t%.2f-%.2f\t%f" % (m_low,m_high, volDeriv[(m_low,)])
      if dim == 2:
        print >>sys.stdout,"\t\tM1 (Msun)\tM2 (Msun)\tLambda"
        for m1_low,m1_high in zip(mass_bins.lower()[0],mass_bins.upper()[0]):
          for m2_low,m2_high in zip(mass_bins.lower()[1],mass_bins.upper()[1]):
            if m1_low<=m2_low and m1_low+m2_low<self.maxtotal and m1_high+m2_high>self.mintotal:
              print >>sys.stdout,"\t\t%.2f-%.2f\t%.2f-%.2f\t%f" % (m1_low,m1_high,m2_low,m2_high,volDeriv[(m1_low,m2_low)])

    return volDeriv


  def _derivitave_fit(self,farts, FARt, vAs, mass_bins):
    '''
    Relies on scipy spline fits for each mass bin to find the derivitave of the
    volume at a given FAR.  See how this works for a simple case where
    I am clearly giving it a parabola.  To high precision it calculates
    the proper derivitave.
    >>> A = [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]
    >>> B = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    >>> C = interpolate.splrep(B,A,s=0, k=4)
    >>> interpolate.splev(5,C,der=1)
    10.000
    '''
    dA = rate.BinnedArray(mass_bins)

    dim = len(mass_bins) # only possible for dim to be 1 or 2
    if dim == 1:
      for m in mass_bins.centres()[0]:
          da = [ vAs[farts[f]][(m,)] for f in farts.centres() ]
          fit = interpolate.splrep(farts.centres(),da,k=4)
          val = interpolate.splev(FARt,fit,der=1)
          # FIXME this prevents negative derivitives arising from bad fits
          if val < 0: val = 0
          dA[(m,)] = val # minus the derivitave
    else:
      for m1 in range(dA.array.shape[0]):
        for m2 in range(dA.array.shape[1]):
          da = []
          for f in farts.centres():
            da.append(vAs[farts[f]].array[m1][m2])
          fit = interpolate.splrep(farts.centres(),da,k=4)
          val = interpolate.splev(FARt,fit,der=1)
          # FIXME this prevents negative derivitives arising from bad fits
          if val < 0: val = 0
          dA.array[m1][m2] = val # minus the derivitave

    return dA

  def filter_injection(self,sim):
    if sim.waveform in self.opts.exclude_sim_type:
      return True

    if not self.mintotal < sim.mass1 + sim.mass2 < self.maxtotal:
      return True

    if not self.minmass < sim.mass1 < self.maxmass:
      return True

    if not self.minmass < sim.mass2 < self.maxmass:
      return True

    return False

  def get_injections(self, instruments, FAR=None):
    """
    This method separates injections into found and missed categories. An injection which
    is coincident with two or more single inspiral triggers (sngl1<-->sim and sngl2<-->sim)
    which are themselves coincident (sngl1<-->sngl2) triggers are considered "found". An
    injection in triple time therefore is considered found if it matches any double-IFO
    coincident event. All other injections are considered "missed".
    """
    if FAR is None: FAR = self.far[instruments]

    found = []
    missed = []

    # Open a fresh connection to the database
    working_filename = dbtables.get_connection_filename(self.fname, tmp_path = self.opts.tmp_space, verbose = self.opts.verbose)
    connection = sqlite3.connect(working_filename)


    def injection_was_made(geocent_end_time, geocent_end_time_ns):
        """
        Returns True if injection end time lies within the instruments' coincident segments.
        """
        return lsctables.LIGOTimeGPS(geocent_end_time, geocent_end_time_ns) in self.zero_lag_segments[instruments]

    connection.create_function("injection_was_made", 2, injection_was_made)
    make_sim_inspiral = lsctables.table.get_table(dbtables.get_xml(connection), lsctables.SimInspiralTable.tableName).row_from_cols

    injection_finding_query = """
       SELECT sim_inspiral.*,
       -- true if injection matched a coinc below the false alarm rate threshold
       EXISTS (
	     SELECT *
	     FROM coinc_event_map AS mapa
	     JOIN coinc_event_map AS mapb ON ( mapa.coinc_event_id == mapb.coinc_event_id )
	     JOIN coinc_inspiral ON ( mapb.table_name == "coinc_event" AND mapb.event_id == coinc_inspiral.coinc_event_id )
	     WHERE mapa.table_name == "sim_inspiral"
	     AND mapa.event_id == sim_inspiral.simulation_id
	     AND coinc_inspiral.combined_far < ?
	     )
       FROM sim_inspiral
       WHERE
       -- only interested in injections that were injected
       injection_was_made(sim_inspiral.geocent_end_time, sim_inspiral.geocent_end_time_ns)
	 """

    for values in connection.cursor().execute(injection_finding_query,(FAR,)):
      sim = make_sim_inspiral(values)

      if self.filter_injection(sim): continue

      if values[-1]:
        found.append(sim)
      else:
        missed.append(sim)

    # close connection to database
    connection.commit()
    dbtables.discard_connection_filename(self.fname, working_filename, verbose = self.opts.verbose)
    dbtables.DBTable_set_connection(None)

    return found, missed


  def _scramble_pop(self, m, f):
    """
    A function to draw a new injection sample in the "boot strap" method
    http://en.wikipedia.org/wiki/Bootstrapping_(statistics)
    and included refereneces.
    This was used in the stack-a-flare search to get MC errors etc.
    """
    inj = m+f
    ix = scipy.random.randint(0,len(inj), (len(inj),))
    #return new missed, found
    missed = [inj[i] for i in ix if i < len(m) ]
    found = [inj[i] for i in ix if i >=len(m) ]
    return missed, found

  def _scramble_dist(self, inj, relerr, syserr):
    """
    Function to handle random calibration error.  Individually scrambles the distances
    of injections by an error assumed to be log normal + a systematic.
    """
    return numpy.array([sim.distance * (1.0-syserr) * float(scipy.exp( relerr * scipy.random.standard_normal(1))) for sim in inj])

  def live_time_array(self,instruments,mass_bins):
    """
    return an array of live times, note every bin will be the same :) it is just a
    convenience.
    """
    live_time = rate.BinnedArray(mass_bins)
    live_time.array += self.livetime[instruments]
    return live_time

  def twoD_SearchVolume(self,instruments,bin_type,dbin_in=None,FAR=None,bootnum=None,verbose=False):
    """
    Compute the search volume above the specified FAR over given mass bins.
    If bootstrapping is turned on, the injection population will be randomly
    (i) perturbed in injected distance and (ii) resampled with replacement to
    account for errors due to resp. (i) uncertain calibration and (ii) finite
    number of injections. We take the variance in the bootstrapped volume in
    as a measure of the uncertainty in the search volume (as given by the mean
    bootstrapped volume).
    """
    # get the appropriate mass bins for this calculation
    mass_bins = self.mass_bins[bin_type]

    # if no FAR specified, use the FAR of the loudest event
    if FAR is None: FAR = self.far[instruments]

    found, missed = self.get_injections(instruments, FAR)

    if verbose:
      print >>sys.stdout, "\nCalculating search volume below FAR %g for %s, binning by %s" % (FAR,",".join(sorted(list(instruments))),bin_type)

    # wnfunc is for smoothing across bins
    wnfunc = self.gw
    if wnfunc: wnfunc /= wnfunc[(wnfunc.shape[0]-1) / 2, (wnfunc.shape[1]-1) / 2]

    if bootnum is None: bootnum = self.opts.bootstrap_iterations

    # set up an empty ratio array for each distance bin
    rArrays = [rate.BinnedRatios(mass_bins) for k in range(self.opts.dist_bins)]

    # an array to hold to the found/missed statistics for the injections
    fm_array = rate.BinnedRatios(mass_bins)

    # the search volume arrays are obtained by summing some function of
    # the binned arrays in rArrays over distance
    volArray=rate.BinnedArray(mass_bins)
    volArray2=rate.BinnedArray(mass_bins)

    # Bootstrap to account for errors.
    #
    # In bootstrapping, we draw a new population of found (missed) injections
    # from the observed population of found (missed) injections, with replacement,
    # such that the total number of injections does not change. We then use this
    # scrambled population to recompute the search volume. This technique gives
    # a sense of how sensitive the calculation is to the particular set of data
    # we happened to acquire.
    for trial in range(bootnum):

      # Initialize this sum by setting the binned arrays in rArrays to zero
      for k in range(self.opts.dist_bins):
        rArrays[k].numerator.array = numpy.zeros(rArrays[k].numerator.bins.shape)
        rArrays[k].denominator.array = numpy.zeros(rArrays[k].numerator.bins.shape)

      if trial == 0: # first time through, use the observed found/missed populations
        new_found = [inj for inj in found]
        new_missed = [inj for inj in missed]

        # Adjust for systematic errors
        f_dist = self._scramble_dist(new_found, 0.0, self.opts.dist_sys_err)
        m_dist = self._scramble_dist(new_missed, 0.0, self.opts.dist_sys_err)
        if verbose:
          print >>sys.stdout, "\tcomputing observed volume for actual injection population: found = %d, missed = %d" % (len(found), len(missed))

      else: # after the first time, resample the found/missed populations (bootstrapping)
        # resample found/missed
        new_missed, new_found = self._scramble_pop(missed, found)

        if verbose:
          print >>sys.stdout, "\tbootstrapping on injection population, trial %d: found = %d, missed = %d" % (trial, len(new_found), len(new_missed))

	# randomly adjust injection distance to account for uncertainty in distance
        # I make a separate array of distances to speed up this calculation
        f_dist = self._scramble_dist(new_found, self.opts.dist_err, self.opts.dist_sys_err)
        m_dist = self._scramble_dist(new_missed, self.opts.dist_err, self.opts.dist_sys_err)

      # compute the distance bins
      if not dbin_in:
        if FAR > 0:
          dbin = rate.LogarithmicBins(0.95*min(f_dist),1.05*max(f_dist), self.opts.dist_bins) # add a little fudge to avoid min=max special case
        else:
          dbin = rate.LogarithmicBins(min(m_dist),max(m_dist), self.opts.dist_bins) # doesn't matter, the volume is zero anyway
      else: dbin = dbin_in

      # THIS IS WHERE THE CODE STARTS CARING ABOUT WHAT PARAMETERS WE ARE BINNING OVER
      if bin_type == "Mass1_Mass2" or bin_type == "BNS_BBH":
        rArrays = self.sort_into_m1m2_bins(rArrays,new_found,f_dist,new_missed,m_dist,dbin)
      if bin_type == "Total_Mass":
        rArrays = self.sort_into_1D_mass_bins(rArrays,total_mass,new_found,f_dist,new_missed,m_dist,dbin)
      if bin_type == "Chirp_Mass":
        rArrays = self.sort_into_1D_mass_bins(rArrays,chirp_mass,new_found,f_dist,new_missed,m_dist,dbin)
      # THIS IS WHERE THE CODE STOPS CARING ABOUT WHAT PARAMETERS WE ARE BINNING OVER

      if trial == 0: # store injection summary for actually observed injection results
        fm_array.numerator.array = numpy.sum(rArrays[k].numerator.array for k in range(self.opts.dist_bins))
        fm_array.denominator.array = numpy.sum(rArrays[k].denominator.array for k in range(self.opts.dist_bins))

      # If the loudest event has 0-FAR, then there is no volume above that event.
      # We return zeros for the volume arrays.
      if FAR == 0:
        return rate.BinnedArray(mass_bins),rate.BinnedArray(mass_bins), fm_array

      # check whether there are a sensible number of injections
      # FIXME this check could be cleaner
      if verbose and trial == 0:
        dim = len(mass_bins.shape)
        farray = sum(rArrays[i].numerator.array for i in range(len(rArrays)))
        if dim == 1:
          for m in mass_bins.centres()[0]:
            if farray[mass_bins[(m,)]] < 100:
              print >>sys.stderr, "WARNING: Only %d injections were found in %s time in the %.1f mass bin over all injected distances."  % (farray[mass_bins[(m,)]],''.join(sorted(list(instruments))),m)
              print >>sys.stderr, "In order to obtain an accurate upper limit, you should run with more injections."
        if dim == 2:
          for m1 in mass_bins.centres()[0]:
            for m2 in mass_bins.centres()[1]:
              if m1+m2<self.maxtotal and m1+m2>self.mintotal and m1<=m2 and farray[mass_bins[(m1,m2)]] < 100:
                print >>sys.stderr, "WARNING: Only %d injections were found in %s time in the %.1f-%.1f mass bin over all injected distances."  % (farray[mass_bins[(m1,m2)]],''.join(sorted(list(instruments))),m1,m2)
                print >>sys.stderr, "In order to obtain an accurate upper limit, you should run with more injections."

      # the ratio of the numerator to the (numerator+denominator) is equal
      # to the efficiency at that m1-m2-d bin
      tmpArray2=rate.BinnedArray(mass_bins) #start with a zero array to compute the mean square
      for k in range(self.opts.dist_bins):
        tbins = rArrays[k]
        tbins.denominator.array += tbins.numerator.array
        if wnfunc: rate.filter_array(tbins.denominator.array,wnfunc)
        if wnfunc: rate.filter_array(tbins.numerator.array,wnfunc)
        tbins.regularize()

        # integral wrt log(r), not r:
	# integral( 4pi r**2 eff(r) )dr = integral( 4pi r**3 eff(r) )dlog(r)
        integrand = 4.0 * pi * tbins.ratio() * dbin.centres()[k]**3 * dbin.delta
        volArray.array += integrand
        tmpArray2.array += integrand

      tmpArray2.array *= tmpArray2.array
      volArray2.array += tmpArray2.array

    #Mean and variance
    volArray.array /= bootnum
    volArray2.array /= bootnum
    volArray2.array -= volArray.array**2 # Variance

    if verbose:
      mean_range = (3./(4*numpy.pi) *volArray.array)**(1./3)
      error_range = (mean_range/3) *(volArray2.array**0.5/volArray.array)
      if dim == 1:
        print >>sys.stdout,"\t\t%s (Msun)\tRange (Mpc)" % bin_type
        for m_low,m_high in zip(mass_bins.lower()[0],mass_bins.upper()[0]):
          print >>sys.stdout,"\t\t%.2f-%.2f\t%.2f pm %.2f" % (m_low,m_high, mean_range[mass_bins[(m_low,)]],error_range[mass_bins[(m_low,)]])
      if dim == 2:
        print >>sys.stdout,"\t\tM1 (Msun)\tM2 (Msun)\tRange (Mpc)"
        for m1_low,m1_high in zip(mass_bins.lower()[0],mass_bins.upper()[0]):
          for m2_low,m2_high in zip(mass_bins.lower()[1],mass_bins.upper()[1]):
            if m1_low<=m2_low and m1_low+m2_low<self.maxtotal and m1_high+m2_high>self.mintotal:
              print >>sys.stdout,"\t\t%.2f-%.2f\t%.2f-%.2f\t%.2f pm %.2f" % (m1_low,m1_high,m2_low,m2_high,mean_range[mass_bins[(m1_low,m2_low)]],error_range[mass_bins[(m1_low,m2_low)]])

    volArray.array *= self.livetime[instruments]
    volArray2.array *= self.livetime[instruments]**2

    return volArray, volArray2, fm_array


  def sort_into_1D_mass_bins(self,rArrays,param_convert,found,found_dist,missed,missed_dist,dbin,quiet=True):

    f_m1 = numpy.array([l.mass1 for l in  found])
    f_m2 = numpy.array([l.mass2 for l in  found])
    m_m1 = numpy.array([l.mass1 for l in  missed])
    m_m2 = numpy.array([l.mass2 for l in  missed])

    # get rid of all missed injections outside the distance bins
    # to prevent binning errors
    m_m1, m_m2, missed_dist = self.cut_distance(m_m1, m_m2, missed_dist, dbin)
    f_m1, f_m2, found_dist = self.cut_distance(f_m1, f_m2, found_dist, dbin)

    f_mparam = param_convert(f_m1,f_m2)
    m_mparam = param_convert(m_m1,m_m2)

    # for each found injection, find the m1-m2-d bin it corresponds to
    # and increment the numerator there by one
    for i, l in enumerate(found_dist):
      tbin = rArrays[dbin[found_dist[i]]]
      tbin.incnumerator( (f_mparam[i],) )

    # for each found injection, find the m-d bin it corresponds to
    # and increment the denominator there by one
    for i, l in enumerate(missed_dist):
      tbin = rArrays[dbin[missed_dist[i]]]
      tbin.incdenominator( (m_mparam[i],) )

    return rArrays


  def sort_into_m1m2_bins(self,rArrays,found,found_dist,missed,missed_dist,dbin,quiet=True):

    f_m1 = numpy.array([l.mass1 for l in  found])
    f_m2 = numpy.array([l.mass2 for l in  found])
    m_m1 = numpy.array([l.mass1 for l in  missed])
    m_m2 = numpy.array([l.mass2 for l in  missed])

    # get rid of all missed injections outside the distance bins
    # to prevent binning errors
    m_m1, m_m2, missed_dist = self.cut_distance(m_m1, m_m2, missed_dist, dbin)
    f_m1, f_m2, found_dist = self.cut_distance(f_m1, f_m2, found_dist, dbin)

    # for each found injection, find the m1-m2-d bin it corresponds to
    # and increment the numerator there by one
    for i, l in enumerate(found_dist):
      tbin = rArrays[dbin[found_dist[i]]]
      if f_m1[i] >= f_m2[i]: # exploit m1/m2 symmetry to improve statistics
        tbin.incnumerator( (f_m1[i], f_m2[i]) )
      else:
        tbin.incnumerator( (f_m2[i], f_m1[i]) )

    # for each missed injection, find the m1-m2-d bin it corresponds to
    # and increment the denominator there by one
    for i, l in enumerate(missed_dist):
      tbin = rArrays[dbin[missed_dist[i]]]
      if m_m1[i] >= m_m2[i]: # exploit m1/m2 symmetry to improve statistics
        tbin.incdenominator( (m_m1[i], m_m2[i]) )
      else:
        tbin.incdenominator( (m_m2[i], m_m1[i]) )

    return rArrays


  def cut_distance(self, m1, m2, d, dbin):
    """
    Exclude sims outside some distance range to avoid errors when binning
    """
    mnd = min(dbin.lower())
    mxd = max(dbin.upper())
    indexes = numpy.logical_and(d <= mxd, d >= mnd)
    return m1[indexes], m2[indexes], d[indexes]


  def distance_from_4volume(self,vA,instruments):
    distance = rate.BinnedArray(vA.bins)
    distance.array = (vA.array / self.livetime[instruments] / (4.0/3.0 * pi)) **(1.0/3.0)
    return distance


def parse_command_line():
  parser = OptionParser(version = git_version.verbose_msg, usage = "%prog [options] database", description = "%prog computes the sensitive search volume as a function of mass for the search results described by the input database.")

  # These options can be used to control how much computing the program actually does.
  # Limiting the computations can be useful for parallelizing the workflow.
  parser.add_option("--bin-by-total-mass", default = False, action = "store_true", help = "Compute the search volume as a function of total mass.")
  parser.add_option("--bin-by-chirp-mass", default = False, action = "store_true", help = "Compute the search volume as a function of chirp mass.")
  parser.add_option("--bin-by-m1m2", default = False, action = "store_true", help = "Compute the search volume as a function of component masses.")
  parser.add_option("--bin-by-bns-bbh", default = False, action = "store_true", help = "Compute the search volume for BNS/BBH systems.")
  parser.add_option("--instruments", default = None, metavar = "IFO[,IFO,...]", help = "Specify the on-instruments sets for computing the search volume.  Example \"H1,L1,V1\"")

  # Control the injection population used to measure the search volume
  parser.add_option("--max-mtotal", type = "float", default = None, action = "store", help = "Specify the maximum total mass to use in the calculation.")
  parser.add_option("--exclude-sim-type", default = [], action = "append", metavar = "SIM", help = "When computing the search volume, exclude injections made using the SIM waveform family. Example: SpinTaylorthreePointFivePN. Use this option multiple times to exclude more than one injection type.")

  # These options control the volume uncertainty estimation.
  parser.add_option("--bootstrap-iterations", default = 1000, metavar = "integer", type = "int", help = "Number of bootstrap trials to use for computing the mean and variance of the search volume. A good number is 10000.")
  parser.add_option("--bootstrap-seed",default = None, metavar = "integer",type = "int", help = "Provide a seed for the bootstrap resampling. This is useful for testing code changes. Otherwise output is completely (pseudo) random!")
  parser.add_option("--dist-err", default = 0.197, metavar = "float", type = "float", help = "When bootstrapping, simulate a random calibration error on distance of the specified magnitude.")
  parser.add_option("--dist-sys-err", default = 0.074, metavar = "float", type = "float", help = "systematic calibration error on distance (should use worst)")

  # Binning options. A large number of distance bins is needed for accurate numerical integration.
  parser.add_option("--dist-bins", default = 50, metavar = "integer", type = "int", help = "Number of bins to use for integration over distance.")
  parser.add_option("--mass-bins", default = 11, metavar = "integer", type = "int", help = "Number of mass bins along 1 dimension (Note the total number of mass bins will generally be less than --mass-bins * --mass-bins once the actual parameter space is carved out)")

  # Options to control the FAR used for computing the search volume. The default behavior is to use
  # the FAR of the loudest non-playground event.
  parser.add_option("--far", help = "FAR to use for injection finding instead of loudest event.")
  parser.add_option("--use-expected-loudest-event", default=False, action = "store_true", help = "Instead of using the observed FAR for the loudest event, estimate the FAR based on livetime. This option overrides the --far option.")

  # Techincal options which the general user won't care about
  parser.add_option("--live-time-program", default = "thinca", metavar = "name", help = "Set the name of the program whose rings will be extracted from the search_summary table.  Default = \"thinca\".")
  parser.add_option("--veto-segments-name", default = "vetoes", help = "Set the name of the veto segments to use from the XML document.")
  parser.add_option("--output-name-tag", default = "", metavar = "name", help = "Set the file output name tag, real name is 2Dsearchvolume-<tag>-<ifos>.xml")
  parser.add_option("-t", "--tmp-space", metavar = "path", help = "Path to a directory suitable for use as a work area while manipulating the database file.  The database file will be worked on in this directory, and then moved to the final location when complete.  This option is intended to improve performance when running in a networked environment, where there might be a local disk with higher bandwidth than is available to the filesystem on which the final output will reside.")
  parser.add_option("--output-cache", default = None, help = "Name of output cache file. If none is specified, then no cache file will be written.")

  parser.add_option("--verbose", action = "store_true", help = "Be verbose.")

  opts, filenames = parser.parse_args()

  if opts.instruments is not None:
    opts.instruments = frozenset(lsctables.instrument_set_from_ifos(opts.instruments))

  if len(filenames) != 1:
    print >>sys.stderr, "must specify exactly one database file"
    sys.exit(1)

  if not opts.bin_by_bns_bbh and not opts.bin_by_chirp_mass and not opts.bin_by_m1m2:
    opts.bin_by_total_mass = True # choose a default binning method

  return opts, filenames[0]


############################ MAIN PROGRAM #####################################
###############################################################################
###############################################################################

opts, database = parse_command_line()

#initialize an upper limit class
UL = upper_limit(database, opts)

#create an empty cache which will store the output files/metadata
cache_list = []

#loop over the requested instruments
for instruments in UL.instruments:
  for bin_type in UL.mass_bins:

    #compute volume derivitive
    dvA = UL.get_volume_derivative(instruments,bin_type)

    #compute volume first and second moments
    vA, vA2, fm = UL.twoD_SearchVolume(instruments,bin_type,verbose=opts.verbose,dbin_in = UL.dbins)

    # convert to distance
    distance = UL.distance_from_4volume(vA,instruments)

    # FIXME convert to years (use some lal or pylal thing in the future)
    vA.array /= secs_in_year
    vA2.array /= secs_in_year * secs_in_year #two powers for this squared quantity

    # make a live time table
    ltA = UL.live_time_array(instruments,UL.mass_bins[bin_type])

    #write out the results to the xml file
    xmldoc = ligolw.Document()
    child = xmldoc.appendChild(ligolw.LIGO_LW())

    dim = len(UL.mass_bins[bin_type])
    for j in range(dim):
      xml = ligolw.LIGO_LW({u"Name": u"mass%d_bins:%s" % (j+1,bin_type)})
      xml.appendChild(array.from_array(u"array", edges(UL.mass_bins[bin_type])[j]))
      child.appendChild(xml)

    output_arrays = {"SearchVolumeFirstMoment":vA.array,
                     "SearchVolumeSecondMoment":vA2.array,
                     "SearchVolumeDerivative":dvA.array,
                     "SearchVolumeDistance":distance.array,
                     "SearchVolumeFoundInjections":fm.numerator.array,
                     "SearchVolumeMissedInjections":fm.denominator.array,
                     "SearchVolumeLiveTime":ltA.array}
    for arr in output_arrays:
      xml = ligolw.LIGO_LW({u"Name": u"binned_array:%s" % arr})
      xml.appendChild(array.from_array(u"array",output_arrays[arr]))
      child.appendChild(xml)

    output_filename = "%s-SEARCH_VOLUME-%s-BINNED_BY_%s-%d-%d.xml" % ("".join(sorted(list(instruments))),opts.output_name_tag,bin_type.upper(),UL.start_time,UL.end_time-UL.start_time)

    utils.write_filename(xmldoc, output_filename)
    cache_list.append( lal.CacheEntry( "".join(sorted(list(instruments))),
                                       bin_type,
                                       segments.segment(UL.start_time, UL.end_time),
                                       "file://localhost%s/%s" % (os.getcwd(),output_filename) ) )


# write cache file
if opts.output_cache is not None:
  fd = open( opts.output_cache, "w" )
  for l in cache_list:
    fd.write( str(l) + "\n")
  fd.close()
