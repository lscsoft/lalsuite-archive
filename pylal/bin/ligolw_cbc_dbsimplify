#!/usr/bin/env python

# ============================================================================
#
#                               Preamble
#
# ============================================================================


from optparse import OptionParser
import sqlite3
import sys
import os
import time

from glue.ligolw import lsctables
from glue.ligolw import dbtables
from glue.ligolw.utils import process
from glue import git_version

from pylal import ligolw_sqlutils as sqlutils

__prog__ = "ligolw_cbc_dbsimplify"
__author__ = "Collin Capano <cdcapano@physics.syr.edu>"

description = \
"Cleans and simplifies a database by removing redundant ids."

# ============================================================================
#
#                               Set Options
#
# ============================================================================

def parse_command_line():
    """
    Parser function dedicated
    """
    parser = OptionParser(
        version = git_version.verbose_msg,
        usage   = "%prog [options]",
        description = description
        )
    # following are related to file input and output naming
    parser.add_option( "-d", "--database", action = "store", type = "string", default = None,
        help =
            "Database to update. Must already exist."
            )
    parser.add_option( "-t", "--tmp-space", action = "store", type = "string", default = None,
        metavar = "PATH",
        help =
            "Location of local disk on which to do work. This is optional; " +
            "it is only used to enhance performance in a networked " +
            "environment. "
            )
    parser.add_option( "", "--vacuum", action = "store_true", default = False,
        help = 
            "If turned on, will vacuum the database before saving. " +
            "This cleans any fragmentation and removes empty space " +
            "left behind by all the DELETEs, making the output " +
            "database smaller and more efficient. " +
            "WARNING: Since this requires rebuilding the entire " +
            "database, this can take awhile for larger files." 
            )

    parser.add_option( "-v", "--verbose", action = "store_true", default = False,
        help =
            "Print progress information"
           )
    parser.add_option( "-D", "--debug", action = "store_true", default = False,
        help =
            "Print SQLite queries used and the approximate time taken to run each one." )

    (options, args) = parser.parse_args()
    # check for required options and for self-consistency
    if not options.database:
        raise ValueError, "No database specified."

    return options, sys.argv[1:]


# =============================================================================
#
#                                     Main
#
# =============================================================================

opts, args = parse_command_line()

# get input database filename
filename = opts.database
if not os.path.isfile( filename ):
    raise ValueError, "The input file, %s, cannot be found." % filename

# Setup working databases and connections
if opts.verbose: 
    print >> sys.stdout, "Creating a database connection..."
working_filename = dbtables.get_connection_filename( 
    filename, tmp_path = opts.tmp_space, verbose = opts.verbose )
connection = sqlite3.connect( working_filename )
if opts.tmp_space:
    dbtables.set_temp_store_directory(connection, opts.tmp_space, verbose = opts.verbose)
dbtables.DBTable_set_connection( connection )

# Add program to process and process params table

# FIXME: remove the following two lines once boolean type
# has been properly handled
from glue.ligolw import types as ligolwtypes
ligolwtypes.FromPyType[type(True)] = ligolwtypes.FromPyType[type(8)]

xmldoc = dbtables.get_xml(connection)
proc_id = process.register_to_xmldoc(xmldoc, 'ligolw_cbc_dbsimplify', opts.__dict__, version = git_version.id)

# set of programs run so far on this data
programs = set(connection.cursor().execute('SELECT DISTINCT program FROM process').fetchall())

# create needed indices on tables if they don't already exist
current_indices = [index[0] for index in 
    connection.cursor().execute('SELECT name FROM sqlite_master WHERE type == "index"').fetchall()]
sqlscript = ''
if 'ts_io_index' not in current_indices:
    sqlscript += 'CREATE INDEX ts_io_index ON time_slide (instrument, offset);\n'
if 'e_sgitlc_index' not in current_indices:
    sqlscript += 'CREATE INDEX e_sgitlc_index ON experiment (search, search_group, instruments, gps_start_time, gps_end_time, lars_id, comments);\n'
if 'es_etvds_index' not in current_indices:
    sqlscript += 'CREATE INDEX es_etvds_index ON experiment_summary (experiment_id, time_slide_id, veto_def_name, datatype, sim_proc_id);\n'
if 'em_esi_index' not in current_indices:
    sqlscript += 'CREATE INDEX em_esi_index ON experiment_map (experiment_summ_id);\n'
if 'em_cei_index' not in current_indices:
    sqlscript += 'CREATE INDEX em_cei_index ON experiment_map (coinc_event_id);\n'

if sqlscript != '':
    if opts.verbose:
        print >> sys.stdout, "Creating needed indices..."
    connection.cursor().executescript(sqlscript)


# Cleaning up the veto_definer and segments tables
sqlutils.simplify_segments_tbls(connection, programs, verbose=opts.verbose, debug=opts.debug)
sqlutils.simplify_vetodef_tbl(connection, verbose=opts.verbose, debug=opts.debug)

# Make process_id map from info in the process & process_params tables
sqlutils.get_process_info(connection, verbose=opts.verbose, debug=opts.debug)

sqlutils.simplify_timeslide_tbl(connection, verbose=opts.verbose, debug=opts.debug)
if set([('inspinj',),('rinj',)]) & programs:
    sqlutils.simplify_sim_tbls(connection, programs, verbose=opts.verbose, debug=opts.debug)

# Cleaning up the coinc_definer & experiment tables
sqlutils.simplify_coincdef_tbl(connection, verbose=opts.verbose, debug=opts.debug)
sqlutils.simplify_expr_tbl(connection, verbose=opts.verbose, debug=opts.debug)
sqlutils.simplify_exprsumm_tbl(connection, verbose=opts.verbose, debug=opts.debug)

# Cleaning up the summary tables
sqlutils.simplify_summ_tbls(connection, verbose=opts.verbose, debug=opts.debug)
# Update process_ids in the sngl_inspiral table
sqlutils.update_sngl_inspiral(connection, current_indices, verbose=opts.verbose, debug=opts.debug)
# Cleaning up the process & process_params tables
sqlutils.simplify_proc_tbls(connection, verbose=opts.verbose, debug=opts.debug)

# Vacuum database if desired
if opts.vacuum:
    if opts.verbose:
        print >> sys.stderr, "Vacuuming database..."
    connection.cursor().execute( 'VACUUM' )

#
#       Save and Exit
#

connection.commit()
connection.close()

# write output database
dbtables.put_connection_filename(filename, working_filename, verbose = opts.verbose)

if opts.verbose: 
    print >> sys.stdout, "Finished!"

# set process end time
process.set_process_end_time(proc_id)
sys.exit(0)

