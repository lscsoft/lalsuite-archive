#!/usr/bin/python
try:
	import sqlite3
except ImportError:
	# pre 2.5.x
	from pysqlite2 import dbapi2 as sqlite3
import sys
import numpy
from optparse import OptionParser
from pylal import git_version
from pylal import SnglBurstUtils
from glue.ligolw import dbtables
from glue.ligolw import table
from glue.ligolw import lsctables
from glue.ligolw.utils import process
from xml import sax
from glue import iterutils
from glue import lal
from pylal import farutils
from pylal import llwapp

__author__ = "Chad Hanna channa@ligo.caltech.edu"
__version__ = "git id %s" % git_version.id
__date__ = git_version.date

def mchirp(m1,m2):
	return (m1+m2)**(0.6) / (m1*m2)**(0.2)

def check_table(xmldoc, tab, choke=False):

	#
	# Find out if there is a table and make one if not
	#

	try:
		ret_tab = table.get_table(xmldoc, tab.tableName)
	except ValueError:
		if choke: raise
		else: ret_tab = lsctables.New(dbtables.TableByName[table.StripTableName(tab.tableName)])
		# FIXME, make this xmldoc extraction work?
		#xmldoc.childNodes[0].appendChild(coinc_event_table)
	return ret_tab

def add_coinc(cetab, citab, cemtab, segs, tsid, cdid, procid, ifos, masses, ids, nevents):

	#
	# first do coinc_event
	#

	row = cetab.RowType()
	row.coinc_event_id = cetab.get_next_id()
	row.nevents = nevents
	row.likelihood = None
	row.set_instruments(segs.keys_at(time))
	row.time_slide_id = tsid
	row.coinc_def_id = cdid
	row.process_id = procid #FIXME do a proper process entry
	coinc_event_table.append(row)

	#
	# Then do coinc event map
	#

	for ceid in ids:
		cemrow = cemtab.RowType()
		cemrow.coinc_event_id = row.coinc_event_id
		#FIXME is that right?
		cemrow.table_name = lsctables.SnglInspiralTable.tableName
		cemrow.event_id = ceid
		coinc_event_map.append(cemrow)
	
	#
	# Then do coinc inspiral
	#

	cirow = citab.RowType()
	cirow.coinc_event_id = row.coinc_event_id
	cirow.snr = None #FIXME
	cirow.set_ifos(ifos)
	cirow.false_alarm_rate = None
	cirow.combined_far = None
	# Arithmetic mean of total mass and chirpmass
	cirow.mass = numpy.mean([m1+m2 for m1,m2 in masses])
	cirow.mchirp = numpy.mean([mchirp(m1,m2) for m1,m2 in masses])
	gps = lal.LIGOTimeGPS(time)
	cirow.end_time, cirow.end_time_ns = gps.seconds, gps.nanoseconds
	coinc_inspiral_table.append(cirow)

def parse_command_line():
	parser = OptionParser(
		version = "Name: %%prog\n%s" % git_version.verbose_msg,
		usage = "%prog [options] [file ...]",
		description = "%prog does blah blah blah."
	)
	parser.add_option("-i", "--input-cache", metavar = "filename", action = "append", help = "Retrieve database files from this LAL cache.  Can be given multiple times.")
	parser.add_option("-t", "--tmp-space", metavar = "path", help = "Path to a directory suitable for use as a work area while manipulating the database file.  The database file will be worked on in this directory, and then moved to the final location when complete.  This option is intended to improve performance when running in a networked environment, where there might be a local disk with higher bandwidth than is available to the filesystem on which the final output will reside.")
	parser.add_option("-p", "--live-time-program", help="live time program for extracting seglists")
	parser.add_option("-w", "--coinc-window", type="float", default=0.1, help="time window for coincidence, default 0.1 seconds")
	parser.add_option("-v", "--verbose", action = "store_true", help = "Be verbose.")

	options, filenames = parser.parse_args()
	
	if options.input_cache is not None:
		filenames += [lal.CacheEntry(line).path() for filename in options.input_cache for line in file(filename)]

	return options, filenames

options, filenames = parse_command_line()

cetab = None
citab = None
cemtab = None
cdtab = None
ptab = None

#
# This program treats every file as self contained and does not do coincidences across files
# 

for filename in filenames:


	#
	# Open database and extract xmldoc
	#

	working_filename = dbtables.get_connection_filename(filename, tmp_path = options.tmp_space, verbose = options.verbose)
	connection = sqlite3.connect(working_filename)
	if options.verbose:
                print >>sys.stderr, "\tcalculating coincidences in %s with time window %f" % (working_filename, options.coinc_window)

	dbtables.DBTable_set_connection(connection)
	# pull this XML out so that we can build tables
	xmldoc = dbtables.get_xml(connection)

	#
	# Setup tables
	#

	# define custom classes if they don't exist
	if not cetab: cetab = dbtables.DBTable(sax.xmlreader.AttributesImpl({"Name":lsctables.CoincTable.tableName}))
	if not cemtab: cemtab = dbtables.DBTable(sax.xmlreader.AttributesImpl({"Name":lsctables.CoincMapTable.tableName}))
	if not cdtab: cdtab = dbtables.DBTable(sax.xmlreader.AttributesImpl({"Name":lsctables.CoincDefTable.tableName}))
	if not citab: citab = dbtables.DBTable(sax.xmlreader.AttributesImpl({"Name":lsctables.CoincInspiralTable.tableName}))
	if not ptab: ptab = dbtables.DBTable(sax.xmlreader.AttributesImpl({"Name":lsctables.ProcessTable.tableName}))

	# Find out if there is a time slide table and barf if not
	time_slide_table = check_table(xmldoc, lsctables.TimeSlideTable, choke=True)
	# Find out if there are other tables and make them if not
	coinc_event_table = check_table(xmldoc, lsctables.CoincTable)
	coinc_event_map = check_table(xmldoc, lsctables.CoincMapTable)
	coinc_definer = check_table(xmldoc, lsctables.CoincDefTable)
	coinc_inspiral_table = check_table(xmldoc, lsctables.CoincInspiralTable)
	process_table = check_table(xmldoc, lsctables.ProcessTable)

	# sync the ids
	dbtables.idmap_sync(connection)

	# FIXME get the correct Coinc Def from somewhere in pylal?
	# setup coinc definer row
	CoincDef = lsctables.CoincDef(search = u"inspiral", search_coinc_type = 0, description = u"sngl_inspiral<-->sngl_inspiral coincidences")
	CoincDef.coinc_def_id = coinc_definer.get_next_id()
	coinc_definer.append(CoincDef)

	#
	# Create a temporary table to help find doubles and index it
	#

	connection.cursor().execute("""
CREATE TEMPORARY TABLE sngl AS 
	SELECT event_id, ifo, mass1, mass2, end_time + end_time_ns*1e-9 AS time, end_time + end_time_ns*1e-9 AS slid_time
		FROM sngl_inspiral
""")
	connection.cursor().execute("""CREATE INDEX tmpindex1 ON sngl (event_id)""")
	connection.cursor().execute("""CREATE INDEX tmpindex2 ON sngl (time)""")
	connection.cursor().execute("""CREATE INDEX tmpindex3 ON sngl (mass1,mass2)""")
	connection.cursor().execute("""CREATE INDEX tmpindex4 ON sngl (mass1)""")
	connection.cursor().execute("""CREATE INDEX tmpindex5 ON sngl (mass2)""")
	connection.cursor().execute("""CREATE INDEX tmpindex6 ON sngl (ifo)""")

	zero_lag_time_slides, background_time_slides = SnglBurstUtils.get_time_slides(connection)
	# FIXME get the instruments properly	
	instruments = zero_lag_time_slides.items()[0][1].keys()
	proc = process.append_process(xmldoc, program = sys.argv[0], version = __version__, cvs_repository = None, cvs_entry_time = None, comment = "cbc coinc", is_online = False, jobid = 0, domain = None, ifos = instruments)	
	process_id = proc.process_id
	

	#
	# Pull out the seglists and store a copy of the old offsets to use later
	#

	seglists = llwapp.segmentlistdict_fromsearchsummary(xmldoc, options.live_time_program).coalesce()
	old_offsets = seglists.offsets.copy()

	#
	# Iterate over time slides and form double coincs
	#

	cnt=0
	if options.verbose: print >> sys.stderr, "\n"
	zero_lag_time_slides, background_time_slides = SnglBurstUtils.get_time_slides(connection)
	for i, (time_slide_id, time_slide), in enumerate(background_time_slides.items() + zero_lag_time_slides.items()):

		# update the seglists with the proper offsets
		seglists.offsets.update(time_slide)

		# verbosity
		if options.verbose: print >> sys.stderr, "processing slides %.0f %%: found %d double coincs\r" % (100.0 * float(i+1) / (len(background_time_slides.items())+len(zero_lag_time_slides.items())), cnt),

		#
		# define a function for the slid time
		#

		def slidtime(ifoA, timeA, ifoB, timeB, slide=time_slide):
			return abs((slide[ifoA] + timeA) - (slide[ifoB]+timeB))

		connection.create_function("slidtime", 4, slidtime)

		#
		# Iterate over the double coincidences found within the time window
		# right now this just does exact mass coincidence, but a little
		# work might get e-thinca working too.
		#

        	for id1, id2, ifo1, ifo2, mass1_1, mass2_1, mass1_2, mass2_2, time in connection.cursor().execute("""
SELECT snglA.event_id, snglB.event_id, snglA.ifo, snglB.ifo, snglA.mass1, snglA.mass2, snglB.mass1, snglB.mass2, min(snglA.time, snglB.time)
	FROM sngl AS snglA 
		JOIN sngl AS snglB
			ON (snglA.mass1 == snglB.mass1 AND snglA.mass2 == snglB.mass2)
		WHERE snglA.ifo != snglB.ifo 
			AND slidtime(snglA.ifo, snglA.time, snglB.ifo, snglB.time) <= ?
			AND snglA.event_id > snglB.event_id
		""", (options.coinc_window,)):

			# for verbosity
			cnt+=1
	
			add_coinc(coinc_event_table, coinc_inspiral_table, coinc_event_map, seglists, time_slide_id, CoincDef.coinc_def_id, process_id, [ifo1, ifo2], [(mass1_1,mass2_1),(mass1_2,mass2_2)], [id1, id2], 2)

		# put the offsets back 
		seglists.offsets.update(old_offsets)

	#
	# Now do triples 
	# FIXME, I cannot figure out the way to implement N-way coincidences "easily", ligolw_thinca has an awesome algorithm, try to reproduce that.
	# That means this code can be deleted when that day comes
	#

	for level in range(3,len(instruments)+1):
		if level > 3: break #FIXME not supported yet
		if options.verbose: print >>sys.stderr, "\nProcessing triples\n"
		connection.cursor().execute("CREATE INDEX cemix1 ON coinc_event_map (event_id)")
		connection.cursor().execute("CREATE INDEX cemix2 ON coinc_event_map (coinc_event_id)")
		connection.cursor().execute("""
CREATE TEMPORARY TABLE tmpcemap AS
	SELECT cemA.coinc_event_id AS cid, cemA.event_id AS id1, cemB.event_id AS id2, coinc_event.time_slide_id AS tsid FROM coinc_event_map AS cemA 
		JOIN coinc_event_map AS cemB ON cemA.coinc_event_id == cemB.coinc_event_id
		JOIN coinc_event ON cemA.coinc_event_id == coinc_event.coinc_event_id
		WHERE cemA.event_id > cemB.event_id""")
#		AND coinc_event.time_slide_id == ?""")
#			""", (time_slide_id,))

		connection.cursor().execute("CREATE INDEX tmpcemapix1 ON tmpcemap (cid)")
		connection.cursor().execute("CREATE INDEX tmpcemapix2 ON tmpcemap (id1)")
		connection.cursor().execute("CREATE INDEX tmpcemapix3 ON tmpcemap (id2)")
		connection.cursor().execute("CREATE INDEX tmpcemapix4 ON tmpcemap (id1,id2)")
		connection.cursor().execute("CREATE INDEX tmpcemapix5 ON tmpcemap (tsid)")
		connection.cursor().execute("CREATE INDEX tmpcemapix6 ON tmpcemap (tsid,id1,id2)")

		trips = 0
		connection.cursor().execute("""
CREATE TEMPORARY TABLE triple AS 
	SELECT A.tsid AS tsid, A.cid AS cid1, B.cid AS cid2, C.cid AS cid3, A.id1 AS id1, A.id2 AS id2, B.id2 AS id3, siA.ifo as ifo1, siA.mass1 AS m1_1, 
		siA.mass2 AS m2_1, siB.ifo AS ifo2, siB.mass1 AS m1_2, siB.mass2 AS m2_2, siC.ifo AS ifo3, siC.mass1 AS m1_3, siC.mass2 AS m2_3
	FROM tmpcemap AS A 
	JOIN tmpcemap AS B JOIN tmpcemap AS C 
	JOIN sngl AS siA ON siA.event_id == A.id1
	JOIN sngl AS siB ON siB.event_id == A.id2
	JOIN sngl AS siC ON siC.event_id == B.id2
	WHERE A.id1 == B.id1 AND A.id2 == C.id1 AND B.id2 == C.id2
--	AND A.tsid == B.tsid == C.tsid
		""")

		for tsid, cid1, cid2, cid3, id1, id2, id3, ifo1, m1_1, m2_1, ifo2, m1_2, m2_2, ifo3, m1_3, m2_3 in connection.cursor().execute("SELECT tsid, cid1, cid2, cid3, id1, id2, id3, ifo1, m1_1, m2_1, ifo2, m1_2, m2_2, ifo3, m1_3, m2_3 FROM triple"):
			add_coinc(cetab, citab, cemtab, seglists, tsid, CoincDef.coinc_def_id, process_id, [ifo1,ifo2,ifo3], [(m1_1,m2_1),(m1_2,m2_2),(m1_3,m2_3)], [id1,id2,id3], 3)
			trips += 1
			print >>sys.stderr, "found %d coincs\r" % (trips,),

		connection.cursor().execute("DELETE FROM coinc_event WHERE coinc_event_id IN (SELECT cid1 FROM triple)")
		connection.cursor().execute("DELETE FROM coinc_event WHERE coinc_event_id IN (SELECT cid2 FROM triple)")
		connection.cursor().execute("DELETE FROM coinc_event WHERE coinc_event_id IN (SELECT cid3 FROM triple)")
		connection.cursor().execute("DELETE FROM coinc_event_map WHERE coinc_event_id IN (SELECT cid1 FROM triple)")
		connection.cursor().execute("DELETE FROM coinc_event_map WHERE coinc_event_id IN (SELECT cid2 FROM triple)")
		connection.cursor().execute("DELETE FROM coinc_event_map WHERE coinc_event_id IN (SELECT cid3 FROM triple)")
		connection.cursor().execute("DELETE FROM coinc_inspiral WHERE coinc_event_id IN (SELECT cid1 FROM triple)")
		connection.cursor().execute("DELETE FROM coinc_inspiral WHERE coinc_event_id IN (SELECT cid2 FROM triple)")
		connection.cursor().execute("DELETE FROM coinc_inspiral WHERE coinc_event_id IN (SELECT cid3 FROM triple)")

		connection.cursor().execute("DROP TABLE triple")
		connection.cursor().execute("DROP INDEX tmpcemapix1")
		connection.cursor().execute("DROP INDEX tmpcemapix2")
		connection.cursor().execute("DROP INDEX tmpcemapix3")
		connection.cursor().execute("DROP INDEX tmpcemapix4")
		connection.cursor().execute("DROP INDEX tmpcemapix5")
		connection.cursor().execute("DROP INDEX tmpcemapix6")
		connection.cursor().execute("DROP INDEX cemix1")
		connection.cursor().execute("DROP INDEX cemix2")
		connection.cursor().execute("DROP TABLE tmpcemap")

			
	# DROP INDICES
	connection.cursor().execute("DROP INDEX tmpindex1")
	connection.cursor().execute("DROP INDEX tmpindex2")
	connection.cursor().execute("DROP INDEX tmpindex3")
	connection.cursor().execute("DROP INDEX tmpindex4")
	connection.cursor().execute("DROP table sngl")
	connection.commit()
#	connection.close()
	dbtables.put_connection_filename(filename, working_filename, verbose = options.verbose)
