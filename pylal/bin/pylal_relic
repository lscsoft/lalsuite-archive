#!/usr/bin/python
#
# Copyright (C) 2008  Nickolas Fotopoulos
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
#
"""
pylal_relic
REcord Loudest Injection Coincidences

Loop over injection trials and keep only the stats from the loudest coincs
for each mean measured mchirp, injected m2, and injected D bin.
"""

import cPickle as pickle
import operator
import optparse
import sys
import glob

import numpy
numpy.seterr(all="raise")  # throw an exception on any funny business

from glue import iterutils
from glue import lal
from glue.ligolw import ligolw
from glue.ligolw import lsctables
from glue.ligolw import table
from glue.ligolw import utils
from glue.ligolw.utils import process as ligolw_process
from glue import segmentsUtils
from pylal import CoincInspiralUtils
from pylal import grbsummary
from pylal import rate
from pylal import git_version
from pylal.xlal.datatypes.ligotimegps import LIGOTimeGPS

__author__ = "Nickolas Fotopoulos <nvf@gravity.phys.uwm.edu> and Valeriu Predoi <valeriu.predoi@astro.cf.ac.uk>"

#
# get loudest coincs from each category
#
def comma_delimited(option, opt_str, value, parser, elem_type=str):
    """
    This callback function stores a comma-delimited string as a list during
    option parsing.  Cast elements of list to elem_type, specified via
    callback_kwargs (default: str).  Must specify type="string"!

    Example:
    parser.add_option("-n", "--names", action="callback", type="string",
        callback=comma_delimited, callback_kwargs={"elem_type":str})

    This would allow a user to provide "--names Joe,Bob,Sarah" and the
    developer to have opts.names == ["Joe", "Bob", "Sarah"].
    """
    setattr(parser.values, option.dest, map(elem_type, value.split(",")))


def get_loudest_stats_by_bins(rows, stat_func, nd_bins, key_funcs,
    dtype=float, verbose=False):
    """
    Return an array of dimension equal to nd_bins containing the loudest
    stats in rows.  The length of the key_funcs must be equal to the
    length of nd_bins.  The key_funcs are the functions used to
    extract the quantities being binned.  stat_func is called to extract
    the statistic of interest from each row.
    Example:
    >>> bins = NDBins((LinearBins(1, 25, 3), LogarithmicBins(1, 25, 3)))
    >>> stat = lambda trig: trig.snr
    >>> keys = (lambda trig: trig.mass1, lambda trig: trig.mass2)
    >>> loudest_by_m1_m2 = get_loudest_stats_by_bins(triggers, stat, bins, keys)
    """
    if len(nd_bins) != len(key_funcs):
        raise ValueError, "number of bins does not match number of keys"

    num_discarded = 0
    loudest_stats = numpy.zeros(shape=nd_bins.shape, dtype=dtype)
    for coinc in rows:
        bin_val = tuple([key_func(coinc) for key_func in key_funcs])
        try:
            ind = nd_bins[bin_val]
        except (IndexError, KeyError):
            num_discarded += 1
            continue
        stat = stat_func(coinc)
        if stat > loudest_stats[ind]:
            loudest_stats[ind] = stat
    if verbose and num_discarded > 0:
        sys.stderr.write("warning: %d coincs fell outside bins\n" \
                         % num_discarded)

    return loudest_stats

def get_loudest_stats_by_cat(xmldoc, coinc_stat, mc_bins, mc_ifo_cats):
    """
    Return a 1-D array containing the loudest stats in the SnglInspiralTable
    in xmldoc for each mean mchirp bin.  coinc_stat must be an instance
    of CoincInspiralUtils.coincStatistic and mc_bins must be an instance
    of rate.Bins. mc_ifo_cats is a Categories object to bin up the
    (mchirp_ind, IFO) combos.
    """
    # read unclustered on-source coincs
    try:
      onsource_trigs = table.get_table(xmldoc,
          lsctables.SnglInspiralTable.tableName)
    except ValueError:
      onsource_trigs = lsctables.New(lsctables.SnglInspiralTable)
      xmldoc.childNodes[0].appendChild(onsource_trigs)
    onsource_coincs = CoincInspiralUtils.coincInspiralTable(onsource_trigs,
        coinc_stat)

    # define bins and keys; output shape matches nd_bins.shape
    nd_bins = rate.NDBins((mc_ifo_cats,))
    stat_func = operator.attrgetter("stat")
    keys = (lambda c: (mc_bins[grbsummary.get_mean_mchirp(c)], c.ifos),)

    # get loudest stat in each bin
    return get_loudest_stats_by_bins(onsource_coincs, stat_func, nd_bins, keys,
        verbose=True)

def keep_only_loudest_events_by_cat(xmldoc, coincstat, mc_bins, mc_ifo_cats):
    """
    Duplicate get_loudest_stats_by_cat, except return the xmldoc with all
    coincs eliminated but the loudest in each mc_bin. mc_ifo_cats is a
    Categories object to bin up the (mchirp_ind, IFO) combos.
    If xmldoc has no SnglInspiralTable, create an empty one.
    """
    # read unclustered on-source coincs
    try:
      onsource_trigs = table.get_table(xmldoc,
          lsctables.SnglInspiralTable.tableName)
    except ValueError:
      onsource_trigs = lsctables.New(lsctables.SnglInspiralTable)
      xmldoc.childNodes[0].appendChild(onsource_trigs)
    onsource_coincs = CoincInspiralUtils.coincInspiralTable(onsource_trigs,
        coinc_stat)

    # define bins and keys; output shape matches nd_bins.shape
    nd_bins = rate.NDBins((mc_ifo_cats,))
    stat_func = lambda coinc: (coinc.stat, coinc.event_id)
    keys = (lambda c: (mc_bins[grbsummary.get_mean_mchirp(c)], c.ifos),)

    # get loudest (stat, event_id) in each bin, then filter for matching trigs
    loudest_pairs = get_loudest_stats_by_bins(onsource_coincs, stat_func,
        nd_bins, keys, dtype=object, verbose=True)
    loudest_ids = set(pair[1] for pair in loudest_pairs.flat if pair != 0)
    iterutils.inplace_filter(lambda t: t.event_id in loudest_ids,
        onsource_trigs)

    return xmldoc

def get_loudest_stats_by_trial_cat_slide(offsource_doc, coinc_stat,
    trial_bins, slide_bins, mc_bins, mc_ifo_cats):
    """
    Return a 3-D array containing the loudest stats in the SnglInspiralTable
    in xmldoc for each (trial, category) bin.  coinc_stat must be an instance
    of CoincInspiralUtils.coincStatistic and trial_bins and mc_bins must be
    instances of rate.Bins. mc_ifo_cats is a Categories object to bin up the
    (mchirp_ind, IFO) combos.
    """
    # read unclustered background coincs
    tables = table.getTablesByName(offsource_doc,
        lsctables.SnglInspiralTable.tableName)
    if len(tables) == 1:
      offsource_trigs = tables[0]
    elif len(tables) == 0:
      offsource_trigs = []
    else:
      raise ValueError, "why are there multiple SnglInspiral tables?"
    offsource_coincs = CoincInspiralUtils.coincInspiralTable(offsource_trigs,
        coinc_stat)

    # slide bins
    nominal_num_slides = grbsummary.get_num_slides(offsource_doc)
    total_num_slides = 2 * nominal_num_slides + 1 or 1
    slide_bins = rate.LinearBins(-nominal_num_slides-0.5, nominal_num_slides+0.5, total_num_slides)


    # define bins and keys
    nd_bins = rate.NDBins((trial_bins, slide_bins, mc_ifo_cats))
    stat_func = operator.attrgetter("stat")
    keys = (CoincInspiralUtils.coincInspiralTable.row.get_time, CoincInspiralUtils.coincInspiralTable.row._get_slide_num,
            lambda c: (mc_bins[grbsummary.get_mean_mchirp(c)], c.ifos))

    # get loudest stat in each bin
    return get_loudest_stats_by_bins(offsource_coincs, stat_func, nd_bins,
        keys, verbose=True)

def get_loudest_stats_by_inj_cat(inj_doc, coinc_doc, coinc_stat, trial_bins,
    mc_bins, mc_ifo_cats):
    """
    Return a list of injections and a 2-D array of the loudest coincs binned
    by injection trial and category. The order of the injections and the
    order of the 0-axis of the array are the same. mc_ifo_cats is a
    Categories object to bin up the (mchirp_ind, IFO) combos.
    """
    # get injection info
    sims = table.get_table(inj_doc, lsctables.SimInspiralTable.tableName)
    sim_trials = [trial_bins[s.geocent_end_time] for s in sims]

    # sanity check: no two injections went into the same trial
    assert len(sim_trials) == len(set(sim_trials))

    # get coincs
    try:
      inj_trigs = table.get_table(coinc_doc,
          lsctables.SnglInspiralTable.tableName)
    except ValueError:
      print "WARNING: coinc_doc contains no triggers."
      inj_trigs = lsctables.New(lsctables.SnglInspiralTable)

    inj_coincs = CoincInspiralUtils.coincInspiralTable(inj_trigs, coinc_stat)

    # find loudest coincs
    # convert time -> trial index -> sim index
    keys = (lambda row: trial_bins[row.get_time()],
            lambda c: (mc_bins[grbsummary.get_mean_mchirp(c)], c.ifos))
    sim_bins = rate.Categories([(trial_ind,) for trial_ind in sim_trials])
    nd_bins = rate.NDBins((sim_bins, mc_ifo_cats))
    stat_func = operator.attrgetter("stat")
    loudest_by_sim_cat = get_loudest_stats_by_bins(inj_coincs, stat_func,
        nd_bins, keys)

    return sims, loudest_by_sim_cat


def parse_args():
    parser = optparse.OptionParser(version=git_version.verbose_msg)

    # cache input
    parser.add_option("--cache-file", help="LAL-formatted cache file "
        "containing entries for all XML filies of interest")
    parser.add_option("--onsource-glob", metavar="GLOB", help="glob the "
        "on-source files with GLOB")
    parser.add_option("--offsource-pattern", metavar="PAT", help="sieve the "
        "cache descriptions for off-source coincidence files with PAT: THINCA_SLIDE_SECOND*OFFSOURCE for slides only; THINCA*SECOND*OFFSOURCE for slides and zero-lag; THINCA_SECOND*OFFSOURCE for zero-lag only")
    parser.add_option("--injection-pattern", metavar="PAT",
        help="sieve the cache descriptions for injection files with PAT")
    parser.add_option("--inj-coinc-pattern", metavar="PAT",
        help="sieve the cache descriptions for injection THINCA files with PAT")

    # output
    parser.add_option("--user-tag", default="",
        help="identifying string for these data")
    parser.add_option("--write-onsource", action="store_true", default=False,
        help="specify to write the onsource loudest coincidences; "\
        "requires --off-source-pattern and --onsource-pattern")
    parser.add_option("--write-offsource", action="store_true", default=False,
        help="specify to write the offsource loudest coincidences; "\
        "requires --off-source-pattern")
    parser.add_option("--write-injections", action="store_true", default=False,
        help="specify to write the loudest injection coincidences; "\
        "requires --off-source-pattern and --injection-pattern")

    # segments
    parser.add_option( "--offsource-seg", action="store", type="string",
        default=None,
        help="segwizard-formatted file containing offsource segments")
    parser.add_option( "--buffer-seg", action="store", type="string",
        default=None,
        help="segwizard-formatted file containing buffer segment")
    parser.add_option("--g1-veto-file", default="",
        help="segwizard-formatted segment files that "
        "contain segments to veto in G1")
    parser.add_option("--h1-veto-file", default="",
        help="segwizard-formatted segment files that "
        "contain segments to veto in H1")
    parser.add_option("--h2-veto-file", default="",
        help="segwizard-formatted segment files that "
        "contain segments to veto in H2")
    parser.add_option("--l1-veto-file", default="",
        help="segwizard-formatted segment files that "
        "contain segments to veto in L1")
    parser.add_option("--t1-veto-file", default="",
        help="segwizard-formatted segment files that "
        "contain segments to veto in T1")
    parser.add_option("--v1-veto-file", default="",
        help="segwizard-formatted segment files that "
        "contain segments to veto in V1")
    parser.add_option( "--onsource-seg", action="store", type="string",
        default=None,
        help="segwizard-formatted file containing onsource segment")


    # binning
    parser.add_option("--m2-min", type="float", help="minimum of the range in "
        "injected companion mass")
    parser.add_option("--m2-max", type="float", help="maximum of the range in "
        "injected companion mass")
    parser.add_option("--m2-nbins", type="int", help="number of evenly-spaced "
        "bins in injected companion mass")
    parser.add_option("--D-min", type="float", help="minimum of the range in "
        "injected distance")
    parser.add_option("--D-max", type="float", help="maximum of the range in "
        "injected distance")
    parser.add_option("--D-nbins", type="int", help="number of evenly-spaced "
        "bins in injected distance")
    parser.add_option("--mc-boundaries", help="comma-delimited list of "
        "boundaries in average recovered chirp mass")

    # odds and ends
    parser.add_option("--statistic", default="snr",
        help="choice of statistic used in making plots, valid arguments are: "
        "snr,effective_snr and new_snr")
    parser.add_option("--verbose", action="store_true", default=False,
        help="print extra information to the console")
    parser.add_option("--ifos", action="callback", type="string",
        callback=comma_delimited,
        help="comma-separated list of IFOs in lower case")



    options, arguments = parser.parse_args()

    # check that mandatory switches are present
    for opt in ("cache_file","offsource_pattern",
        "mc_boundaries", "statistic"):
        if getattr(options, opt) is None:
            raise ValueError, "--%s is always required" % opt.replace("_", "-")
    if not (options.write_onsource or options.write_offsource \
            or options.write_injections):
        raise ValueError, "must specify at least one of {--write-onsource, "\
            "--write-offsource, --write-injections}"
    if options.write_injections and (options.injection_pattern is None \
        or options.inj_coinc_pattern is None \
        or options.m2_min is None \
        or options.m2_max is None \
        or options.m2_nbins is None \
        or options.D_min is None \
        or options.D_max is None \
        or options.D_nbins is None):
        raise ValueError, "if --write-injections is specified, you must also "\
            "provide --injection-pattern, --inj-coinc-pattern, --m2-min, "\
            "--m2-max, --m2-nbins, --D-min, --D-max, and --D-nbins."

    return options, arguments

################################################################################
# parse arguments
opts, args = parse_args()

##############################################################################
# generic initialization
coinc_stat = CoincInspiralUtils.coincStatistic(opts.statistic)

##############################################################################
# read in non-injection documents
cache = lal.Cache.fromfile(open(opts.cache_file), coltype=LIGOTimeGPS)

# XXX: Speed hack; if opts.write_onsource, need all columns to be able to write
lsctables.SimInspiralTable.loadcolumns = ["simulation_id", "mass1", "mass2",
    "distance", "geocent_end_time", "geocent_end_time_ns", "process_id"]
if not opts.write_onsource:
    lsctables.SnglInspiralTable.loadcolumns = ["event_id", "mchirp", "ifo",
        "snr", "chisq", "chisq_dof", "end_time", "end_time_ns", "process_id"]

# always read offsource triggers (needed in any case)
offsource_doc = grbsummary.load_cache(ligolw.Document(), cache,
    opts.offsource_pattern, verbose=opts.verbose)
off_segs = segmentsUtils.fromsegwizard(open(opts.offsource_seg),
                                      coltype=int)
buffer_segs = segmentsUtils.fromsegwizard(open(opts.buffer_seg),
                                      coltype=int)
################################################################################
# choose segments/trials/vetoes (match grbtimeslide_stats)

on_segs = segmentsUtils.fromsegwizard(open(opts.onsource_seg),
                                      coltype=int)

nominal_num_slides = grbsummary.get_num_slides(offsource_doc)
if nominal_num_slides > 0: #timeslides and/or zerolag
  if opts.offsource_pattern == "THINCA_SLIDE_SECOND*OFFSOURCE":
    total_num_slides = 2 * nominal_num_slides
  if opts.offsource_pattern == "THINCA*SECOND*OFFSOURCE":
    total_num_slides = 2 * nominal_num_slides + 1
  if opts.offsource_pattern == "THINCA_SECOND*OFFSOURCE":
    total_num_slides = 1
else:
  total_num_slides = 1 #no slides turned on
extent_off = off_segs.extent()
extent_buffer = buffer_segs.extent()

#veto mask prerequisites
trial_len =  abs(on_segs)
num_trials = abs(off_segs) // trial_len
num_trials_buffers_onsource = abs(buffer_segs) // trial_len

##veto segments for IFOs
ifo_list = opts.ifos
veto_segs = {}
for ifo in ifo_list:
  veto_segs[ifo] = segmentsUtils.fromsegwizard(open(getattr(opts, ifo + "_veto_file")))

#get slide amounts(values of slide amount must be an integer!!)
slide_amount = {}
slide_table = table.get_table(offsource_doc, lsctables.ProcessParamsTable.tableName)
for row in slide_table:
  for ifo in ifo_list:
    if nominal_num_slides > 0:
      if row.param == "--%s-slide" % ifo:
        slide_amount[ifo] = int(float(row.value)) // trial_len
    else:
      slide_amount[ifo] = 0

#make trial, chirpmass and slide bins
trial_bins = rate.LinearBins(extent_off[0], extent_off[1], num_trials)
mc_bins = rate.IrregularBins(map(float, opts.mc_boundaries.split(",")))
slide_bins = rate.LinearBins(-nominal_num_slides-0.5, nominal_num_slides+0.5, total_num_slides)

#build veto masks to left and right and then merge them
veto_mask_left = grbsummary.get_veto_mask(extent_off[0], extent_buffer[0], trial_len, veto_segs)
veto_mask_right = grbsummary.get_veto_mask(extent_buffer[1], extent_off[1], trial_len, veto_segs)
trial_veto_mask_2d = numpy.zeros((total_num_slides, num_trials), dtype=numpy.bool8)
buffer_mask = numpy.ones(num_trials_buffers_onsource, dtype=numpy.bool8)

for slide in range(-nominal_num_slides, nominal_num_slides+1):

  trial_mask_left = grbsummary.get_trial_mask(veto_mask_left, slide_amount, slide)
  trial_mask_right = grbsummary.get_trial_mask(veto_mask_right, slide_amount, slide)
  trial_mask_2d = numpy.concatenate((trial_mask_left, buffer_mask, trial_mask_right))
  trial_veto_mask_2d[slide] = trial_mask_2d

trial_veto_mask = trial_veto_mask_2d.flatten()
trial_veto_mask_inj = numpy.zeros(num_trials, dtype=numpy.bool8)
if nominal_num_slides > 0:
  trial_veto_mask_inj = trial_veto_mask_2d[0]
else:
  trial_veto_mask_inj = trial_veto_mask
################################################################################
# choose other binnings: mchirp, m2, D, and (mchirp_ind and IFO combo)

if opts.write_injections:
    m2_bins = rate.LinearBins(opts.m2_min, opts.m2_max, opts.m2_nbins)
    D_bins = rate.LinearBins(opts.D_min, opts.D_max, opts.D_nbins)

# turn all mc+IFO combos into distinct categories, starting with the largest
explicit_ifo_combos = \
    set(e.observatory for e in cache if len(e.observatory) >= 4)
ifos = sorted(set(combo[2*i:2*i+2] for combo in explicit_ifo_combos \
                                   for i in xrange(len(combo) // 2)))
ifo_combos = [frozenset(combo) for n in xrange(len(ifos), 1, -1) \
                    for combo in iterutils.choices(ifos, n)]
mc_ifo_cats = rate.Categories(((i, combo),) for combo in ifo_combos \
                              for i in xrange(len(mc_bins)))

################################################################################
# get loudest on-source coincs
if opts.write_onsource:

  # read the onsource file(s)
  fileList = glob.glob(opts.onsource_glob)
  if len(fileList)!=1:
    raise ValueError, "Number of on-source fils must be 1, it is %d " % len(fileList)
  onsource_doc = utils.load_filename(fileList[0], verbose=opts.verbose,
      gz=fileList[0].endswith(".gz"))

  # add this program to the process table
  process = ligolw_process.register_to_xmldoc(onsource_doc, "pylal_relic",
    opts.__dict__, version=git_version.tag or git_version.id,
    cvs_repository="lalsuite", cvs_entry_time=git_version.date)

  # extract the loudest for each MC bin
  onsource_loudest_by_cat = get_loudest_stats_by_cat(onsource_doc, coinc_stat,
      mc_bins, mc_ifo_cats)

  # also alter the XML to contain only the loudest event in each MC bin
  keep_only_loudest_events_by_cat(onsource_doc, coinc_stat, mc_bins, mc_ifo_cats)

  # since we didn't do the argmax in exactly the same way as the max,
  # let's be paranoid that we got the same loudest events.
  assert (onsource_loudest_by_cat == get_loudest_stats_by_cat(onsource_doc,
      coinc_stat, mc_bins, mc_ifo_cats)).all()

################################################################################
# get loudest off-source coincs
if opts.write_offsource or opts.write_injections:

  offsource_loudest_by_trial_cat_slide = get_loudest_stats_by_trial_cat_slide(offsource_doc,
      coinc_stat, trial_bins, slide_bins, mc_bins, mc_ifo_cats)
  offsource_loudest_by_trial_cat_unvetoed = \
      offsource_loudest_by_trial_cat_slide.reshape(total_num_slides*len(trial_bins), len(mc_bins))
  offsource_loudest_by_trial_cat = \
      offsource_loudest_by_trial_cat_unvetoed[~trial_veto_mask,:]
################################################################################
# get loudest injection coincs
if opts.write_injections:
    # sieve down to just injection coinc files
    injection_cache = cache.sieve(description=opts.injection_pattern).sieve(ifos='HL')
    inj_coinc_cache = cache.sieve(description=opts.inj_coinc_pattern)

    # speed hack: only iterate over IFOs of interest for mchirp calculation
    CoincInspiralUtils.ifos = tuple(ifos)

    # get all unique descriptions (can have multiple segments per description)
    inj_patterns = set("*" + "_".join(entry.description.split("_")[-2:]) \
                       for entry in inj_coinc_cache)

    # tally up the numerator and denominator for p(c|h) for each inj pattern
    if opts.verbose:
        print "Tallying injections:"
    sims = []
    inj_loudest_by_inj_cat = []
    for pattern in inj_patterns:
        # read injection and its corresponding coincs
        inj_doc = grbsummary.load_cache(ligolw.Document(), injection_cache,
                                        pattern, exact_match=True)
        coinc_doc = grbsummary.load_cache(ligolw.Document(), inj_coinc_cache,
                                          pattern, exact_match=True)

        tmp_sims, tmp_coinc_count = \
            get_loudest_stats_by_inj_cat(inj_doc, coinc_doc, coinc_stat,
                trial_bins, mc_bins, mc_ifo_cats)

        sims.extend(tmp_sims)
        inj_loudest_by_inj_cat.extend(tmp_coinc_count)

        if opts.verbose:
            sys.stdout.write(".")
            sys.stdout.flush()
    inj_loudest_by_inj_cat = numpy.array(inj_loudest_by_inj_cat)

    # throw out vetoed injection trials
    inj_mask = trial_veto_mask_inj[[trial_bins[sim.get_end()] for sim in sims]]
    sims = [sim for sim, keep in zip(sims, inj_mask) if not keep]
    inj_loudest_by_inj_cat = inj_loudest_by_inj_cat[~inj_mask, ...]

    # extract m2 and D values of sims
    m2_D_by_inj = [(sim.mass2, sim.distance) for sim in sims]

    if opts.verbose:
        print "Done. Found loudest coincs for %d injections." % len(sims)

################################################################################
# write loudest coincs to disk
# my proprietary file format: a pickled tuple
fname_prefix = "pylal_relic"
if opts.user_tag != "":
    fname_suffix = "_" + opts.user_tag + ".pickle"
else:
    fname_suffix = ".pickle"

if opts.write_onsource:
    fname = fname_prefix + "_onsource" + fname_suffix
    # write pickle
    pickle.dump((opts.statistic, mc_bins, mc_ifo_cats, onsource_loudest_by_cat),
                open(fname, "wb"), -1)
    # write XML
    ligolw_process.set_process_end_time(process)
    utils.write_filename(onsource_doc, fname_prefix + "_onsource" \
        + fname_suffix.replace(".pickle", ".xml"))
    sys.stdout.write("Loudest on-source coincs written.\n")
if opts.write_offsource:
    fname = fname_prefix + "_offsource" + fname_suffix
    pickle.dump((opts.statistic, mc_bins, mc_ifo_cats,
                 offsource_loudest_by_trial_cat), open(fname, "wb"), -1)
    sys.stdout.write("Loudest off-source coincs written.\n")
if opts.write_injections:
    fname = fname_prefix + "_injections" + fname_suffix
    pickle.dump((opts.statistic, mc_bins, mc_ifo_cats, m2_bins, D_bins,
                 m2_D_by_inj, inj_loudest_by_inj_cat),
                open(fname, "wb"), -1)
    sys.stdout.write("Loudest injection coincs written.\n")

