#!/usr/bin/python

__author__ = "Ruslan Vaulin <vaulin@gravity.phys.uwm.edu>"
__version__ = "$Revision$"[11:-2]
__date__ = "$Date$"[7:-2]
__prog__="inspiral_search_summary"
__Id__ = "$Id$"

#loading standard modules
from optparse import *
import glob
import sys
import os
#loading modules used for input/output of data 
from glue import lal
from glue.ligolw import lsctables
from pylal import CoincInspiralUtils
from pylal import SnglInspiralUtils
from pylal import SimInspiralUtils
from pylal import InspiralUtils
from glue.ligolw import ligolw
from scipy import *
import numpy
import cPickle

######################################################################################################
# Functions
######################################################################################################

def poly_between(x, ylower, yupper):
    """
    given a sequence of x, ylower and yupper, return the polygon that
    fills the regions between them.  ylower or yupper can be scalar or
    iterable.  If they are iterable, they must be equal in length to x

    return value is x, y arrays for use with Axes.fill
    """
    Nx = len(x)
    if not iterable(ylower):
      ylower = ylower*numpy.ones(Nx)

    if not iterable(yupper):
      yupper = yupper*numpy.ones(Nx)

    x = numpy.concatenate( (x,x[::-1]) )
    y = numpy.concatenate( (yupper, ylower[::-1]) )
    return x,y


def get_cum_num(x):
  """Return the array of cumulative numbers calculated based on frequencies with which each uniq element of data array x is appearing.
     @param x: array containing values of stochastic variable X
         The array of cum numbers is a two-dimesional array. Zeroth row contains all unique values of variable X sorted in ascending order,
         whereas first row contains the corresponding to these cumulative numbers.
  """
  if len(x) >0:
    p1 = numpy.fliplr(stats.itemfreq(x).transpose())
    p1[1] = p1[1].cumsum()
    p = numpy.fliplr(p1)
    return p
  else:
     raise ValueError, "empty frequency array"



def calculate_ifar(zerolag_stats, slide_stats, slide_time):
  """
  Function to calculate ifar for all triggers in zero-lag and time slides
  @param zerolag_stats: array of zero lag statistic
  @param slide_stats: dictionary of time slide statistic
  @param slide_time: duration of slides
  """

  # define array to hold ifar for zerolag
  zerolag_ifar = numpy.zeros(len(zerolag_stats))

  # define dictionary to hold ifar for slides
  slide_ifar = {}
  
  for key in slide_stats.keys():
    slide_ifar[key] = numpy.zeros(len(slide_stats[key]))

  # get all background stats
  all_slide_stats = numpy.zeros(1)

  for key in slide_stats.keys():
    all_slide_stats = numpy.concatenate((all_slide_stats, slide_stats[key]))

  # get rid of zero
  all_slide_stats = numpy.trim_zeros(all_slide_stats)

  # sort it
  all_slide_stats.sort()

  # calculate total number of background events
  N_total_slides = len(all_slide_stats)

  # calculate ifar for zero lag
  for i in range(len(zerolag_ifar)):
    index = numpy.searchsorted(all_slide_stats, zerolag_stats[i])
    if index == 0:
      zerolag_ifar[i] = float(N_total_slides)
    elif index == N_total_slides:
      zerolag_ifar[i] = 0.5
    else:
      zerolag_ifar[i] = float(N_total_slides - index)

  # divide by duration of slides and normalize it to 1 year
  zerolag_ifar = (zerolag_ifar * 31536000.0) / float(slide_time)

  # take the inverse
  zerolag_ifar = 1.0 / zerolag_ifar


  # calculate ifar for slides

  for key in slide_stats.keys():
    for i in range(len(slide_stats[key])):
      index = numpy.searchsorted(all_slide_stats, slide_stats[key][i])
      if index == 0:
        slide_ifar[key][i] = float(N_total_slides)
      elif index == N_total_slides:
        slide_ifar[key][i] = 0.5
      else:
        slide_ifar[key][i] = float(N_total_slides - index)

    # divide by duration of slides and normalize it to 1 year
    slide_ifar[key] = (slide_ifar[key] * 31536000.0) / float(slide_time)

    # take the inverse
    slide_ifar[key] = 1.0 / slide_ifar[key]


  return zerolag_ifar, slide_ifar
    
















def cumhiststat(zerolag_stats=None, slide_stats=None, min_val = None, \
  max_val = None, nbins = 20, stat=None, scalebkg=False):
  """
  function to plot a cumulative histogram of the snr of coincident events
  in the zero lag and times slides
  
  @param zerolag_stats: array of zero lag statistic
  @param slide_stats: dictionary of time slide statistic
  @param min_val: minimum of snr to be plotted
  @param max_val: maximum of snr to be plotted
  @param nbins: number of bins to use in histogram
  @param stat: the statistic being used
  @param scalebkg: Use this option if plotting playground zero lag against
  full data time slides (it will rescale the time slides).
  """
  internal_min = numpy.inf
  internal_max = -numpy.inf

  if not zerolag_stats == None:
	  internal_max = max(internal_max, zerolag_stats.max())
	  internal_min = min(internal_min, zerolag_stats.min())
  if not slide_stats == None:
	max_slide_stat = 0.0
	min_slide_stat = 0.0
	for key in slide_stats.keys():
	  max_slide_stat = max(max_slide_stat, slide_stats[key].max())
	  min_slide_stat = min(min_slide_stat, slide_stats[key].min())

	internal_max = max(internal_max, max_slide_stat)
	internal_min = min(internal_min, min_slide_stat)
  # set up the bin boundaries
  if not max_val:
    max_val = internal_max
  if not min_val:
    min_val = internal_min

  if min_val >= max_val:
    # CHECKME: what should we do without any trigs or slide_trigs?
    # This is the old behavior.
    min_val = 5.
    max_val = 10.
  if min_val == max_val:
    # NB: this is numpy.histogram's default behavior for equal max and min
    min_val -= 0.5
    max_val += 0.5

  bins = numpy.linspace(min_val, max_val, nbins)

  # hist of the zero lag:
  if not zerolag_stats == None:
    zero_dist, xbin = numpy.histogram(zerolag_stats, bins)
    cum_dist_zero = zero_dist[:-1][::-1].cumsum()[::-1]

  # hist of the slides:
  if not slide_stats == None:
    cum_dist_slide = []
    for key in slide_stats.keys():
      num_slide, bin = numpy.histogram(slide_stats[key], bins)
      cum_slide = num_slide[:-1][::-1].cumsum()[::-1]
      cum_dist_slide.append(cum_slide)
    cum_dist_slide = numpy.array(cum_dist_slide)
    slide_mean = cum_dist_slide.mean(axis=0)
    slide_std = cum_dist_slide.std(axis=0)
    if scalebkg:
      slide_mean *= 600./6370.
      slide_std *= sqrt(600./6370.)
	  
  if ("bitten_l" in stat) or ("ifar" in stat) or ("lvS5stat" in stat):
	delta = (bins[1] - bins[0]) / 2.0
	center_bins = numpy.zeros(len(bins) - 1)
	for i in range(len(bins) - 1):
	  center_bins[i] = bins[i] + delta
	xvals = center_bins
  else:
	delta = (bins[1] - bins[0]) / 2.0
	center_bins = numpy.zeros(len(bins) - 1)
	for i in range(len(bins) - 1):
	  center_bins[i] = bins[i] + delta
	xvals=center_bins**2

  figure()
  
  # plot zero lag
  if not zerolag_stats == None:
	if stat == 'ifar':
	  loglog(10**(xvals), cum_dist_zero + 0.0001, 'r^',markerfacecolor="b", markersize=12)
	else:
	  semilogy(xvals,cum_dist_zero + 0.0001,'r^',markerfacecolor="b", markersize=12)

  # plot time slides
  if not slide_stats == None:
	ds = (bins[1] - bins[0]) / 2
	slide_min = []
	for i in range( len(slide_mean) ):
	  slide_min.append( max(slide_mean[i] - slide_std[i], 0.0001) )
	  slide_mean[i] = max(slide_mean[i], 0.0001)
	if stat == 'ifar':
	  loglog(10**(xvals),asarray(slide_mean), 'r+', markersize=12)
	  tmpx,tmpy = viz.makesteps(center_bins,slide_min,slide_mean+slide_std)
	else:
	  semilogy(xvals,asarray(slide_mean), 'r+', markersize=12)
	  tmpx,tmpy = viz.makesteps(center_bins,slide_min,slide_mean+slide_std)
	if ("bitten_l" in stat) or ('ifar' in stat) or ('lvS5stat' in stat):
	  if stat == 'ifar':
	    p=fill(10**(tmpx-ds),tmpy, facecolor='y')	
	  else:
	    p=fill((tmpx-ds),tmpy, facecolor='y')
	else:
	  p=fill((tmpx-ds)*(tmpx-ds),tmpy, facecolor='y')
	setp(p, alpha=0.3)

  if stat == 'coherent_snr': xlab = 'Coherent SNR$^{2}$'
  elif stat == 'ifar': xlab = 'Inverse False Alarm Rate [years]'
  elif stat == 'lvS5stat': xlab = 'ln(effective likelihood)'
  elif stat: xlab = 'combined ' + stat.replace('_',' ')
  else: xlab = 'Combined Statistic'
  xlabel(xlab, size='xx-large')
  ylabel('Number of events', size='xx-large')
  title_text = 'Cum. hist. of num events vs ' + xlab
  title(title_text, size='xx-large')
  if stat == 'ifar':
    ylim(ymin=10**(-3))

def writeProcessParams(name, version, command):
  """
  Convert input parameters from the process params that the code was called 
  with into a formatted string that can be saved within an other document 
  (e.g., HTML)

  @param name: name of the executable/script
  @param version:version of the executable/script
  @param command: command line arguments from a pylal script
  @return text
  """
  text = "Figure(s) produced with " + name + ", " \
      + version + ", invoked with the following command line arguments:" \
      + '<br>\n<p style="width:80%; color:blue">'+ name
  for arg in command:
    text += " " +  arg
  text+='</p>'

  return text

def write_cache_output(opts, html_filename,fnameList):
  """
  write the output cache file of theplotting functions
  """

  output_cache_name = opts.prefix + opts.suffix +'.cache'
  if opts.output_path:
    output_cache_name = opts.output_path + output_cache_name
  this = open(output_cache_name, 'w')
  if opts.enable_output is True:
    this.write(os.path.basename(html_filename) + '\n')
  for filename in fnameList:
    if str(filename).endswith('.png'):
      fname = "Images/"+os.path.basename(filename) # set the correct name for linking
    elif str(filename).endswith('.html'):
      fname = os.path.basename(str(filename)) # set the correct name for linking
    this.write(fname + '\n')
  this.close()

################################################################################
# Main program
################################################################################
usage= """
usage: %prog [options]

This code calculates false alarm probability for N loudest candidates in the search and prints them to a summary html page.
"""
###############################################################################
# Options to read in Input
###############################################################################
def parse_command_line():

  """
  Parser function dedicated
  """
  parser = OptionParser( usage=usage, version="%prog CVS $Id$ " )
  
  parser.add_option("","--slides-glob",action="store",type="string",\
      default=None, metavar=" GLOB",help="GLOB time slides files to read" )
	
  parser.add_option("","--zero-lag-glob",action="store",type="string",\
      default=None, metavar=" GLOB",help="GLOB zero-lag files to read" )

  parser.add_option("","--no-bg-zero-lag-glob",action="store",type="string",\
      default=None, metavar=" GLOB",help="GLOB no background zero lag files to read")
	
  parser.add_option("","--input-cache-file",action="store",type="string",\
      default=None, metavar="ZEROLAGCACHEFILE",help="name of the cache file including the path" )

  parser.add_option("","--slides-pattern",\
      default="", metavar="SLIDESPATTERN", help="the time slides files pattern the cache file, specified by --input-cache-file option, will be seived with.")
	
  parser.add_option("","--zero-lag-pattern",\
      default="", metavar="ZEROLAGPATTERN", help="the zero lag files pattern the cache file, specified by --input-cache-file option, will be seived with.")

  parser.add_option("","--no-bg-zero-lag-pattern",\
      default="", metavar="NO_BG_ZERO_LAG_PATTERN", help="the zero lag with no background files pattern the cache file, specified by"\
      " --input-cache-file option, will be seived with.")

  parser.add_option("","--efactors-file", action="store",type="string",\
      default = None, help="file with efficiency factors" )

  parser.add_option("","--gps-start-time",action="store",\
      type="int",  metavar="GPSSTARTTIME",\
      help="gps start time (for naming figure and output files")

  parser.add_option("","--gps-end-time",action="store",\
      type="int",  metavar=" GPSENDTIME",\
      help="gps end time (for naming figure and output files")

  parser.add_option("", "--h1-triggers",action="store_true", default=False,\
      help="input files contain triggers from H1")

  parser.add_option("", "--h2-triggers",action="store_true", default=False,\
      help="input files contain triggers from H2")

  parser.add_option("", "--l1-triggers",action="store_true", default=False,\
      help="input files contain triggers from L1")

  parser.add_option("", "--g1-triggers",action="store_true", default=False,\
      help="input files contain triggers from G1")

  parser.add_option("", "--v1-triggers",action="store_true", default=False,\
      help="input files contain triggers from V1")

  parser.add_option("","--statistic",action="store",default='snr',\
      type="string",\
      help="choice of statistic used in building coinc table, valid arguments are: snr (DEFAULT), snr_over_chi, s3_snr_chi_stat, effective_snr, bitten_l, bitten_lsq, ifar")
	
  parser.add_option("", "--use-likelihood",action="store_true", default=False,\
      help="enables likelihood to be used as detection statistic")

  parser.add_option("","--make-effective-likelihood-histogram",action="store_true", default=False,\
      help="Make an effective likelihood histogram plot")

  parser.add_option("","--plot-slides",action="store_true", default=False,\
      help="Plot the statistic of the loudest time slides")
	  
  parser.add_option("","--plot-mchirp-vs-effective-snr",action="store_true", default=False,\
      help="Make scatter plot of mchirp vs effective snr for loudest coincs form each time slide")

  parser.add_option("","--plot-mchirp-vs-stat",action="store_true", default=False,\
      help="Make scatter plot of mchirp vs statistic for the loudest coincs from each time slides") 
  parser.add_option("","--plot-efactors",action="store_true", default=False,\
      help="Make bar plot of efficiency factors")
		
  parser.add_option("","--num-events", action="store",type="int",\
      default = 1, help="number of loudest events to be printed" )
	
  parser.add_option("", "--save-background-stats",action="store_true", default=False,\
      help="save loudest events found in each time slide")
	  
  parser.add_option("","--output-background-file", action="store",type="string",\
      default = None, help="output file for loudest events found in each time slide" )

  parser.add_option("", "--skip-timeslides",action="store_true", default=False,\
      help="skip time slides, use loudest-background-events-file instead.")
	
  parser.add_option("","--loudest-background-stats-file", action="store",type="string",\
      default = None, help="file with loudest events found in each time slide" )
		
  parser.add_option("", "--plot-ifar",action="store_true", default=False,\
      help="make plots of inverse false alarm rate")
	  
  parser.add_option("","--septime-files",action="store",type="string",\
      default=None,help="GLOB septime files" )
	  
		
  parser.add_option("","--num-slides", action="store",type="int",\
      default = 0, metavar="numslides", help="number of time slides performed, must match the corresponding parameter from the .ini file of the search" )
		
  parser.add_option("","--verbose", action="store_true",\
      default=False, help="print information" )

  parser.add_option("-u","--user-tag",action="store",type="string",\
      default=None, metavar=" USERTAG",\
      help="The user tag used in the name of the figures" )

  parser.add_option("-Z","--zero-lag-playground",action="store_true",\
      default=False,\
      help="scale number of bkg triggers in slide plots by 600/6370")

  parser.add_option("","--ignore-IFO-times",action="store",type="string",\
      default='', metavar=" USERTAG",\
      help="comma separated list of IFOTYPE_IFOTIME that should not be included in efficiency calculation e.g. H1H2_H1H2,H2L1_H1H2L1. This option will work only with s5 LV search files that are named IFOTIME_IFOTYPE-*xml" )
  
  parser.add_option("-P","--output-path",action="store",\
      type="string",default=None,  metavar="PATH",\
      help="path where the figures would be stored")


  parser.add_option("-O","--enable-output",action="store_true",\
      default="false",  metavar="OUTPUT",\
      help="enable the generation of the html and cache documents")


  parser.add_option("", "--figure-resolution",action="store",type="int",\
      default=50, metavar="FIGURERESOLUTION", \
      help="resolution of the thumbnails (50 by default)" )

  parser.add_option("", "--html-for-cbcweb",action="store",\
      default=False, metavar = "CVS DIRECTORY", help="publish the html "\
      "output in a format that can be directly published on the cbc webpage "\
      "or in CVS. This only works IF --enable-output is also specified. The "\
      "argument should be the cvs directory where the html file will be placed "\
      "Example: --html-for-cbcweb protected/projects/s5/yourprojectdir")


  (opts,args) = parser.parse_args()

  return opts, sys.argv[1:]
#####################################################################
opts, args = parse_command_line()


def init_markup_page( opts):
  """
  Load the markup module, and initialise the HTML document if the opts 
  argument contains enable_ouput option.

  @param  opts : the user arguments 
  @return page 
  @return extra 
  """
  # Initialise the html output file
  if opts.enable_output is True:
    try:
      from glue import markup
      from glue.markup import oneliner as extra_oneliner
    except:
      raise ImportError("Require markup.py to generate the html page")

    page = markup.page()
    try:
      page.init(title=__title__)
    except:
      page.init()

  return page, extra_oneliner


# Sanity checks
######################################################################

if opts.skip_timeslides and not opts.loudest_background_events_file:
  print >> sys.stderr, "--loudest-background-events-file must be given if --skip-timeslides option is used"
  sys.exit(1)
  
if not opts.skip_timeslides and not opts.num_slides:
  print >> sys.stderr, "number of time slides should be provided if running with time slides triggers,"
  print >> sys.stderr, "use --num-slides option"
  sys.exit(1)
   
if opts.plot_efactors and not opts.efactors_file:
  print >> sys.stderr, "--efactors_file must be provided if --plot_efactors is used"
  sys.exit(1)  

if not (opts.input_cache_file or opts.slides_glob):
  print >>sys.stderr, "Some of the options specifying the input files containing single inspiral tables are missing." 
  print >> sys.stderr, " Either --input-cache-file or --slides-glob must be given."
  sys.exit(1)
  
# Initializing the html output
InspiralUtils.message(opts, "Initialisation...")
opts = InspiralUtils.initialise(opts, __prog__, __version__)
fnameList = []
tagList = []
fig_num = 0
comments = ""

# Change to Agg back-end if show() will not be called 
# thus avoiding display problem
import matplotlib
matplotlib.use('Agg')
from pylab import *
from pylal import viz
from pylal import plotutils
rcParams.update({                                                               
    "text.usetex": True,                                                        
    "text.verticalalignment": "center",                                         
    "lines.linewidth": 2.5,                                                     
    "font.size": 16,                                                            
    "axes.titlesize": 20,                                                       
    "axes.labelsize": 16,                                                       
    "xtick.labelsize": 16,                                                      
    "ytick.labelsize": 16,                                                      
    "legend.fontsize": 16,                                                      
})

#Calculating statistic for coincidences
statistic = CoincInspiralUtils.coincStatistic(opts.statistic) 

  
# contsructing lists of data files containing time slides and zero-lag triggers respectively
########################################################################################################	
if opts.input_cache_file:
  InspiralUtils.message(opts, "Reading input-cache-file ...")
  slidesfiles = []
  zero_lag_files = []
  no_bg_zero_lag_files = []
  SnglInspiralCache = lal.Cache.fromfile(open(opts.input_cache_file))
  if not opts.skip_timeslides:
    slidesfiles = SnglInspiralCache.sieve(description = opts.slides_pattern, exact_match=True).checkfilesexist()[0].pfnlist()
  zero_lag_files = SnglInspiralCache.sieve(description = opts.zero_lag_pattern, exact_match=True).checkfilesexist()[0].pfnlist()
  no_bg_zero_lag_files = SnglInspiralCache.sieve(description = opts.no_bg_zero_lag_pattern, exact_match=True).checkfilesexist()[0].pfnlist()
else:
  slidesfiles = []
  zero_lag_files = []
  no_bg_zero_lag_files = []
  if not opts.skip_timeslides:
    slidesfiles = glob.glob(opts.slides_glob)
  zero_lag_files = glob.glob(opts.zero_lag_glob)
  no_bg_zero_lag_files = glob.glob(opts.no_bg_zero_lag_glob)
  
# check if file lists are not empty
if not opts.skip_timeslides:
  if not len(slidesfiles) > 0:
    print >>sys.stderr, "List of time slides files is empty: your sieve (glob) pattern may be wrong or files do not exist in the location given by the cache file"
    sys.exit(1)
if  not len(zero_lag_files) > 0:
  print >>sys.stderr, "List of zero-lag files is empty: your sieve (glob) pattern may be wrong or files do not exist in the location given by the cache file"
if  not len(no_bg_zero_lag_files) > 0:
  print >>sys.stderr, "List of no-bg-zero-lag files is empty: your sieve (glob) pattern may be wrong or files do not exist in the location given by the cache file"
  sys.exit(1) 


# get rid of certain IFO times if necessary
if opts.ignore_IFO_times:

  ifo_times_to_ignore = opts.ignore_IFO_times.split(",")

  # time slides
  # Assumes that ifo time is the first thing in the file name
  new_slidesfiles = []
  for file in slidesfiles:
    tmpifotime=file.split("/")[-1].split("_")[0]
    tmpifotype=file.split("/")[-1].split("_")[1].split("-")[0]
    category="_".join([tmpifotype,tmpifotime])
    if not (category in ifo_times_to_ignore):
      new_slidesfiles.append(file)

  slidesfiles = []
  slidesfiles = new_slidesfiles

  # zero lag
  # Assumes that ifo time is the first thing in the file name
  new_zero_lag_files = []
  for file in zero_lag_files:
    tmpifotime=file.split("/")[-1].split("_")[0]
    tmpifotype=file.split("/")[-1].split("_")[1].split("-")[0]
    category="_".join([tmpifotype,tmpifotime])
    if not (category in ifo_times_to_ignore):
      new_zero_lag_files.append(file)

  zero_lag_files = []
  zero_lag_files = new_zero_lag_files 

  # no bg zero lag
  # Assumes that ifo times is the first thing in the file name
  new_no_bg_zero_lag_files = []
  for file in no_bg_zero_lag_files:
    tmpifotime=file.split("/")[-1].split("_")[0]
    tmpifotype=file.split("/")[-1].split("_")[1].split("-")[0]
    category="_".join([tmpifotype,tmpifotime])
    if not (category in ifo_times_to_ignore):
      new_no_bg_zero_lag_files.append(file)

  no_bg_zero_lag_files = []
  no_bg_zero_lag_files = new_no_bg_zero_lag_files

# Finding loudest events in each of the time slides
########################################################################################################################


if not opts.skip_timeslides:
  InspiralUtils.message(opts, "Finding loudest events in each of the time slides ...")

  # define dictionary to hold loudest stats for each time slide
  stats_dic = {}
  for slide in range(1, opts.num_slides + 1):
	stats_dic[slide] = numpy.zeros(1)
	stats_dic[-slide] = numpy.zeros(1)
  
  # define dictionary to hold stats for each time slide
  all_stats_dic = {}
  for slide in range(1, opts.num_slides + 1):
        all_stats_dic[slide] = numpy.zeros(1)
        all_stats_dic[-slide] = numpy.zeros(1)
	
  # define array that stores maximum statistic for each of the time slide
  max_stat_array = numpy.zeros(2*opts.num_slides, dtype = float)
  
  # define dictionary of  loudest events in each time slide
  loudest_slides_dic = {}
  for slide in range(1, opts.num_slides + 1):
	loudest_slides_dic[slide] = []
	loudest_slides_dic[-slide] = []

  InspiralUtils.message(opts," reading in time slides ...")
  for file in slidesfiles:
    # read in time slides triggers 
    slidesTriggers = None
    InspiralUtils.message(opts," reading in " + file)
    slidesTriggers = SnglInspiralUtils.ReadSnglInspiralFromFiles([file], non_lsc_tables_ok=True)
    InspiralUtils.message(opts,"reconstructing coincs ...")
    # construct the time slides coincs
    slidesCoincTriggers = CoincInspiralUtils.coincInspiralTable(slidesTriggers, statistic)

    # read InspiralLikelihoodTable if necessary and add likelihood values to coincs  
    if opts.use_likelihood:
      slidesLikelihoodTriggers = inspiral_likelihood.ReadInspiralLikelihoodFromFiles([file])
      # add likelihood values to coincs
      inspiral_likelihood.add_likelihood(slidesCoincTriggers, slidesLikelihoodTriggers)       


    for slide in range(1, opts.num_slides + 1):
      #  triggers in each time slide are sorted in descending order in statistic which is passed to an array

      # for slide forward	  
	  # get loudest coinc in this slide
      forward_slide_coincs = slidesCoincTriggers.getslide(slide)
      if len(forward_slide_coincs) > 0:
		forward_slide_coincs.sort()
		all_stats_dic[slide] = numpy.concatenate((all_stats_dic[slide], forward_slide_coincs.getstat()))
		if len(loudest_slides_dic[slide]) > 0:
		  if forward_slide_coincs[0].stat >= loudest_slides_dic[slide][0].stat:
			loudest_slides_dic[slide][0] = forward_slide_coincs[0]
		else:
		  loudest_slides_dic[slide].append(forward_slide_coincs[0])

	  # store this slide's maximum statistic
      if len(forward_slide_coincs) > 0:
        if opts.use_likelihood:
		  max_stat_array[slide - 1] = max(max_stat_array[slide - 1], numpy.max(forward_slide_coincs.getlikelihood()))
		  stats_dic[slide] = numpy.append(stats_dic[slide], forward_slide_coincs.getlikelihood())
        else:
		  max_stat_array[slide - 1] = max(max_stat_array[slide - 1], numpy.max(forward_slide_coincs.getstat()))
		  stats_dic[slide] = numpy.append(stats_dic[slide], forward_slide_coincs.getstat())
 	
      # for slide backward
	  # get loudest coinc in this slide
      backward_slide_coincs = slidesCoincTriggers.getslide(-slide)
	  
      if len(backward_slide_coincs) > 0:
		backward_slide_coincs.sort()
		all_stats_dic[-slide] = numpy.concatenate((all_stats_dic[-slide], backward_slide_coincs.getstat()))
		if len(loudest_slides_dic[-slide]) > 0:
		  if backward_slide_coincs[0].stat >= loudest_slides_dic[-slide][0].stat:
			loudest_slides_dic[-slide][0] = backward_slide_coincs[0]
		else:
		  loudest_slides_dic[-slide].append(backward_slide_coincs[0])


      # store this slide's  maximum statistic
      if len( backward_slide_coincs) > 0:    
        if opts.use_likelihood:
		  max_stat_array[slide - 1 + opts.num_slides] = max(max_stat_array[slide - 1 + opts.num_slides], numpy.max(backward_slide_coincs.getlikelihood()))
		  stats_dic[-slide] = numpy.append(stats_dic[-slide], backward_slide_coincs.getlikelihood())
        else:
		  max_stat_array[slide - 1 + opts.num_slides] = max(max_stat_array[slide - 1 + opts.num_slides], numpy.max(backward_slide_coincs.getstat()))
		  stats_dic[-slide] = numpy.append(stats_dic[-slide], backward_slide_coincs.getstat())


      # end of the loop over slides
  
  # get rid of zeros
  for key in stats_dic.keys():
	stats_dic[key] = numpy.trim_zeros(stats_dic[key])
  
  for key in all_stats_dic.keys():
        all_stats_dic[key] = numpy.trim_zeros(all_stats_dic[key])

  if opts.save_background_stats:
  
	InspiralUtils.message(opts,"saving max_stat_array into a file ...")
	
	#open output file
	file = open(opts.output_background_file, "w")

	#saving max_stat_array
	cPickle.dump(max_stat_array, file)

	#close file
	file.close()

  InspiralUtils.message(opts, "Done." )
else:
  InspiralUtils.message(opts, "Skiping time slides...")
  InspiralUtils.message(opts, "using max_stat_array from " + str(opts.loudest_background_stats_file))
  
  # open file
  max_stat_file = open(opts.loudest_background_stats_file, "rb")
  
  # get max_stat_array
  max_stat_array = cPickle.load(max_stat_file)


# Make a plot of the loudest time slides before they are sorted
if opts.plot_slides:

  fig_num += 1
  figure(fig_num)

  totalnumberofslides = int(0.5*len(max_stat_array))
  pos_slides=range(1,totalnumberofslides+1)
  all_slides=range(1,totalnumberofslides+1)
  for slidenum in pos_slides:
    all_slides.append(-1*slidenum)

  max_stat_efflikelihood = []
  for stat in max_stat_array:
    max_stat_efflikelihood.append( numpy.log(numpy.exp(stat) - 1.0 + 10**(-10))   )

  slideplot = plotutils.CumulativeHistogramPlot("ln(effective likelihood)","cumulative number","Cumulative histogram of ranking statistic for background slides")
  slideplot.add_content(max_stat_efflikelihood, marker="+", color="red", linestyle="None")

  slideplot.finalize()

  grid(True)
  if opts.enable_output is True:
    name = "loudest_bg_slides"
    text = "Loudest Background in Each Slide"
    fname = InspiralUtils.set_figure_name(opts, name)
    fname_thumb = InspiralUtils.savefig_pylal( filename=fname )
    close()
    fnameList.append(fname)
    tagList.append(text)


# reading in zero lag files
###########################################################################################################################

#sort background stats
max_stat_array = numpy.sort(max_stat_array)

InspiralUtils.message(opts,"Reading zero-lag files ...")
# read in sngl inspiral table
Triggers = SnglInspiralUtils.ReadSnglInspiralFromFiles(zero_lag_files, mangle_event_id=False, non_lsc_tables_ok=True)
NoBgTriggers = SnglInspiralUtils.ReadSnglInspiralFromFiles(no_bg_zero_lag_files, mangle_event_id=False, non_lsc_tables_ok=True)

InspiralUtils.message(opts," reconstructing coincs ...")

# construct coincidence 
CoincTriggers = CoincInspiralUtils.coincInspiralTable(Triggers, statistic)
NoBgCoincTriggers = CoincInspiralUtils.coincInspiralTable(NoBgTriggers, statistic)

# read InspiralLikelihoodTable if necessary  
if opts.use_likelihood:

  LikelihoodTriggers = inspiral_likelihood.ReadInspiralLikelihoodFromFiles(zero_lag_files)
  NoBgLikelihoodTriggers = inspiral_likelihood.ReadInspiralLikelihoodFromFiles(no_bg_zero_lag_files) 
 
  # add likelihood values to coincs
  inspiral_likelihood.add_likelihood(CoincTriggers, LikelihoodTriggers)       
  inspiral_likelihood.add_likeliihood(NoBgCoincTriggers, NoBgLikelihoodTriggers) 

# make the effective likelihood histogram
if opts.make_effective_likelihood_histogram:

  rescaled_zerolag_stat = numpy.log(numpy.exp(CoincTriggers.getstat()) - 1.0 + 10**(-10))

  rescaled_stats_dic = copy.copy(stats_dic)

  for key in rescaled_stats_dic.keys():
    rescaled_stats_dic[key] = numpy.log(numpy.exp(rescaled_stats_dic[key]) - 1.0 + 10**(-10))
	
  fig_num += 1
  figure(fig_num)
  cumhiststat(rescaled_zerolag_stat, rescaled_stats_dic, stat=statistic.name, scalebkg=opts.zero_lag_playground)
  grid(True)
  if opts.enable_output is True:  
    name = "eff_likelihood_cum_hist_" + statistic.name 
    text = " Cumulative histogram of ln(Effective Likelihood) distribution"
    fname = InspiralUtils.set_figure_name(opts, name)
    fname_thumb = InspiralUtils.savefig_pylal( filename=fname )
    close()
    fnameList.append(fname)
    tagList.append(text)


if opts.plot_ifar:
  
  # glob for septime files
  septime_files = glob.glob(opts.septime_files)

  total_slide_time = 0

  for septime_file in septime_files:
    # open file
    timefile = open(septime_file, 'r')
    slide_time = 0
    # read it in line by line
    line_index = 0
    for line in timefile:
      line = line.split()
      line_index += 1
      if line_index ==1 :
        zero_lag_time = float(line[1])
      else:
        slide_time += float(line[1])

    #close file
    timefile.close()

	# increment total slide time
    total_slide_time += slide_time

  zerolag_ifar, slides_ifar = calculate_ifar(CoincTriggers.getstat(), all_stats_dic, total_slide_time)
  
  zerolag_ifar_file = open("zerolag_ifar.pickle", "wb")
  cPickle.dump(zerolag_ifar, zerolag_ifar_file)
  zerolag_ifar_file.close()

  # make a cumulative histogram of ifar
  fig_num += 1
  figure(fig_num)
  log_slides_ifar = {}
  for key in slides_ifar.keys():
    log_slides_ifar[key] = numpy.log10(slides_ifar[key])
  cumhiststat(numpy.log10(zerolag_ifar), log_slides_ifar, stat="ifar", scalebkg=opts.zero_lag_playground)
  grid(True)
  if opts.enable_output is True:
    name = "ifar_cum_hist"
    text = " Cumulative histogram of IFAR distribution"
    fname = InspiralUtils.set_figure_name(opts, name)
    fname_thumb = InspiralUtils.savefig_pylal( filename=fname )
    close()
    fnameList.append(fname)
    tagList.append(text)
		

  # make another ifar plot
  
  zerolag_cum_num = get_cum_num(zerolag_ifar)
  xmin = zerolag_cum_num[0,0]
  xmax = zerolag_cum_num[0,-1]
  ymax = zerolag_cum_num[1, 0]
  
  slides_cum_num = {}
  for key in slides_ifar.keys():
    slides_cum_num[key] = get_cum_num(slides_ifar[key])
    xmin = min(xmin, slides_cum_num[key][0,0])
    xmax = max(xmax, slides_cum_num[key][0,-1])
    ymax = max(ymax, slides_cum_num[key][1,0])

  fig_num += 1
  figure(fig_num)

  for key in slides_cum_num.keys():
    loglog( slides_cum_num[key][0], slides_cum_num[key][1], linestyle='-', color='gray', alpha=0.2, label='_nolegend_')
    hold(True)

  # plot background
  xbkg = numpy.logspace( -4, 2, num=100, endpoint=True, base=10.0 )
  ybkg = (zerolag_cum_num[1,0]*zerolag_cum_num[0,0])*1./xbkg
  loglog( xbkg, ybkg, 'k--', linewidth=2, label='_nolegend_' )
  # plot error
  bkgplus = ybkg + sqrt(ybkg)
  bkgminus = ybkg - sqrt(ybkg)
  bkgminus = where( bkgminus<=0, 1e-5, bkgminus ) # prevent (-) values
  xs, ys = poly_between( xbkg, bkgminus, bkgplus )
  fill( xs, ys, facecolor='y', alpha=0.4, label='_nolegend_' )

  bkgplus = ybkg + 2*sqrt(ybkg)
  bkgminus = ybkg - 2*sqrt(ybkg)
  bkgminus = where( bkgminus<=0, 1e-5, bkgminus ) # prevent (-) values
  xs, ys = poly_between( xbkg, bkgminus, bkgplus )
  fill( xs, ys, facecolor='y', alpha=0.2, label='_nolegend_' )


  # plot foreground
  loglog( zerolag_cum_num[0], zerolag_cum_num[1], marker='^', linestyle='None', markerfacecolor='b', markeredgecolor='k', alpha=0.9, label='Combined Triggers' )

  xlabel( r"Inverse False Alarm Rate (years)", size='x-large' )
  ylabel( r"Cumulative \#", size='x-large' )
  legend()
  xlim(xmin*0.8, xmax*1.1)
  ylim(0.5*zerolag_cum_num[1,0]*zerolag_cum_num[0,0]/(xmax*1.1), ymax*1.1)

  if opts.enable_output is True:
    name = "another_ifar_plot"
    text = "Combined Cumulative Histogram of IFAR distribution"
    fname = InspiralUtils.set_figure_name(opts, name)
    fname_thumb = InspiralUtils.savefig_pylal( filename=fname )
    close()
    fnameList.append(fname)
    tagList.append(text)



# getting N loudest zero-lag candidates
###########################################################################################################################

# sort coincs in descending order according to their statistic
CoincTriggers.sort()
NoBgCoincTriggers.sort()

#Make an empty table to put the first N coincs in
loudest_coincs = CoincInspiralUtils.coincInspiralTable(stat = CoincTriggers.stat)
loudest_coincs.extend(CoincTriggers[:opts.num_events])

# For each of the loudest coincs calculate false alarm probability
loudest_coincs.calculate_fap(stats = max_stat_array)

# For each of the no_bg loudest coincs, set the fap to 0 (since the beta column contains the efficiency factor)
for coinc in NoBgCoincTriggers:
  coinc.fap = 0.0


# make scatter plot of mchrip vs statistic

if opts.plot_mchirp_vs_stat or opts.plot_mchirp_vs_effective_snr:
  loudest_background_coincs = CoincInspiralUtils.coincInspiralTable(stat = statistic)
  
  for key in loudest_slides_dic.keys():
	loudest_background_coincs.append(loudest_slides_dic[key][0])
  
  if opts.plot_mchirp_vs_stat:
	background_mchirps = numpy.zeros(len(loudest_background_coincs))
	background_stats = numpy.zeros(len(loudest_background_coincs))
	for (i, coinc) in enumerate(loudest_background_coincs):
	  background_mchirps[i] = sum(t.mchirp for t in coinc) / coinc.numifos
	  background_stats[i] = numpy.log(numpy.exp(coinc.stat) - 1.0 + 10**(-10))
	  
	loudest_zerolag_mchirp = sum(t.mchirp for t in loudest_coincs[0]) / loudest_coincs[0].numifos  
	loudest_zerolag_stat = numpy.log(numpy.exp(loudest_coincs[0].stat) - 1.0 + 10**(-10))
	
	fig_num += 1
	figure(fig_num)
	legend_text = []
	plot(background_stats, background_mchirps, "kv")
	legend_text.append("time slides")
	hold(True)
	plot([loudest_zerolag_stat], [loudest_zerolag_mchirp], "b^")
	legend_text.append("zero lag")
	axhline(y=0.87, color="b")
	hold(True)
	axhline(y=3.48, color="b")
	hold(True)
	axhline(y=7.4, color="b")
	hold(True)
	axhline(y=15.24, color="b")
	grid(True)
	ylabel('chrip mass', size='xx-large')
	xlabel('ln(effective likelihood)', size='xx-large')
	title("Loudest events: zero lag vs time slides", size='xx-large')
	leg = legend(legend_text,loc=0)
	leg_text=leg.get_texts()
	setp(leg_text,fontsize='x-large')

	
	if opts.enable_output is True:  
	  name = "mchrip_vs_stat_" + statistic.name 
	  text = " Scatter plot chirp mass vs ranking statistic "
	  fname = InspiralUtils.set_figure_name(opts, name)
	  fname_thumb = InspiralUtils.savefig_pylal( filename=fname )
	  close()
	  fnameList.append(fname)
	  tagList.append(text)
	  
  if opts.plot_mchirp_vs_effective_snr:
	background_mchirps = numpy.zeros(len(loudest_background_coincs))
	background_eff_snrs = numpy.zeros(len(loudest_background_coincs))
	for (i, coinc) in enumerate(loudest_background_coincs):
	  background_mchirps[i] = sum(t.mchirp for t in coinc) / coinc.numifos
	  background_eff_snrs[i] = (sum(t.get_effective_snr()**2.0 for t in coinc))**(1.0/2.0) 
	  
	loudest_zerolag_mchirp = sum(t.mchirp for t in loudest_coincs[0]) / loudest_coincs[0].numifos  
	loudest_zerolag_eff_snr = (sum(t.get_effective_snr()**2.0 for t in loudest_coincs[0]))**(1.0/2.0)
	
	fig_num += 1
	figure(fig_num)
	legend_text = []
	plot(background_eff_snrs, background_mchirps, "kv")
	legend_text.append("time slides")
	hold(True)
	plot([loudest_zerolag_eff_snr], [loudest_zerolag_mchirp], "b^")
	legend_text.append("zero lag")
	hold(True)
	axhline(y=0.87, color="b")
	hold(True)
	axhline(y=3.48, color="b")
	hold(True)
	axhline(y=7.4, color="b")
	hold(True)
	axhline(y=15.24, color="b")
	grid(True)
	ylabel('chrip mass', size='xx-large')
	xlabel('effective snr', size='xx-large')
	title("Loudest events: zero lag vs time slides", size='xx-large')
	leg = legend(legend_text,loc=0)
	leg_text=leg.get_texts()
	setp(leg_text,fontsize='x-large')

	
	if opts.enable_output is True:  
	  name = "mchrip_vs_effective_snr_" + statistic.name 
	  text = "Scatter plot chirp mass vs effective snr "
	  fname = InspiralUtils.set_figure_name(opts, name)
	  fname_thumb = InspiralUtils.savefig_pylal( filename=fname )
	  close()
	  fnameList.append(fname)
	  tagList.append(text)

if opts.plot_efactors:

  fig_num += 1
  figure(fig_num)

  eff_file = open(opts.efactors_file,"rb")
  eff_factors = cPickle.load(eff_file)

  ifo_list = [ifo for ifo in ("G1", "H1", "H2", "L1", "V1") if getattr(opts, "%s_triggers" % ifo.lower())]

  ifo_times = CoincInspiralUtils.get_ifo_combos(ifo_list)

  # Make a list of all the ifotype_ifotime categories. Make an additional list that is LaTeX-friendly and has a \ in front of the _.
  categorylist = []
  latexcategorylist = []

  for ifo_time in ifo_times:                                                                  
    ifo_types = CoincInspiralUtils.get_ifo_combos(ifo_time)
    for ifo_type in ifo_types:
      categorylist.append("".join(ifo_type) + "_" + "".join(ifo_time))
      latexcategorylist.append("".join(ifo_type) + "\_" + "".join(ifo_time))

  eff_vals = []
  for category in categorylist:
    eff_vals.append(eff_factors[category])

  categorytuple = tuple(latexcategorylist)

  categorycount = range(0,33)
  width = 0.35

  axes([0.2,0.125,0.75,0.75])
  barh(categorycount, eff_vals, color='r')
  xlabel('Efficiency Factors', size='xx-large')
  title('Efficiency Factors for Injections', size='xx-large')
  yticks([i+width/2. for i in categorycount], categorytuple, rotation=0, size='x-small' )
  grid()

  if opts.enable_output is True:
    name = "efficiencyfactorshist"
    text = "Efficiency Factors"
    fname = InspiralUtils.set_figure_name(opts, name)
    fname_thumb = InspiralUtils.savefig_pylal( filename=fname )
    close()
    fnameList.append(fname)
    tagList.append(text)
	  
if opts.enable_output is True:
  if opts.verbose: print >> sys.stdout, "Writing html file and cache."

  coincTList = []
  nobgcoincTList = []

  commentList = []
  nobgcommentList = []
  
  coincTList.append(loudest_coincs)
  nobgcoincTList.append(NoBgCoincTriggers)
  
  commentList.append(str(opts.num_events) + ' loudest events of the search ' )
  nobgcommentList.append('Loudest events of the search that have no estimated background because they are louder than all time slides in their category' )

  # MAKE THE SUMMARY TABLE
  coincSumm = InspiralUtils.write_coinc_summ_table(
        tableList = coincTList, commentList = commentList, stat = statistic,
        statTag = opts.statistic, number= opts.num_events, format='html')

  # MAKE THE NO_BACKGROUND SUMMARY TABLE (LABEL THE STATISTIC EFFICIENCY)
  nobgcoincSumm = InspiralUtils.write_coinc_summ_table(
        tableList = nobgcoincTList, commentList = nobgcommentList, stat = statistic,
        statTag = 'Efficiency Factor', number= opts.num_events, format='html')

  page, extra = init_markup_page(opts)
  page.h1("Summary of Loudest Events")
  page.hr()
  html_filename = opts.output_path + "/loudesteventsummary.html"
  html_file = open(html_filename,"w")
 
  for tag,filename in zip(tagList,fnameList):
    fname = "Images/" + os.path.basename(filename)
    fname_thumb = fname[:-4] + "_thumb.png"
    page.a(extra.img(src=[fname_thumb], width=400, \
        alt=tag, border="2"), title=tag, href=[ fname])

  page.add("<hr/>")
  page.add(coincSumm)
  page.hr()
  page.add(nobgcoincSumm)
  page.hr()
  text = writeProcessParams( opts.name, opts.version,  args)
  page.add(text)
  html_file.write(page(False))
  html_file.close()

  write_cache_output(opts, html_filename, fnameList)

# save loudest coincs in found in zero-lag and each of the time slides

loudest_zerolag_file = open(opts.output_path + "/loudest_zerolag.xml", "w")
# create xml doc
output_doc = ligolw.Document()

#create LIGO_LW element
output_ligo_lw = ligolw.LIGO_LW()

#append it to xml doc
output_doc.appendChild(output_ligo_lw)

#get sngl inspiral table from coinc table
sngl_table = lsctables.New(lsctables.SnglInspiralTable)
ifos, ifolist = loudest_coincs[0].get_ifos()
for ifo in ifolist:
  sngl_table.append(getattr(loudest_coincs[0], ifo))
  
output_doc.childNodes[0].appendChild(sngl_table)

#writing xml doc to the output file
output_doc.write(loudest_zerolag_file)
loudest_zerolag_file.close()

loudest_timeslides_file = open(opts.output_path + "/loudest_timeslides.xml", "w")
# create xml doc
output_doc = ligolw.Document()

#create LIGO_LW element
output_ligo_lw = ligolw.LIGO_LW()

#append it to xml doc
output_doc.appendChild(output_ligo_lw)

#get sngl inspiral table from coinc table
sngl_table = lsctables.New(lsctables.SnglInspiralTable)
for key in loudest_slides_dic.keys():
  ifos, ifolist = loudest_slides_dic[key][0].get_ifos()
  for ifo in ifolist:
	sngl_table.append(getattr(loudest_slides_dic[key][0], ifo))

output_doc.childNodes[0].appendChild(sngl_table)
#writing xml doc to the output file
output_doc.write(loudest_timeslides_file)
loudest_timeslides_file.close()





