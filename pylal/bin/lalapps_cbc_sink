#!/usr/bin/python
import sys, os
from optparse import OptionParser
from pylal import rate
from pylal import SimInspiralUtils
from pylal import InspiralUtils
import scipy
from scipy import interpolate
import numpy
import matplotlib
matplotlib.use('Agg')
import pylab
from math import *
import sys
import glob
import copy
import bisect
from glue.ligolw.utils import ligolw_add
from glue.ligolw import table
from glue.ligolw import array
from glue.ligolw import lsctables
from glue.ligolw.utils import print_tables
from glue.ligolw import ligolw, utils
from glue import lal
from glue import iterutils

from pylal import upper_limit_utils
from pylal.xlal import constants

from pylal import git_version
__author__ = "Stephen Privitera <sprivite@caltech.edu>"
__version__ = "git id %s" % git_version.id
__date__ = git_version.date
__prog__ = "lalapps_cbc_sink"


# FIXME:  the latex rendering sucks :(
matplotlib.rcParams.update({"text.usetex": False})

Mpc3_per_L10 = 50.0 #FIXME

def edges(bins):
  """Get the boundary points of a rate.NDBins object."""
  return tuple( numpy.concatenate((l,u[-1:])) for l,u in zip(bins.lower(),bins.upper()) )


def get_bins(file,bin_type):
	xmldoc = utils.load_filename(file, gz = (file or "stdin").endswith(".gz")).childNodes[0]
	mbins = xmldoc.getChildrenByAttributes({"Name":"mass_bins:%s" % bin_type})
	if len(mbins) == 1:
		mbins = array.get_array(mbins[0],u"array").array
	else:
		print >>sys.stderr,"XML must contain exactly 1 mass bin. Found %d."%len(mbins)
		sys.exit(1)

        bins = rate.NDBins((rate.IrregularBins(mbins),))

	return bins


def get_data(file,tablename):
	"""Read in data produced by lalapps_cbc_svim"""

	xmldoc = utils.load_filename(file, gz = (file or "stdin").endswith(".gz"))
	xmldoc = xmldoc.childNodes[0]
	table_node = xmldoc.getChildrenByAttributes({"Name":"binned_array:%s" % tablename})
	if len(table_node) != 1:
		print >>sys.stderr,"XML must contain exactly 1 table %s. Found %d."% (tab,len(table_node))
		sys.exit(1)

	return array.get_array(table_node[0],u"array").array


def savefig_pylal(plot_description, open_box, inspiral_utils_opts, fnameList, tagList):
	name = InspiralUtils.set_figure_tag( plot_description, open_box = opts.open_box)
	fname = InspiralUtils.set_figure_name(inspiral_utils_opts, name)
	fname_thumb = InspiralUtils.savefig_pylal( filename=fname )
	fnameList.append(fname)
	tagList.append(name)


class UpperLimitTable(table.Table):
	tableName = "upper_limit:table"

        validcolumns = {"mass_bin":"lstring",
                        "sensitivity_in_L10_yr":"lstring",
                        "avg_reach_in_L10s":"lstring",
                        "avg_reach_in_Mpc":"lstring",
                        "lambda_ratio":"lstring",
                        "fractional_error":"lstring",
                        "upper_limit_in_mergers_per_L10_per_yr":"lstring",
                        "effective_numerator":"lstring",
                        "livetime_in_days":"lstring",
                        "injs_found":"int_4s",
                        "injs_missed":"int_4s"}


def parse_command_line():
	parser = OptionParser(version = "Name: %%prog\n%s" % git_version.verbose_msg)

	# Note: an input cache is required
	parser.add_option("","--input-cache", action = "append", default = [],
                          help="Add an input cache containing the lalapps_cbc_svim xml files you want to run on")
	parser.add_option("-f", "--output-format", action = "store", type = "string",
			  default = "html", metavar = "wiki, html, OR xml",
			  help = "Format of output summary table. Choices are 'wiki', 'html', or 'xml'. Default is html.")
	parser.add_option("--output-path", default = "./", action = "store",
			  help="Choose directory to save output files.")
	parser.add_option("--open-box", default = False, action = "store_true",
			  help="Turn flag on to indicate that input data describes zero-lag coincident events.")
        parser.add_option("--user-tag",default = '',help = "Add a descriptive string to the output file names.")
        parser.add_option("--prior-cache",default = None, help = "Specify a cache file containing rate priors. The first column of the files in the cache will be interpreseted as the rate. The second column will be interpreted as the posterior density. The description field of the cache file should indicate the number of the mass bin to which the prior corresponds, counting up from 1, the lowest bin .")
        ##########################

	opts, files = parser.parse_args()

        files += opts.input_cache
        opts.input_cache = lal.Cache([])
        for f in files: opts.input_cache |= lal.Cache.fromfile(open(f))

	opts.gps_extent =  opts.input_cache.to_segmentlistdict().extent()
	opts.enable_output = True

	return opts


opts  = parse_command_line()


# a lot of work to get the list of instruments that were used
def any(iterable):
  for element in iterable:
    if element: return True
  return False

combined_ifos = ''
for ifo in ['H1','L1','V1']:
  if any( ifo in entry.observatory for entry in opts.input_cache ):
    combined_ifos += ifo


for bin_type in ["Chirp_Mass","Total_Mass","Component_Mass","BNS_BBH"]:

   __prog__ = "lalapps_cbc_sink_by_"+bin_type.lower() # have you ever met a program with multiple identities?
   total_vol = total_err = total_found = total_missed = total_lt = 0

   files = opts.input_cache.sieve(description=bin_type)
   if len(files) == 0: continue

   # read in the data produced by lalapps_cbc_svim
   bins = get_bins(files[0].path(),bin_type) # better use same binning in all files!!
   vols = [rate.BinnedArray(bins,array=get_data(entry.path(),"SearchVolumeFirstMoment")) for entry in files]
   volErrs = [rate.BinnedArray(bins,array=get_data(entry.path(),"SearchVolumeSecondMoment")) for entry in files]
   volDerivs = [rate.BinnedArray(bins,array=get_data(entry.path(),"SearchVolumeDerivative")) for entry in files]
   foundInjs = [rate.BinnedArray(bins,array=get_data(entry.path(),"SearchVolumeFoundInjections")) for entry in files]
   missedInjs = [rate.BinnedArray(bins,array=get_data(entry.path(),"SearchVolumeMissedInjections")) for entry in files]
   livetimes = [rate.BinnedArray(bins,array=get_data(entry.path(),"SearchVolumeLiveTime")) for entry in files]

   # get some aggregate data
   total_vol = rate.BinnedArray(bins,array=numpy.sum(a.array for a in vols))
   total_err = rate.BinnedArray(bins,array=numpy.sum(a.array**2 for a in volErrs))
   total_found = rate.BinnedArray(bins,array=numpy.sum(a.array for a in foundInjs))
   total_missed = rate.BinnedArray(bins,array=numpy.sum(a.array for a in missedInjs))
   total_lt = rate.BinnedArray(bins,array=numpy.sum(a.array for a in livetimes))

   # get mass ranges
   mrange = [(min(b),max(b)) for b in edges(bins)]

   # Initialize inspiral utility plotting helper
   __prog__ = "lalapps_cbc_combined_sink_by_"+bin_type.lower()
   opts.ifo_times = combined_ifos
   opts.gps_start_time = numpy.min([entry.segment[0] for entry in files])
   opts.gps_end_time = numpy.max([entry.segment[1] for entry in files])
   InspiralUtilsOpts = InspiralUtils.initialise( opts, __prog__, git_version.verbose_msg )
   fnameList = []; tagList = []

   combined_upper_limit = rate.BinnedArray(bins)

   # Gather priors.
   if opts.prior_cache:
     priors = lal.Cache.fromfile(open(opts.prior_cache))
   else:
     priors = lal.Cache([])

   mu_min = 1e-7 #FIXME don't hardcode rates
   mu_max = 1e-1
   mu = numpy.arange(0,mu_max,mu_min) #FIXME hardcoded rates are bad

   # compute the combined posterior with errors included
   for j,mbin in enumerate(iterutils.MultiIter(*bins.centres())):
     pk = priors.sieve(description=bin_type+":"+str(j+1))
     length = 100000
     if len(pk) == 1: # use given prior
       mu_in = numpy.loadtxt(pk[0].path())[:,0]
       prior = numpy.loadtxt(pk[0].path())[:,1]
       #create a linear spline representation of the prior, with no smoothing
       prior = interpolate.splrep(mu_in, prior, s=0, k=1)
       #choose new values for mu and interpolate the prior to these new values
       prior = interpolate.splev(mu, prior)
       prior[prior < 0] = 0 #prevent interpolation from giving negative probs
     elif len(pk) > 1:
       print [p.path() for p in pk]
       print >>sys.stderr, "Too many priors given in input cache."
       sys.exit(1)
     else: # use flat prior
       prior = numpy.ones(len(mu))

     # compute posterior/upper limits marginalizing over uncertainties
     combined_post = prior
     for vol,vol2,lam in zip(vols,volErrs,volDerivs):
       mu, combined_post = upper_limit_utils.compute_posterior(vol[mbin],vol2[mbin],lam[mbin],mu,combined_post)
     combined_post /= combined_post.sum()
     combined_upper_limit[mbin] = upper_limit_utils.compute_upper_limit(mu, combined_post, 0.90)

     if combined_upper_limit[mbin] == 0: continue
     pylab.figure(1)
     pylab.semilogx(mu,combined_post/combined_post.sum(),label=','.join(["%.1f"%m for m in mbin])+"M$_{\odot}$")
     pylab.figure(2)
     pylab.semilogx(mu,combined_post.cumsum(),label=','.join(["%.1f"%m for m in mbin])+"M$_{\odot}$")
     pylab.figure(3)
     pylab.semilogx(mu,prior/prior.sum(),label=','.join(["%.1f"%m for m in mbin])+"M$_{\odot}$")

   pylab.figure(1)
   pylab.title(combined_ifos+ " Combined Posterior Rate PDF",fontsize=14)
   pylab.legend(loc='lower right')
   pylab.ylabel("Probability",fontsize=14)
   pylab.xlabel("Merger Rate (1/L10/yr)",fontsize=14)
   pylab.grid()
   pylab.xlim([mu_min, mu_max]) #FIXME hardcoded rate limits are bad for advanced ligo
   #pylab.ylim([0, 1e-1])
   savefig_pylal('combined_posterior_density', opts.open_box, InspiralUtilsOpts,fnameList,tagList)
   pylab.clf()

   pylab.figure(2)
   pylab.title(combined_ifos+ " Combined Cumulative Posterior Rate Distributions",fontsize=14)
   pylab.legend(loc='lower right')
   pylab.ylabel("Cumulative Probability",fontsize=14)
   pylab.xlabel("Merger Rate (1/L10/yr)",fontsize=14)
   pylab.ylim([1e-2, 1])
   pylab.grid()
   pylab.xlim([mu_min, mu_max]) #FIXME hardcoded rate limits are bad for advanced ligo
   savefig_pylal('combined_posterior', opts.open_box, InspiralUtilsOpts,fnameList,tagList)
   pylab.clf()

   pylab.figure(3)
   pylab.title(combined_ifos+ " Prior Rate Distributions",fontsize=14)
   pylab.legend(loc='lower right')
   pylab.ylabel("Cumulative Probability",fontsize=14)
   pylab.xlabel("Merger Rate (1/L10/yr)",fontsize=14)
   pylab.grid()
   pylab.xlim([mu_min, mu_max]) #FIXME hardcoded rate limits are bad for advanced ligo
   savefig_pylal('prior', opts.open_box, InspiralUtilsOpts,fnameList,tagList)
   pylab.clf()


   tick_locs = edges(bins)[0]
   if bin_type == "BNS_BBH":
     tick_locs += 0.5 #center the labels
     tick_strings = ["BNS","NSBH","BBH"]
   else:
     tick_strings = ["%.1f"% m for m in tick_locs]

   #
   # combined upper limit plot
   #
   fudge = 1e-9
   width = bins.upper()[0]-bins.lower()[0]
   top = pylab.log10(combined_upper_limit.array + fudge)
   bottom = pylab.log10(1e-10)
   pylab.bar(bins.lower()[0],top-bottom,width, bottom = bottom, color='b')
   pylab.title("Combined 90%s Upper Limit (%.1f days livetime)"%('%',total_lt.array[0]*constants.LAL_YRJUL_SI/(3600*24)),fontsize=14)
   pylab.xticks(tick_locs,tick_strings)
   pylab.xlim([numpy.min(bins.lower()[0])-numpy.min(width)/2,numpy.max(bins.upper()[0])+numpy.min(width)/2])
   pylab.ylim([numpy.log10(mu_min),numpy.log10(mu_max)])
   pylab.xlabel(bin_type.replace('_',' ') + " (M$_{\odot}$)",fontsize=14)
   pylab.ylabel("Rate (log$_{10}$ 1/L10/yr)", fontsize=14)
   pylab.grid()
   savefig_pylal('combined_upper_limit_plot', opts.open_box, InspiralUtilsOpts,fnameList,tagList)
   pylab.clf()

   #
   # distance plot in 1d
   #
   distance = (Mpc3_per_L10*total_vol.array/total_lt.array /(4*numpy.pi/3) )**(1./3)
   derr = (distance /3) *( total_err.array**0.5 / total_vol.array ) # fractional error in distance is 1/3 fractional error in volume
   pylab.bar(bins.lower()[0],distance,width,yerr=derr)
   pylab.grid()
   pylab.xticks(tick_locs,tick_strings)
   pylab.xlim([numpy.min(bins.lower()[0])-numpy.min(width)/2,numpy.max(bins.upper()[0])+numpy.min(width)/2])
   pylab.title("%s Search Range (%.1f days livetime)"%(combined_ifos,total_lt.array[0]*constants.LAL_YRJUL_SI/(3600*24)),fontsize=14)
   pylab.xlabel(bin_type.replace('_',' ') + " (M$_{\odot}$)",fontsize=14)
   pylab.ylim([0,100])
   pylab.ylabel("Range (Mpc)",fontsize=14)
   savefig_pylal("combined_distance", opts.open_box, InspiralUtilsOpts,fnameList,tagList)
   pylab.clf()

   plothtml = InspiralUtils.write_html_output( InspiralUtilsOpts, [], fnameList,
					       tagList, add_box_flag = False ) #FIXME
   InspiralUtils.write_cache_output( InspiralUtilsOpts, plothtml, fnameList )

   #
   # write out a summary table
   #
   summary_file = open( '%s%s-%s_combined_upper_limit_%s-%d-%d.%s'%(opts.output_path,combined_ifos,__prog__,opts.user_tag,opts.gps_start_time, opts.gps_end_time-opts.gps_start_time, opts.output_format),'w')
   summary_doc = ligolw.Document()
   summary_doc.appendChild(ligolw.LIGO_LW())
   ul_table = lsctables.New(UpperLimitTable)
   summary_doc.childNodes[0].appendChild(ul_table)

   for mbin in iterutils.MultiIter(*bins.centres()):

      row = ul_table.RowType()

      row.mass_bin = "%.1f-%.1f"%(bins.lower()[0][bins[mbin][0]],bins.upper()[0][bins[mbin][0]])
      row.sensitivity_in_L10_yr = "%.3g" % (total_vol[mbin],)
      row.livetime_in_days = "%f" % (total_lt[mbin]*constants.LAL_YRJUL_SI/(3600*24),)
      row.avg_reach_in_L10s = "%.3g" % (total_vol[mbin]/total_lt[mbin],)
      row.avg_reach_in_Mpc = "%.1f" % ((Mpc3_per_L10*total_vol[mbin]/total_lt[mbin] /(4*numpy.pi/3) )**(1./3),)
      row.upper_limit_in_mergers_per_L10_per_yr = "%.3g" % (combined_upper_limit[mbin],)
      row.effective_numerator = "%.2f" % (combined_upper_limit[mbin]*total_vol[mbin],)
      row.fractional_error = "%.2f" % (total_err[mbin]**0.5 / total_vol[mbin],)
      row.injs_found = total_found[mbin]
      row.injs_missed = total_missed[mbin]

      ul_table.append(row)

   columnList = ['mass_bin','sensitivity_in_L10_yr','livetime_in_days','avg_reach_in_L10s','avg_reach_in_Mpc','upper_limit_in_mergers_per_L10_per_yr','effective_numerator','fractional_error','injs_found','injs_missed']
   print_tables.print_tables(summary_doc,summary_file,opts.output_format,
			     tableList=['upper_limit'],
			     columnList = columnList)
   summary_file.close()


print >> sys.stderr, "ALL FINNISH!"
