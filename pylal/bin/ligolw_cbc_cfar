#!/usr/bin/env python

#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#


from optparse import OptionParser
try:
    import sqlite3
except ImportError:
    # pre 2.5.x
    from pysqlite2 import dbapi2 as sqlite3
import sys
import os

from pylal import ligolw_sqlutils as sqlutils

from glue.ligolw import dbtables
from glue.ligolw.utils import process
from glue.ligolw.utils.ligolw_sqlite import extract

usage = \
'''
Calculates uncombined and combined false alarm rates (FAR) in units of yr^(-1).
Writes results out to a new database.
'''

__author__ = "Collin Capano <cdcapano@physics.syr.edu>"
__date__ = "$Date$" 
__version__ = "$Revision$"


# =============================================================================
#
#                                   Set Options
#
# =============================================================================


def parse_command_line():
    """
    Parse the command line, return options and check for consistency among the
    options.
    """
    parser = OptionParser( version = "", usage = usage )

    # following are related to file input and output naming
    parser.add_option( "-i", "--input", action = "store", type = "string", default = None,
        help = 
            "Input database to read. Can only input one at a time."
            )
    parser.add_option( "-o", "--output", action = "store", type = "string", default = None,
        help = 
            "Name of output database to save to."
            )
    parser.add_option( "-x", "--write-xml-file", action = "store", type = "string", default = None,
        help =
            "Writes output to specified xml file. Warning: for larger databases, this can take awhile."
            )
    parser.add_option( "-t", "--temp-space", action = "store", type = "string", default = None,
        metavar = "PATH",
        help = 
            "Requried. Location of local disk on which to do work. " +
            "This is used to enhance performance in a networked " +
            "environment, and to protect against accidently " +      
            "overwriting the input database."
            )
    parser.add_option( "-v", "--verbose", action = "store_true", default = False,
        help = 
            "Print progress information"
           )
    parser.add_option( "-d", "--debug", action = "store_true", default = False,
        help =
            "Print SQLite queries used and the approximate time taken to run each one." )
    # following are generic inspiral_sql options
    parser.add_option( "", "--param-name", action = "store", default = None,
        metavar = "PARAMETER", 
        help = 
            "Can be any parameter in the coinc_inspiral table. " + 
            "Specifying this and param-ranges defines the categories " +
            "which the uncombined_fars are calculated in and are " +
            "combined over in the combined far calculation. " +
            "If not specified, triggers will not be binned when calculating " +
            "the uncombined FAR and so the uncombined FAR will be the same as " +
            "the combined FAR."
             )
    parser.add_option( "", "--param-ranges", action = "store", default = None,
        metavar = " [ LOW1, HIGH1 ); ( LOW2, HIGH2]; etc.",
        help = 
            "Requires --param-name. Specify the parameter ranges " +
            "to bin the triggers in. A '(' or ')' implies an open " +
            "boundary, a '[' or ']' a closed boundary. To specify " +
            "multiple ranges, separate each range by a ';'. Any " +
            "coincidences that fall outside of the union of all " +
            "specified ranges will be deleted." 
            )
    parser.add_option( "", "--exclude-coincs", action = "store", type = "string", default = None,
        metavar = " [COINC_INSTRUMENTS1 + COINC_INSTRUMENTS2 in INSTRUMENTS_ON1];" +
            "[ALL in INSTRUMENTS_ON2]; etc.",
        help = 
            "Exclude coincident types in specified detector times, " + 
            "e.g., '[H2,L1 in H1,H2,L1]'. Some rules: " +             
                "* Coinc-types and detector time must be separated by " + 
                "an ' in '. When specifying a coinc_type or detector " +
                "time, detectors and/or ifos must be separated by " +
                "commas, e.g. 'H1,L1' not 'H1L1'. " + 
                "* To specify multiple coinc-types in one type of time, " +
                "separate each coinc-type by a '+', e.g., " +
                "'[H1,H2 + H2,L1 in H1,H2,L1]'. " +
                "* To exclude all coincs in a specified detector time " +
                "or specific coinc-type in all times, use 'ALL'. E.g., " +
                "to exclude all H1,H2 triggers, use '[H1,H2 in ALL]' " +
                "or to exclude all H2,L1 time use '[ALL in H2,L1]'. " +
                "* To specify multiple exclusions, separate each " +
                "bracket by a ';'. " +
                "* Order of the instruments nor case of the letters " +
                "matter. So if your pinky is broken and you're " +
                "dyslexic you can type '[h2,h1 in all]' without a " +
                "problem. " 
            )
    parser.add_option( "", "--include-only-coincs", action = "store", type = "string", default = None,
        metavar = " [COINC_INSTRUMENTS1 + COINC_INSTRUMENTS2 in INSTRUMENTS_ON1];" +
            "[ALL in INSTRUMENTS_ON2]; etc.",
        help =
            "Opposite of --exclude-coincs: fars will be calculated " +
            "for the specified coinc types only (all other coincs will be " +
            "deleted from the output database). To avoid confusing overlaps, " +
            "cannot specify both --exclude-coincs and --include-only-coincs." 
            )
    parser.add_option( "", "--vacuum", action = "store_true", default = False,
        help = 
            "If turned on, will vacuum the database before saving. " +
            "This cleans any fragmentation and removes empty space " +
            "left behind by all the DELETEs, making the output " +
            "database smaller and more efficient. " +
            "WARNING: Since this requires rebuilding the entire " +
            "database, this can take awhile for larger files." 
            )
    # following are options specific to this program
    parser.add_option( "", "--ranking-stat", action = "store", type = "string", default = None,
        help =
            "Required. The stat to use to rank triggers for calculating " +
            "the false alarm rate. Can be any column in the coinc_inspiral table." 
            )
    parser.add_option( "", "--rank-by", action = "store", type = "string", default = None, 
        metavar = "MAX or MIN",
        help = 
            "Requried. Options are MAX or MIN. " +
            "This specifies whether to rank triggers by ascending (MAX) or " +
            "descending (MIN) stat value." 
            )
    parser.add_option( "", "--combine-fars", action = "store", type = "string", default = None, 
        metavar = "across_all, across_param_only",
        help = 
            "Required. Tell cfar what categories to combine uncombined fars across. " +
            "Options are across_all or across_param_only. " +
            "If across_all, will combine FARs across both coinc-types and parameter grouping. " +
            "If across_param_only, will only combine FARs across the parameter grouping." 
            )
  
    (options, args) = parser.parse_args()
  
    # check for required options and for self-consistency
    if not options.input:
        raise ValueError, "No input specified."
    if not options.output:
        raise ValueError, "No output specified."
    if not options.temp_space:
        raise ValueError, "--temp-space is a requred argument."
    if not options.ranking_stat:
        raise ValueError, "No ranking stat specified."
    if not (options.rank_by.upper() == 'MAX' or options.rank_by.upper() == 'MIN'):
        raise ValueError, "--rank-by must be specified and set to either MAX or MIN."
    if options.param_name and not options.param_ranges:
        raise ValueError, "param-name requires param-ranges"
    if options.param_ranges and not options.param_name:
        raise ValueError, "param-ranges requires param-name"
    if not options.combine_fars:
        raise ValueError, "combine_fars is a requried argument."
    if not (options.combine_fars == 'across_all' or options.combine_fars == 'across_param_only'):
        raise ValueError, "combine-fars must be set to either across_all or across_param_only"
    if options.exclude_coincs and options.include_only_coincs:
        raise ValueError, "Cannot specify both --exclude-coincs and --include-only-coincs."

    return options, sys.argv[1:]


# =============================================================================
#
#                       Function Definitions
#
# =============================================================================

def convert_to_yrs( duration ):
    """
    Uses sqlutils.convert_duration to automatically convert the frg_durs
    to years. 
    """
    return sqlutils.convert_duration( duration, 'yr' )
                   

# =============================================================================
#
#                                     Main
#
# =============================================================================

#
#       Generic Initilization
#

opts, args = parse_command_line()

# get input database filename
filename = opts.input
if not os.path.isfile( filename ):
    raise ValueError, "The input file, %s, cannot be found." % filename

# Setup working databases and connections
if opts.verbose: 
    print >> sys.stdout, "Setting up temp. database..."
working_filename = dbtables.get_connection_filename( 
    filename, tmp_path = opts.temp_space, verbose = opts.verbose )
connection = sqlite3.connect( working_filename )
dbtables.DBTable_set_connection( connection )

# Add program to process and process params table

# FIXME: remove the following two lines once boolean type
# has been properly handled
from glue.ligolw import types as ligolwtypes
ligolwtypes.FromPyType[type(True)] = ligolwtypes.FromPyType[type(8)]

# create an xmldoc representation of the database for writing the
# process and process-params
xmldoc = dbtables.get_xml(connection)
# Add entries to process and process_params tables for this program
proc_id = process.register_to_xmldoc(xmldoc, 'ligolw_cbc_cfar', opts.__dict__)

# Get param and param-ranges if specified
if opts.param_name:
    param_parser = sqlutils.parse_param_ranges( 'coinc_inspiral', opts.param_name, 
      opts.param_ranges, verbose = opts.verbose )
    param_name = param_parser.get_param_name()
    param_filters = param_parser.get_param_filters()
else:
    param_filters = None

# Get exclude_coincs list if specified
if opts.exclude_coincs:
    exclude_coinc_filters = sqlutils.parse_coinc_options( opts.exclude_coincs, 
        verbose = opts.verbose ).get_coinc_filters()
else:
    exclude_coinc_filters = None

# Get include_coincs list if specified
if opts.include_only_coincs:
    include_coinc_filters = sqlutils.parse_coinc_options( opts.include_only_coincs, 
        verbose = opts.verbose ).get_coinc_filters()
else:
    include_coinc_filters = None

# Clear coinc_inspiral table of triggers outside of interested ranges
if param_filters or exclude_coinc_filters or include_coinc_filters:
    sqlutils.apply_inclusion_rules_to_coinc_inspiral( connection, 
        exclude_coincs = exclude_coinc_filters,
        include_coincs = include_coinc_filters, 
        param_filters = param_filters, verbose = opts.verbose )

#
#         Program-specific Initialization
# 

# Get ranking stat
ranking_stat =  opts.ranking_stat
if opts.rank_by.strip().upper() == 'MAX':
    rank_by = 'MAX'
elif opts.rank_by.strip().upper() == 'MIN':
    rank_by = 'MIN'
else:
    raise ValueError, "rank_by must be set to either MAX or MIN (received %s)" % str(rank_by)

# sqlitize convert_to_yrs
connection.create_function( 'convert_to_yrs', 1, convert_to_yrs )

# sqlitize param_parser.group_by_param_range()
if opts.param_name:
    connection.create_function("group_by_param", 1, param_parser.group_by_param_range)
    param_grouping = ''.join([ 'group_by_param(', param_name, ')' ])
else:
    param_grouping = '0'

#
# Collect information about the background 
#
if opts.verbose:
    print >> sys.stderr, "Getting background statistics..."

# initialize Summaries class, call background
background = sqlutils.Summaries()

# get information about all rows in the experiment summary table
sqlquery = ''.join(["""
    SELECT
        experiment_summary.experiment_id,
        experiment_summary.experiment_summ_id,
        convert_to_yrs(experiment_summary.duration),
        experiment_summary.datatype
    FROM
        experiment_summary
    WHERE
        experiment_summary.datatype != "simulation" """])
for eid, esid, duration, datatype in connection.cursor().execute( sqlquery ):
    background.append_duration(eid, esid, duration)
    if datatype != "slide":
        background.append_zero_lag_id( eid, esid, datatype )

# calculate the background duration for each experiment_summary_id 
background.calc_bkg_durs()

# get all the non-injection triggers
sqlquery = ''.join([ """
    SELECT 
        experiment_summary.experiment_id,
        experiment_summary.experiment_summ_id,
        coinc_inspiral.ifos,
        """,
        param_grouping, """,
        coinc_inspiral.""", ranking_stat,"""
    FROM 
        coinc_inspiral
    JOIN 
        experiment_summary, experiment_map ON (
            experiment_summary.experiment_summ_id == experiment_map.experiment_summ_id
            AND experiment_map.coinc_event_id == coinc_inspiral.coinc_event_id)
    WHERE 
        experiment_summary.datatype != "simulation" """])

if opts.debug:
    import time
    print >> sys.stderr, sqlquery
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]

for eid, esid, ifos, param_group, stat in connection.cursor().execute(sqlquery):
    background.add_to_bkg_stats(eid, esid, ifos, param_group, stat)

if opts.debug:
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]

# sort the background lists
background.sort_bkg_stats()

if rank_by == "MIN":
    connection.create_function("calc_ufar", 5, background.calc_ufar_by_min)
else:
    connection.create_function("calc_ufar", 5, background.calc_ufar_by_max)


#
#     Calculate uncombined FAR
#

if opts.verbose:
    print >> sys.stderr, "Calculating uncombined FAR..."
# calculate the uncombined far for each trigger and store in coinc_inspiral table
sqlquery = ''.join(["""
    UPDATE
        coinc_inspiral
    SET
        false_alarm_rate = (
            SELECT
                calc_ufar(
                    experiment_summary.experiment_id,
                    experiment_summary.experiment_summ_id,
                    coinc_inspiral.ifos,
                    """, param_grouping, """,
                    coinc_inspiral.""", ranking_stat, """
                    ) 
            FROM 
                experiment_summary, experiment_map
            WHERE
                experiment_summary.datatype != "simulation"
                AND experiment_summary.experiment_summ_id == experiment_map.experiment_summ_id
                AND experiment_map.coinc_event_id == coinc_inspiral.coinc_event_id)"""])
if opts.debug:
    print >> sys.stderr, sqlquery
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]

connection.cursor().execute(sqlquery)

if opts.debug:
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]


#
#   Calculate combined FAR
#

if opts.verbose:
    print >> sys.stderr, "Calculating combined FAR..."

# sqlitize functions
connection.create_function('calc_cfar', 3, background.calc_cfar)

# to calculate the max_bkg_fars in each category, we will 
# use calc_ufar by passing it a 0; for this to work, however,
# calc_ufar must be the by_max version, so if MIN, reset to max
if rank_by == "MIN":
    connection.create_function("calc_ufar", 5, background.calc_ufar_by_max)

#
# Run the sqlite script to calculate combined far. This works in
# 3 steps:
#   1. Create a temporary table called max_bkg_fars. This stores
#      the max_bkg_fars for every category for each experiment_summ_id.
#   2. Get max_bkg_fars for each experiment_summ_id: 
#      this is the same things as the far calculated above, 
#      just that the numerator are ALL the triggers in the
#      background for that category.
#   3. Calculate the combined FAR:
#      This applies the algorithim in calc_cfar to each uncombined_far
#      in the coinc_inspiral table using the max_bkg_fars calculated in 2.
#
sqlscript = ''.join(["""
    CREATE TEMP TABLE max_bkg_fars AS
        SELECT DISTINCT 
            experiment_summary.experiment_id AS experiment_id,
            experiment_summary.experiment_summ_id AS experiment_summ_id,
            coinc_inspiral.ifos AS ifos,
            """,
            param_grouping, """ AS param_group,
            NULL AS max_bkg_far
        FROM 
            coinc_inspiral
        JOIN 
            experiment_summary, experiment_map ON (
                experiment_summary.experiment_summ_id == experiment_map.experiment_summ_id
                AND experiment_map.coinc_event_id == coinc_inspiral.coinc_event_id )
        WHERE 
            experiment_summary.datatype != "simulation";
    UPDATE 
        max_bkg_fars
    SET 
        max_bkg_far = (
            calc_ufar(
                    max_bkg_fars.experiment_id,
                    max_bkg_fars.experiment_summ_id,
                    max_bkg_fars.ifos,
                    max_bkg_fars.param_group,
                    0
                    )
            );
   CREATE INDEX mbf_es_index ON max_bkg_fars (experiment_summ_id);"""])

if opts.debug:
    print >> sys.stderr, sqlscript
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]

connection.cursor().executescript( sqlscript )

if opts.debug:
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]

# get the max bkg fars for each experiment summary
sqlquery = """
    SELECT
        experiment_summ_id,
        ifos,
        max_bkg_far
    FROM
        max_bkg_fars"""

if opts.debug:
    print >> sys.stderr, sqlquery
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]

for esid, ifos, mbf in connection.cursor().execute(sqlquery):
    if opts.combine_fars == "across_all":
        ifos = "ALL_IFOS"
    background.append_max_bkg_far(esid, ifos, mbf)

if opts.debug:
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]

background.sort_max_bkg_fars()

if opts.combine_fars == "across_all":
    ifos_group = '"ALL_IFOS",'
else:
    ifos_group = "coinc_inspiral.ifos,"
sqlquery = ''.join(["""
   UPDATE 
       coinc_inspiral
   SET 
       combined_far = (
           SELECT 
               calc_cfar( 
                    experiment_map.experiment_summ_id,
                    """, ifos_group,
                    """
                    coinc_inspiral.false_alarm_rate )
            FROM 
                experiment_summary, experiment_map
            WHERE
                experiment_summary.datatype != "simulation"
                AND experiment_summary.experiment_summ_id == experiment_map.experiment_summ_id
                AND experiment_map.coinc_event_id == coinc_inspiral.coinc_event_id)"""])

if opts.debug:
    print >> sys.stderr, sqlquery
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]

connection.cursor().execute( sqlquery )

if opts.debug:
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]

# Vacuum database if desired
if opts.vacuum:
    if opts.verbose:
        print >> sys.stderr, "Vacuuming database..."
    connection.cursor().execute( 'VACUUM' )
    if opts.verbose:
        print >> sys.stderr, "done."

#
#       Save and Exit
#

# TODO: set outfile name rather than user inputed name

connection.commit()

# write xml file if desired
if opts.write_xml_file:
    extract(connection, opts.write_xml_file, verbose = opts.verbose)

connection.close()

# write output database
dbtables.put_connection_filename(opts.output, working_filename, verbose = opts.verbose)

if opts.verbose: 
    print >> sys.stdout, "Finished!"

# set process end time
process.set_process_end_time(proc_id)
sys.exit(0)

